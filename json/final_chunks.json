[
    {
        "id": "b37b0461-e69e-4514-8d67-f7ba87b3b13a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nimport asyncio\nimport streamlit as st\nfrom typing import Dict, Tuple, List, Optional",
        "size": 109,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b808b40b-e667-4364-9e3d-7cb922a6a798",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 11,
        "end_line": 47,
        "content": "def initialize():\n        \"\"\"Initialize all session state variables\"\"\"\n        if \"pipeline_states\" not in st.session_state:\n            st.session_state.pipeline_states = {\n                \"1\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                },\n                \"2\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                }\n            }\n        \n        if \"file_uploaded\" not in st.session_state:\n            st.session_state.file_uploaded = False\n        \n        if \"file_name\" not in st.session_state:\n            st.session_state.file_name = \"\"",
        "size": 1509,
        "parent-class": "SessionState",
        "function_name": "initialize"
    },
    {
        "id": "6cc5792c-3d0b-41ff-99b1-57299f068849",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 50,
        "end_line": 53,
        "content": "def reset_search_result(pipeline_id: str):\n        \"\"\"Reset search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = {}",
        "size": 260,
        "parent-class": "SessionState",
        "function_name": "reset_search_result"
    },
    {
        "id": "13633e53-f60a-4edd-9044-25021a27024d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 56,
        "end_line": 59,
        "content": "def reset_reranking_result(pipeline_id: str):\n        \"\"\"Reset reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = {}",
        "size": 272,
        "parent-class": "SessionState",
        "function_name": "reset_reranking_result"
    },
    {
        "id": "1d41657e-6ccb-4fa8-93a9-68282e454876",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 62,
        "end_line": 65,
        "content": "def set_search_performed(pipeline_id: str, top_k: int):\n        \"\"\"Mark search as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = True\n        st.session_state.pipeline_states[pipeline_id][\"top_k\"] = top_k",
        "size": 270,
        "parent-class": "SessionState",
        "function_name": "set_search_performed"
    },
    {
        "id": "0c3a2c2c-ed16-448a-9835-dc3c9284b743",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 68,
        "end_line": 70,
        "content": "def set_reranking_performed(pipeline_id: str):\n        \"\"\"Mark reranking as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = True",
        "size": 196,
        "parent-class": "SessionState",
        "function_name": "set_reranking_performed"
    },
    {
        "id": "a36679c4-30d6-4ca5-9fd2-42e8483d6371",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 73,
        "end_line": 75,
        "content": "def set_index_created(pipeline_id: str):\n        \"\"\"Mark index as created for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"index_created\"] = True",
        "size": 178,
        "parent-class": "SessionState",
        "function_name": "set_index_created"
    },
    {
        "id": "5f8ea068-9bd1-41c3-8c8c-63bf6ec4be23",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 78,
        "end_line": 80,
        "content": "def store_search_results(pipeline_id: str, results: Dict):\n        \"\"\"Store search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = results",
        "size": 199,
        "parent-class": "SessionState",
        "function_name": "store_search_results"
    },
    {
        "id": "d89a03fb-71c0-4710-8dac-a69a8307f38a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 83,
        "end_line": 85,
        "content": "def store_reranking_results(pipeline_id: str, results: Dict):\n        \"\"\"Store reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = results",
        "size": 208,
        "parent-class": "SessionState",
        "function_name": "store_reranking_results"
    },
    {
        "id": "6a02f358-f6b7-4a1b-8151-b0a362a837ba",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 88,
        "end_line": 89,
        "content": "def store_random_question(pipeline_id: str, generated_question: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_question\"] = generated_question",
        "size": 164,
        "parent-class": "SessionState",
        "function_name": "store_random_question"
    },
    {
        "id": "a294d2da-0c03-4d99-b989-4e3325f42044",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 92,
        "end_line": 94,
        "content": "def store_random_question_answer(pipeline_id: str, query: str, results: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_query\"] = query\n        st.session_state.pipeline_states[pipeline_id][\"random_question_results\"] = results",
        "size": 247,
        "parent-class": "SessionState",
        "function_name": "store_random_question_answer"
    },
    {
        "id": "72b08986-ed82-4c95-b39c-0b56e824a602",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 100,
        "end_line": 116,
        "content": "def get_embedding_models() -> List[str]:\n        \"\"\"Get list of available embedding models\"\"\"\n        return [\n            \"\",\n            \"llama-text-embed-v2\",\n            \"multilingual-e5-large\",\n            \"embed-english-v3.0\",\n            \"embed-multilingual-v3.0\",\n            \"embed-english-light-v3.0\",\n            \"embed-multilingual-light-v3.0\",\n            \"embed-english-v2.0\",\n            \"embed-english-light-v2.0\",\n            \"embed-multilingual-v2.0\",\n            \"jina-embeddings-v3\",\n            \"jina-clip-v2\",\n            \"voyage-3-large\"\n        ]",
        "size": 570,
        "parent-class": "ModelRegistry",
        "function_name": "get_embedding_models"
    },
    {
        "id": "89375eb1-45c5-49a9-943b-f99cf105e124",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 119,
        "end_line": 124,
        "content": "def get_code_embedding_models() -> List[str]:\n        return [\n            \"\",\n            \"jina-embeddings-v2-base-code\",\n            \"voyage-code-3\",\n        ]",
        "size": 161,
        "parent-class": "ModelRegistry",
        "function_name": "get_code_embedding_models"
    },
    {
        "id": "a4135c0b-dfa2-48cb-a5ab-59e2c2a11973",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 126,
        "end_line": 139,
        "content": "def get_reranking_models() -> List[str]:\n        \"\"\"Get list of available reranking models\"\"\"\n        return [\n            \"\",\n            \"pinecone-rerank-v0\",\n            \"bge-reranker-v2-m3\",\n            \"rerank-v3.5\",\n            \"rerank-english-v3.0\",\n            \"rerank-multilingual-v3.0\",\n            \"jina-reranker-v2-base-multilingual\",\n            \"rereank-lite-1\",\n            \"rerank-2\",\n            \"rerank-1\"\n        ]",
        "size": 433,
        "parent-class": "ModelRegistry",
        "function_name": "get_reranking_models"
    },
    {
        "id": "1ea3c720-2524-4cd8-95cc-392cf060f96f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 142,
        "end_line": 158,
        "content": "def get_dimensions(dense_embedding_model: str) -> List[int]:\n        \"\"\"Get available dimensions for a specific embedding model\"\"\"\n        model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        return model_to_dimensions.get(dense_embedding_model, [])",
        "size": 856,
        "parent-class": "ModelRegistry",
        "function_name": "get_dimensions"
    },
    {
        "id": "ea36e148-7238-4894-8d23-61610b111af9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 164,
        "end_line": 180,
        "content": "def display_results_tabs(pipeline_id: str):\n        \"\"\"Display results in tabbed interface\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        tab1, tab2 = st.tabs([\"Search Results\", \"Reranking Results\"])\n        \n        with tab1:\n            if pipeline_state[\"search_performed\"]:\n                UIComponents.display_search_results(pipeline_state[\"search_results\"], pipeline_id)\n            else:\n                st.info(\"Run a search to see results here.\")\n        \n        with tab2:\n            if pipeline_state[\"reranking_performed\"]:\n                UIComponents.display_reranking_results(pipeline_state[\"reranking_results\"], pipeline_id)\n            else:\n                st.info(\"Run reranking to see results here.\")",
        "size": 767,
        "parent-class": "UIComponents",
        "function_name": "display_results_tabs"
    },
    {
        "id": "c82fcc88-bd45-4894-88c2-56489f30bd29",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 183,
        "end_line": 196,
        "content": "def display_search_results(results: Dict, pipeline_id: str):\n        \"\"\"Display search results\"\"\"\n        if not results:\n            st.info(\"No search results available.\")\n            return\n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Search metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_search_{pipeline_id}\"\n        )\n        st.json(results, expanded = False)",
        "size": 565,
        "parent-class": "UIComponents",
        "function_name": "display_search_results"
    },
    {
        "id": "926fa627-fba1-4f11-bf45-6626264cfd04",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 200,
        "end_line": 215,
        "content": "def display_reranking_results(results: Dict, pipeline_id: str):\n        \"\"\"Display reranking results\"\"\"\n        if not results:\n            st.info(\"No reranking results available.\")\n            return\n        \n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Rerank metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_reranking_{pipeline_id}\"\n        )\n        \n        st.json(results, expanded = False)",
        "size": 595,
        "parent-class": "UIComponents",
        "function_name": "display_reranking_results"
    },
    {
        "id": "eee7aaab-6d2b-49d2-b3be-03cee51ba574",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 218,
        "end_line": 245,
        "content": "def display_random_question(pipeline_id: str):\n\n        if st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"]:\n            results = st.session_state.pipeline_states[pipeline_id][\"random_question\"]\n            question = results[\"question\"]\n\n            if len(results) > 0:\n                st.markdown(f\"### Random Question: \\n> {question}\")\n\n                for i, res in enumerate(results[\"chunks\"]):\n\n                    col1, col2 = st.columns([1, 1])\n                    with col1:\n                        st.markdown(f\"**Ground Truth Chunk {i+1}**\")\n                    with col2:\n                        st.markdown(f\"**ID:** {res['_id']}\")\n                # Create expander for each chunk\n                    with st.expander(\"Ground Truth\", expanded=False):\n                        \n                        # Display the text with wrapping\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"gt_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")",
        "size": 1243,
        "parent-class": "UIComponents",
        "function_name": "display_random_question"
    },
    {
        "id": "03ee3bbd-da47-41f5-a6be-8ea60766399f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 248,
        "end_line": 276,
        "content": "def display_random_question_answer(pipeline_id: str):\n        \n        if st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"]:\n            response = st.session_state.pipeline_states[pipeline_id][\"random_question_results\"]\n            query = st.session_state.pipeline_states[pipeline_id][\"random_query\"]\n            \n            # Container for the results to improve layout\n            if len(response) > 0:\n                st.markdown(\"### Search Results\")\n                st.markdown(f\"**Query:** \\n> {query}\")\n\n                for i, res in enumerate(response):\n                    # Create expander for each chunk\n                    score_indicator = \"\ud83d\udfe9\" if res['score'] > 0.8 else \"\ud83d\udfe7\" if res['score'] > 0.5 else \"\ud83d\udfe5\"\n                    col1, col2 = st.columns([4, 1])\n                    with col1:\n                        st.markdown(f\"**Relevant chunk {i+1}** || **ID:** {res['id']}\")\n                    with col2:\n                        st.markdown(f\"{score_indicator} **Score:** {res['score']:.4f}\")\n\n                    with st.expander(\"**Chunk**\",expanded=False):\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"chunk_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\n        ",
        "size": 1492,
        "parent-class": "UIComponents",
        "function_name": "display_random_question_answer"
    },
    {
        "id": "8b3afa44-a4e9-41c8-b4a8-60d7aa34901a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 287,
        "end_line": 297,
        "content": " fetch_user_previous_configurations():\n        \"\"\"Fetch user's previous configurations\"\"\"\n        async with httpx.AsyncClient() as client:\n            try:\n                response = await client.get(\n                    f\"{APIClient.BASE_URL}/get-configurations\",\n                    timeout=APIClient.TIMEOUT,\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n    \n   ",
        "size": 545,
        "parent-class": ":\n    \"\"\"",
        "function_name": "r_previous_configurations():\n     "
    },
    {
        "id": "068edd70-101d-42e1-9dbe-ace043bb3c11",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 300,
        "end_line": 315,
        "content": " upload_file(data):\n        \"\"\"Upload a file to the backend service\"\"\"\n        \n        files = {\"file\": data['uploaded_file']}\n        form_data = {\"file_type\" : data[\"file_type\"]}\n\n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/upload-files\",\n                    files=files,\n                    data=form_data\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n        ",
        "size": 681,
        "parent-class": ":\n    \"\"\"",
        "function_name": "le(data):\n "
    },
    {
        "id": "529eb4f0-0f42-4e07-b21a-d146a40188a1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 318,
        "end_line": 335,
        "content": " create_index(file_name: str, embed_model: str, similarity_metric: str, dimension: int) -> Tuple[bool, str]:\n        \"\"\"Create an index and upsert dataset\"\"\"\n        payload = {\n            \"file_name\": file_name,\n            \"embed_model\": embed_model,\n            \"similarity_metric\": similarity_metric,\n            \"dimension\": dimension,\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/index-upsert\",\n                    json=payload,\n                )\n                return response.status_code == 200, response.json()[\"error\"] if response.status_code != 200 else \"\"\n            except Exception as e:\n                return False, str(e)\n        ",
        "size": 807,
        "parent-class": ":\n    \"\"\"",
        "function_name": "dex(file_nam"
    },
    {
        "id": "df39062d-20bf-4464-9e97-950139226031",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 338,
        "end_line": 366,
        "content": " perform_search(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform a search query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/query\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_result\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        ",
        "size": 1235,
        "parent-class": ":\n    \"\"\"",
        "function_name": "earch(is_hybri"
    },
    {
        "id": "e95180bd-3a5b-4f6f-bc4e-ae499b921e39",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 369,
        "end_line": 390,
        "content": " perform_reranking(model_name: str, top_n: int, top_k: int) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform reranking\"\"\"\n        payload = {\n            \"model_name\": model_name,\n            \"top_n\": top_n,\n            \"top_k\": top_k\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/rerank\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_metrics\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        ",
        "size": 867,
        "parent-class": ":\n    \"\"\"",
        "function_name": "eranking(model_na"
    },
    {
        "id": "b2b72515-6975-433b-b15d-306db78048fb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 393,
        "end_line": 411,
        "content": " random_question(file_name: str) -> Tuple[bool, Dict, str]:\n        \"\"\"Generate a random question\"\"\"\n        payload = {\n            \"file_name\": file_name\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-question\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        ",
        "size": 741,
        "parent-class": ":\n    \"\"\"",
        "function_name": "estion(file_nam"
    },
    {
        "id": "37a14169-b746-4eff-818b-3c15ddccdc7d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 414,
        "end_line": 442,
        "content": " random_query(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, query: str, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None):\n        \"\"\"Perform a random query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n            \"query\": query,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-query\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        ",
        "size": 1196,
        "parent-class": ":\n    \"\"\"",
        "function_name": "ery(is_hybri"
    },
    {
        "id": "39cfcdd7-92b8-45bf-b781-0fb3356cd8c4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 448,
        "end_line": 500,
        "content": " index_creation_section(pipeline_id: str, is_hybrid: bool) -> bool:\n        \"\"\"Handle index creation section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = \"\"\n        if st.session_state.get(f'file_type', None) == \"Code\":\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_code_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        else:\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        \n        dimensions = ModelRegistry.get_dimensions(dense_embedding_model)\n        dense_dimension = st.selectbox(\n            \"Enter Dimension of the Dense Model:\",\n            dimensions,\n            key=f\"dense_dimension_{pipeline_id}\",\n        )\n        \n        if not dense_embedding_model or not dense_dimension:\n            st.warning(\"Please select the required models and dimensions.\")\n            return False\n        \n        similarity_metric = \"dotproduct\"\n        if not is_hybrid:\n            similarity_metric = st.selectbox(\n                \"Enter Similarity Metric:\",\n                [\"dotproduct\", \"cosine\", \"euclidean\"],\n                key=f\"similarity_metric_{pipeline_id}\",\n            )\n        else:\n            st.warning(\"By default, dot product similarity is used for the hybrid search.\")\n        \n        if st.button(\"Create Index and Upsert Dataset\", key=f\"create_index_{pipeline_id}\"):\n            with st.spinner(\"Creating index and upserting dataset...\"):\n                success, error_msg = await APIClient.create_index(\n                    file_name, dense_embedding_model, similarity_metric, dense_dimension\n                )\n                \n                if success:\n                    st.success(\"Index created and dataset upserted successfully!\")\n                    SessionState.set_index_created(pipeline_id)\n                else:\n                    st.error(f\"Index creation and dataset upsert failed: {error_msg}\")\n        \n        return pipeline_state[\"index_created\"]\n    \n   ",
        "size": 2357,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ation_section(pipeline"
    },
    {
        "id": "d1a5c935-ef76-42d4-8eb2-31c863a2a7cc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 503,
        "end_line": 554,
        "content": " search_section(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Handle search section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.number_input(\"Enter the value for top_k:\", min_value=1, value=\"min\", step=1, key=f\"top_k_{pipeline_id}\")\n        \n        alpha = None\n        if is_hybrid:\n            alpha = st.slider(\n                \"Select alpha value (between 0 and 1):\",\n                min_value=0.0,\n                max_value=1.0,\n                step=0.1,\n                value=0.5,\n                key=f\"alpha_{pipeline_id}\",\n            )\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get First Stage Evaluation Metrics\",\n                key=f\"perform_search_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing search...\"):\n                    success, results, error_msg = await APIClient.perform_search(\n                        is_hybrid=is_hybrid,\n                        file_name=file_name,\n                        embedding_model=dense_embedding_model,\n                        dimension=dense_dimension,\n                        top_k=top_k,\n                        similarity_metric=similarity_metric,\n                        alpha=alpha,\n                    )\n                    \n                    if success:\n                        st.success(\"Search performed successfully!\")\n                        SessionState.store_search_results(pipeline_id, results)\n                        SessionState.set_search_performed(pipeline_id, top_k)\n                    else:\n                        st.error(f\"First stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_similarity_{pipeline_id}\",\n            ):\n                SessionState.reset_search_result(pipeline_id)\n    \n   ",
        "size": 2279,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ction(pipeline"
    },
    {
        "id": "ab31e010-e99a-41bd-ac88-bcb86c74d9b3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 557,
        "end_line": 605,
        "content": " reranking_section(pipeline_id: str):\n        \"\"\"Handle reranking section of the UI\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        if not pipeline_state[\"search_performed\"] or not pipeline_state[\"search_results\"]:\n            return\n        \n        reranking_model = st.selectbox(\n            \"Select Reranking Model:\",\n            ModelRegistry.get_reranking_models(),\n            key=f\"reranking_model_{pipeline_id}\",\n        )\n        \n        top_n = st.number_input(\"Enter the value for top_n:\", min_value=1, value=\"min\", step=1, key=f\"top_n_{pipeline_id}\")\n        \n        if pipeline_state[\"top_k\"] < top_n:\n            st.warning(\"The value of top_n should be less than or equal to the value of top_k.\")\n            return\n        \n        if not reranking_model or not top_n:\n            st.warning(\"Please select the reranking model and enter the top_n value.\")\n            return\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get Reranking Evaluation Metrics\",\n                key=f\"perform_reranking_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing reranking...\"):\n                    success, results, error_msg = await APIClient.perform_reranking(\n                        model_name=reranking_model,\n                        top_n=top_n,\n                        top_k=pipeline_state[\"top_k\"],\n                    )\n                    \n                    if success:\n                        st.success(\"Reranking performed successfully!\")\n                        SessionState.store_reranking_results(pipeline_id, results)\n                        SessionState.set_reranking_performed(pipeline_id)\n                    else:\n                        st.error(f\"Second stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_reranked_{pipeline_id}\",\n            ):\n                SessionState.reset_reranking_result(pipeline_id)\n        ",
        "size": 2081,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "_section(pipeline"
    },
    {
        "id": "3fd8fe15-fc91-4367-8498-c9799cda39bc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 608,
        "end_line": 627,
        "content": " random_question_section(pipeline_id: str):\n        if \"file_name\" in st.session_state:\n            file_name = st.session_state.file_name\n            \n            if st.button(\n                \"Get random question\",\n                key=f\"generate_random_question_{pipeline_id}\",\n            ):\n                with st.spinner(\"processing random question...\"):\n                    success, response, error_msg = await APIClient.random_question(file_name)\n                    \n                    if success:\n                        st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"] = True\n                        SessionState.store_random_question(pipeline_id = pipeline_id, generated_question = response)\n\n                    else:\n                        st.error(f\"Random question generation failed: {error_msg}\")\n\n        else:\n            st.warning(\"No file selected. Please upload a file first.\")\n        ",
        "size": 937,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "estion_section(pipeline"
    },
    {
        "id": "7b9e7a62-1ca2-47e9-9e29-4b66e284be1c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 630,
        "end_line": 670,
        "content": " random_query_section(pipeline_id: str):\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.session_state.get(f\"top_k_{pipeline_id}\", 0)\n        is_hybrid = st.session_state.get(f\"hybrid_search_{pipeline_id}\", \"No\") == \"Yes\"\n        alpha = st.session_state.get(f\"alpha_{pipeline_id}\", None)\n            \n        query = st.text_input(\"Enter the query for random search:\", key=f\"query_{pipeline_id}\")\n        \n        if not query:\n            st.warning(\"Please enter a query for random search.\")\n            return\n        \n        if st.button(\n            \"Search custom query\", \n            key=f\"search_custom_query_{pipeline_id}\"\n        ):\n            with st.spinner(\"Performing search...\"):\n                success, response, error_msg = await APIClient.random_query(\n                    is_hybrid=is_hybrid,\n                    file_name=file_name,\n                    embedding_model=dense_embedding_model,\n                    dimension=dense_dimension,\n                    top_k=top_k,\n                    query=query,\n                    similarity_metric=similarity_metric,\n                    alpha=alpha,\n                )\n                \n                if success:\n                    st.success(\"Search performed successfully!\")\n                    st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"] = True\n                    SessionState.store_random_question_answer(pipeline_id = pipeline_id, query=query, results = response)\n                        \n                else:\n                    st.error(f\"Error performing search: {error_msg}\")\n    \n   ",
        "size": 1990,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ery_section(pipeline"
    },
    {
        "id": "3c9df468-7e4e-415c-af83-ea3389b10b41",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 673,
        "end_line": 691,
        "content": " run_pipeline(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Run a complete RAG pipeline\"\"\"\n\n        index_ready = await PipelineManager.index_creation_section(pipeline_id, is_hybrid)\n        \n        if index_ready:\n            \n            await PipelineManager.search_section(pipeline_id, is_hybrid)\n            \n            await PipelineManager.reranking_section(pipeline_id)\n            \n            await PipelineManager.random_question_section(pipeline_id)\n            UIComponents.display_random_question(pipeline_id=pipeline_id)\n            \n            await PipelineManager.random_query_section(pipeline_id)\n            UIComponents.display_random_question_answer(pipeline_id=pipeline_id)\n        \n        st.subheader(\"Results\")\n        UIComponents.display_results_tabs(pipeline_id)\n        ",
        "size": 805,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ine(pipeline"
    },
    {
        "id": "5cf31565-846d-4994-b848-9005552cdf4c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 693,
        "end_line": 721,
        "content": " handle_file_upload():\n    \"\"\"Handle file upload\"\"\"\n    file_type = st.radio(\"Select File Type:\", [\"Text\", \"Code\"])\n    if \"file_type\" not in st.session_state:\n        st.session_state.file_type = file_type\n    st.session_state.file_type = file_type\n\n\n    uploaded_file = st.file_uploader(\"Upload a file:\", type=[\"json\"])\n    \n    if uploaded_file and not st.session_state.file_uploaded:\n        with st.spinner(\"Uploading file...\"):\n            data = {\"uploaded_file\": uploaded_file, \"file_type\": file_type}\n            success, response, error_msg = await APIClient.upload_file(data)\n\n            if success:\n                success_message = response.json()[\"detail\"]\n                st.success(f\"Success Message: {success_message}\")\n\n                st.session_state.file_uploaded = True\n                st.session_state.file_name = uploaded_file.name\n\n                st.write(\"Here is the schema of the uploaded file:\")\n                st.json(response.json()[\"data\"][\"file_schema\"])\n            else:\n                st.error(f\"Upload failed: {error_msg}\")\n\n    \n    return st.session_state.file_uploaded\n\nasync d",
        "size": 1121,
        "parent-class": null,
        "function_name": "le_upload():\n    \""
    },
    {
        "id": "3be1192f-2500-49aa-858d-5bc848167621",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 723,
        "end_line": 788,
        "content": " main():\n    \"\"\"Main application entry point\"\"\"\n    \n    SessionState.initialize()\n    \n    st.set_page_config(\n        page_title=\"RAG Pipeline Comparison Tool | Pinecone\",\n        layout=\"wide\",\n        page_icon=\"\ud83e\uddca\",\n    )\n    \n    st.title(\"RetrieveWise\")\n    st.divider()\n    st.markdown(\n        \"\"\"\n        Compare and Evaluate different Information Retrieval Pipelines, Configure two retrieval pipelines side by side \n        with different settings, embedding models, rerankers. Once set compare key performance metrics like precision, recall\n        NDCG, MRR, F1 etc \n    \"\"\"\n    )\n    \n    success, response, error_msg = await APIClient.fetch_user_previous_configurations()\n    \n    if success:\n        data = response.json().get(\"data\", None)\n        if isinstance(data, dict) and \"message\" in data:\n            st.info(data[\"message\"])\n        else:\n            st.write(\"Here are your previous configurations:\")\n            st.json(response.json()[\"data\"], expanded = False)\n    else:\n        st.error(f\"Failed to fetch previous configurations: {error_msg}\")\n    \n    file_uploaded = await handle_file_upload()\n    \n    if not file_uploaded:\n        st.warning(\"Please upload the JSON files for the pipelines to compare.\")\n        return\n\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.header(\"Pipeline 1\")\n        hybrid_search_1 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_1\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"1\", \n            is_hybrid=(hybrid_search_1 == \"Yes\")\n        )\n        \n    with col2:\n        st.header(\"Pipeline 2\")\n        hybrid_search_2 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_2\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"2\", \n            is_hybrid=(hybrid_search_2 == \"Yes\")\n        )\n        \nif",
        "size": 2014,
        "parent-class": null,
        "function_name": "   \""
    },
    {
        "id": "ffe9859f-b7e2-477f-9ff7-6046bc753737",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom app.apis import file_upload, index_upsert_route, query, reranking_router, configuration_route, random_question_route, random_query_route\nfrom app.config.database import db_helper",
        "size": 254,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "3df8c419-c94b-4c8b-b8ec-8a4939108160",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 10,
        "end_line": 14,
        "content": "async def lifespan(app: FastAPI):\n    await db_helper.connect()\n    db = await db_helper.get_db()\n    yield\n    await db_helper.disconnect()",
        "size": 140,
        "parent-class": null,
        "function_name": "lifespan"
    },
    {
        "id": "3e988dde-daed-4609-a63c-00e42c2f4483",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 30,
        "end_line": 31,
        "content": "async def root():\n    return {\"message\": \"Welcome to the RAG Playground\"}",
        "size": 73,
        "parent-class": null,
        "function_name": "root"
    },
    {
        "id": "2d4f5ff5-8660-44a3-85ef-b00e6943488a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.query_controller import QueryController\nfrom app.models.schemas.query_schema import QueryEndPointRequest",
        "size": 269,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "3f1bbc17-1821-415f-8fe0-d7f3510c2e6d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 12,
        "end_line": 26,
        "content": "async def make_query(\n    request: QueryEndPointRequest, query_controller: QueryController = Depends()\n):\n\n    response_data = await query_controller.make_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Query execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 414,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "a18502bb-fc8d-431f-8007-caa9a98c5447",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.models.schemas.random_query_schema import RandomQueryRequest\nfrom app.controllers.random_query_controller import RandomQueryController",
        "size": 287,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "4f24fdf8-461e-45b0-9940-50f702f45c38",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 13,
        "end_line": 28,
        "content": "async def random_query(\n    request: RandomQueryRequest,\n    random_query_controller: RandomQueryController = Depends(),\n):\n\n    response = await random_query_controller.random_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Query Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 469,
        "parent-class": null,
        "function_name": "random_query"
    },
    {
        "id": "a8bdf7d2-2dda-4e68-9807-1754ef90db18",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.random_question_controller import RandomQuestionController",
        "size": 254,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "6784a7f8-0c95-4079-8953-ba5a3d6bfdbc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 16,
        "end_line": 31,
        "content": "async def random_question(\n    request: RQRequest,\n    random_question_controller: RandomQuestionController=Depends(),\n):\n\n    response = await random_question_controller.random_question(request.file_name)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Question Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 486,
        "parent-class": null,
        "function_name": "random_question"
    },
    {
        "id": "fe473e00-0454-4444-bc07-f19c3c3a822d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/configuration_route.py",
        "file_name": "configuration_route.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.config_controller import ConfigurationController",
        "size": 213,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "88aa7dcf-09de-4ccb-bd33-b8a2ef9c1d1d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/configuration_route.py",
        "file_name": "configuration_route.py",
        "start_line": 11,
        "end_line": 25,
        "content": "async def make_query(\n    config_controller: ConfigurationController = Depends()\n):\n\n    response_data = await config_controller.get_config()\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Configuration fetching successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 393,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "668c8c6e-2d11-400b-a42a-349684011d67",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Body, Depends,status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.reranking_controller import RerankingController\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest\n)",
        "size": 290,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "20696a1c-88ac-476e-8020-36b132013eed",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 15,
        "end_line": 31,
        "content": "async def rerank_documents(\n    request: RerankingRequest = Body(...),\n    controller: RerankingController = Depends(),\n):\n    \n    response_data = await controller.rerank_documents(request)\n    response = response_data.model_dump()\n\n    return JSONResponse(\n        content={\n            \"data\": response,\n            \"statuscode\": 200,\n            \"detail\": \"Rerank execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 473,
        "parent-class": null,
        "function_name": "rerank_documents"
    },
    {
        "id": "a2b57e01-816d-47b3-ae69-8cf95f9fa525",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.index_upsert_controller import IndexUpsertController\nfrom app.models.schemas.index_upsert_schema import IndexUpsertRequest",
        "size": 287,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b1b9e864-b6fa-4d75-95de-a1f964a92a9d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 13,
        "end_line": 30,
        "content": "async def index_upsert(\n    request: IndexUpsertRequest,\n    index_upsert_controller: IndexUpsertController = Depends(\n        IndexUpsertController\n    ),\n):\n    \n    response = await index_upsert_controller.index_upsert(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"host\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Upserted Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 490,
        "parent-class": null,
        "function_name": "index_upsert"
    },
    {
        "id": "74c033b9-a9ee-4c75-b2ec-cf7e70b6cee2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, UploadFile, File, status, Form\nfrom fastapi.responses import JSONResponse\nfrom app.controllers.file_upload_controller import FileUploadController\nfrom app.utils.error_handler import handle_exceptions\nimport logging",
        "size": 254,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5caa9c8f-2bb7-49a7-a2ea-0583732388fc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 14,
        "end_line": 32,
        "content": "async def upload_files(\n    file_type: str = Form(),\n    file: UploadFile = File(...),\n    file_controller: FileUploadController = Depends(),\n):\n    response_data = await file_controller.upload_files({\n        \"input_data\": file,\n        \"file_name\": file.filename,\n        \"file_type\": file_type\n    })\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": response_data[\"data\"],\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )",
        "size": 539,
        "parent-class": null,
        "function_name": "upload_files"
    },
    {
        "id": "faa062b4-9207-4ab3-a8b0-a0242e3c6634",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from motor.motor_asyncio import AsyncIOMotorClient\nfrom app.config.settings import settings",
        "size": 91,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "83672cdd-7eb1-468b-a0df-bb296702b4cc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 7,
        "end_line": 13,
        "content": "def __init__(self):\n        self.client = AsyncIOMotorClient(settings.MONGODB_URL)\n        self.db = self.client[settings.DATABASE_NAME]\n        self.raw_data = self.db[\"raw_data\"]\n        self.index_upsert_collection = self.db[\"index_upsert\"]\n        self.gt_data = self.db[\"gt_data\"]\n        self.query_embeddings_collection = self.db[\"query_embeddings\"]",
        "size": 356,
        "parent-class": "DBHelper",
        "function_name": "__init__"
    },
    {
        "id": "0619684f-b082-45cf-b3e5-7870bdaba6c3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 15,
        "end_line": 33,
        "content": "async def connect(self):\n        try:\n            if self.client is None:\n                self.client = AsyncIOMotorClient(\n                    settings.MONGODB_URL,\n                    maxPoolSize=1000,\n                    minPoolSize=50,\n                    maxIdleTimeMS=50000,\n                    connectTimeoutMS=20000,\n                )\n\n                self.db = self.client[settings.DATABASE_NAME]\n                await self.client.admin.command(\"ping\")\n                await self.create_collections()\n\n        except Exception as e:\n            if self.client:\n                await self.disconnect()\n            raise",
        "size": 627,
        "parent-class": "DBHelper",
        "function_name": "connect"
    },
    {
        "id": "a56f0e1d-3216-4af9-b937-eaa9463c826f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 35,
        "end_line": 40,
        "content": "async def create_collections(self):\n        required_collections = [\"raw_data\", \"gt_data\"]\n        existing_collections = await self.db.list_collection_names()\n        for collection in required_collections:\n            if collection not in existing_collections:\n                await self.db.create_collection(collection)",
        "size": 322,
        "parent-class": "DBHelper",
        "function_name": "create_collections"
    },
    {
        "id": "eb6669e6-d8b1-4dcb-83c7-079ae9d1d0a8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 42,
        "end_line": 45,
        "content": "async def get_db(self):\n        if self.client is None:\n            await self.connect()\n        return self.db",
        "size": 111,
        "parent-class": "DBHelper",
        "function_name": "get_db"
    },
    {
        "id": "5ddd810c-a469-4d99-8cdc-376e6d0d434e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 47,
        "end_line": 51,
        "content": "async def disconnect(self):\n        if self.client:\n            self.client.close()\n            self.client = None\n            self.db = None",
        "size": 141,
        "parent-class": "DBHelper",
        "function_name": "disconnect"
    },
    {
        "id": "6a5e40a4-8db3-4574-aa23-565345f0a572",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/settings.py",
        "file_name": "settings.py",
        "start_line": 1,
        "end_line": 1,
        "content": "from pydantic_settings import BaseSettings",
        "size": 42,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5d39f140-43c7-4650-9758-fa9032760763",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import os\nimport json\nimport logging\nfrom datetime import datetime",
        "size": 66,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "0c7c5d9c-0d44-4516-bc67-5e8b577743bf",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 8,
        "end_line": 27,
        "content": "def format(self, record):\n        log_entry = {\n            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n            \"levelname\": record.levelname,\n            \"module\": record.module,\n            \"funcName\": record.funcName,\n            \"lineno\": record.lineno\n        }\n\n        message = record.getMessage()\n        try:\n            parsed_message = json.loads(message)\n            log_entry[\"message\"] = json.dumps(parsed_message, indent=4, ensure_ascii=False)\n        except json.JSONDecodeError:\n            log_entry[\"message\"] = message\n        \n        if record.args:\n            log_entry[\"extra\"] = record.args\n            \n        return json.dumps(log_entry, ensure_ascii = False, indent=4)",
        "size": 718,
        "parent-class": "JSONFormatter",
        "function_name": "format"
    },
    {
        "id": "45de892d-8a6e-44ec-bebe-a229bb2a792b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 29,
        "end_line": 52,
        "content": "def setup_logger(name: str, log_file: str, log_dir: str = \"struct_logs\", level=logging.INFO) -> logging.Logger:\n    \"\"\"\n    Sets up a logger with a specified name and log file.\n    \n    Args:\n        name (str): The name of the logger.\n        log_file (str): The name of the log file.\n        log_dir (str): Directory where logs will be stored.\n        level (int): Logging level (default: logging.INFO).\n    \n    Returns:\n        logging.Logger: Configured logger instance.\n    \"\"\"\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    handler = logging.FileHandler(log_path)\n    handler.setFormatter(JSONFormatter())\n\n    logger.addHandler(handler)\n    return logger",
        "size": 772,
        "parent-class": null,
        "function_name": "setup_logger"
    },
    {
        "id": "d9181c55-0e8b-4ff9-a0d4-951f6f701b62",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nfrom typing import Dict, List\nimport httpx\nfrom app.config.settings import Settings\nfrom app.prompts import rag_generation\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers",
        "size": 226,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "510aa9ac-ebe9-4c21-8cae-9d0c970a78f7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 11,
        "end_line": 24,
        "content": "def __init__(self):\n        self.settings = Settings()\n        self.rag_generation = rag_generation\n        self.OPENAI_BASE_URL = self.settings.OPENAI_BASE_URL \n        self.model = self.settings.OPENAI_MODEL\n        self.openai_api_key = self.settings.OPENAI_API_KEY\n        self.OPENAI_CHAT_SUFFIX = \"chat/completions\"\n        self.openai_url = f\"{self.OPENAI_BASE_URL}/{self.OPENAI_CHAT_SUFFIX}\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )",
        "size": 742,
        "parent-class": "LLMUtils",
        "function_name": "__init__"
    },
    {
        "id": "99d24a28-e6f0-4e2c-861e-6d303629d906",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 26,
        "end_line": 53,
        "content": "async def _make_openai_request(\n        self, messages: List[Dict[str, str]], **params\n    ):\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.openai_api_key}\",\n        }\n\n        data = {\"model\": self.model, \"messages\": messages, **params}\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(\n                    self.openai_url, headers=headers, json=data\n                )\n                \n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {e.response.text}\")\n            raise HTTPException(detail = f\"error in openai call httpx error : {str(e)} - {e.response.text}\", status_code = e.response.status_code)\n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\n        except Exception as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)",
        "size": 1271,
        "parent-class": "LLMUtils",
        "function_name": "_make_openai_request"
    },
    {
        "id": "84e8a99d-91b2-4e54-9b10-0796ab673dc5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 55,
        "end_line": 80,
        "content": "async def generate_questions(self, chunk: str):\n        user_msg = f\"Text chunk:\\n{chunk}\"\n\n        response = await self._make_openai_request(\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": self.rag_generation.GENERATE_QUESTIONS_PROMPT,\n                },\n                {\"role\": \"user\", \"content\": user_msg}\n            ],\n            temperature=0.3,\n            max_tokens=512\n        )\n        print(json.dumps(response, indent=4))\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n\n\n        if \"error\" in response:\n            return [\"Could not generate questions - API error\"]\n\n        content = response[\"choices\"][0][\"message\"][\"content\"]\n        return [q.strip() for q in content.split(\"\\n\") if q.strip()]",
        "size": 841,
        "parent-class": "LLMUtils",
        "function_name": "generate_questions"
    },
    {
        "id": "9d225a52-600e-4310-b999-a1b7848d8334",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 82,
        "end_line": 123,
        "content": "async def generate_multi_chunk_question(self, data: dict):\n        formatted_chunks = \"\\n\\n\".join(\n            f\"Chunk ID: {c['_id']}\\nContent: {c['text']}\" for c in data[\"chunks\"]\n        )\n        if data[\"file_type\"] == 'Text':\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_TXT\n        if data[\"file_type\"] == \"Code\":\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_CODE\n\n        messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": content,\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Text chunks:\\n{formatted_chunks}\"\n                }\n            ]\n        \n        response = await self._make_openai_request(\n            messages=messages,\n            temperature=0.7,\n            max_tokens=1024\n        )\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n        if \"error\" in response:\n            return {\n                \"question\": \"Could not generate question - API error\",\n                \"relevant_ids\": [\n                    data[\"chunks\"][0][\"_id\"], \n                    data[\"chunks\"][1][\"_id\"]\n                ] if len(data[\"chunks\"]) >= 2 else []\n            }\n        loggers[\"main\"].info(f\"response_json from generate multi : {response}\")\n\n        raw_content = response[\"choices\"][0][\"message\"][\"content\"]\n        loggers[\"main\"].info(raw_content)\n        return self._parse_multi_chunk_response(raw_content, data)",
        "size": 1537,
        "parent-class": "LLMUtils",
        "function_name": "generate_multi_chunk_question"
    },
    {
        "id": "a59ef180-6598-4039-bdc7-24f9573357b1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 125,
        "end_line": 145,
        "content": "def _parse_multi_chunk_response(self, raw_content: str, chunks: List[Dict]):\n        try:\n            questions = json.loads(raw_content)\n            if not isinstance(questions, list):\n                raise ValueError(\"Expected a list of questions\")\n            \n            result_list = []\n            for q in questions:\n                if \"question\" not in q or \"chunk_ids\" not in q:\n                    raise ValueError(\"Missing required fields in question item\")\n                    \n                result_list.append({\n                    \"question\": q[\"question\"].strip(),\n                    \"relevant_ids\": [str(id) for id in q[\"chunk_ids\"]]\n                })\n            return result_list\n        except (json.JSONDecodeError, ValueError):\n            return {\n                \"question\": raw_content.strip(),\n                \"relevant_ids\": [c[\"_id\"] for c in chunks[:2]]\n            }",
        "size": 901,
        "parent-class": "LLMUtils",
        "function_name": "_parse_multi_chunk_response"
    },
    {
        "id": "f54e9a76-00dc-46a3-8cf8-b1ae06d1d949",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi.responses import JSONResponse\nfrom functools import wraps\nfrom fastapi import status",
        "size": 97,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "99c67b61-8d2f-4de2-beb2-f0c2a320c323",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 5,
        "end_line": 21,
        "content": "def handle_exceptions(func):\n    \"\"\"A decorator to catch exceptions and return a consistent JSON error response.\"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except Exception as e:\n            return JSONResponse(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                content={\n                    \"data\": {},\n                    \"statuscode\": 500,\n                    \"detail\": \"An internal server error occurred.\",\n                    \"error\": str(e),\n                },\n            )\n    return wrapper",
        "size": 617,
        "parent-class": null,
        "function_name": "handle_exceptions"
    },
    {
        "id": "cd226d67-038e-4e9e-b0b5-e1fd99bbc2ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers",
        "size": 118,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "45bf5e0a-8222-4e98-97c3-ca36ca6b730f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 6,
        "end_line": 9,
        "content": "def __init__(self):\n        self.ground_truth_collection = db_helper.gt_data\n        self.raw_collection = db_helper.raw_data\n        self.index_info_collection = db_helper.index_upsert_collection",
        "size": 196,
        "parent-class": "IndexRepository",
        "function_name": "__init__"
    },
    {
        "id": "a0678a1e-d813-4c64-a229-30ebce7c9d99",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 11,
        "end_line": 27,
        "content": "async def fetch_ground_truth(self, query):\n\n        query = {\"question\": query}\n\n        ground_truth_doc = await self.ground_truth_collection.find_one(query)\n\n        ground_truth_ids = []\n        for x in ground_truth_doc[\"chunks\"]:\n            ground_truth_ids.append(x[\"_id\"])\n            \n        ground_truth = []\n        for _id in ground_truth_ids:\n            chunk = await self.raw_collection.find_one({\"_id\": _id})\n\n            ground_truth.append({\"id\": _id, \"chunk\": chunk[\"text_content\"]})\n\n        return ground_truth",
        "size": 532,
        "parent-class": "IndexRepository",
        "function_name": "fetch_ground_truth"
    },
    {
        "id": "25bf7f4c-dd10-4aa7-8491-277f65ee75bd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 29,
        "end_line": 56,
        "content": "async def get_namespace_and_host(\n        self, index_name: str, embedding_model: str, filename: str\n    ):\n\n        query = {\n            \"index_name\": index_name,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": filename,\n                    \"details.embedding_model\": embedding_model,\n                }\n            },\n        }\n\n        document = await self.index_info_collection.find_one(query)\n        \n        if document is None:\n            return None, None\n        \n        namespace_name = None\n        namespaces = document[\"namespaces\"]\n        for namespace in namespaces:\n            if namespace['details']['embedding_model'] == embedding_model and namespace['details']['filename'] == filename:\n                namespace_name = namespace[\"name\"]\n\n        host = document[\"index_host\"]\n\n        return namespace_name, host",
        "size": 889,
        "parent-class": "IndexRepository",
        "function_name": "get_namespace_and_host"
    },
    {
        "id": "2f0a394c-7b24-4fc2-b0db-7b77e7e5fe34",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 58,
        "end_line": 84,
        "content": "async def fetch_questions(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.ground_truth_collection.find_one(file_query)\n            \n            if not file_doc:\n                raise HTTPException(status_code=404, detail=\"File not found\")\n            \n            questions_with_ground_truth = []\n\n            data_doc = file_doc[\"data\"]\n\n            for document in data_doc:\n                question = document['question']\n                ground_truth_chunk_ids = [chunk['_id'] for chunk in document['chunks']]\n                questions_with_ground_truth.append({\n                    'question': question,\n                    'ground_truth_chunk_ids': ground_truth_chunk_ids\n                })\n            loggers[\"main\"].info(f\"length of questions with ground truth : {len(questions_with_ground_truth)}\")\n\n            return questions_with_ground_truth\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1062,
        "parent-class": "IndexRepository",
        "function_name": "fetch_questions"
    },
    {
        "id": "aaa2f634-fc3e-4808-93fb-b904be545d9e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 86,
        "end_line": 96,
        "content": "async def fetch_total_chunks(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.raw_collection.find_one(file_query)\n            \n            return len(file_doc[\"data\"])\n            \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 377,
        "parent-class": "IndexRepository",
        "function_name": "fetch_total_chunks"
    },
    {
        "id": "0e8ef434-4171-422b-90b6-5af573eb2af1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 98,
        "end_line": 137,
        "content": "async def fetch_user_previous_configurations(self):\n\n        collection_names = await db_helper.db.list_collection_names()\n        if \"index_upsert\" not in collection_names:\n            return {\"message\": \"You have no previous configurations.\"}\n    \n        count = await self.index_info_collection.count_documents({})\n        if count == 0:\n            return {\"message\": \"You have no previous configurations.\"}\n        \n\n\n        try:\n            cursor = self.index_info_collection.find(\n                {}, \n                {\n                    \"index_name\" : 1, \n                    \"dimension\" : 1, \n                    \"similarity_metric\" : 1, \n                    \"namespaces.details.filename\" : 1, \n                    \"namespaces.details.embedding_model\" : 1\n                }\n            )\n            \n            configurations = []\n            async for doc in cursor:\n                configurations.append(\n                    {\n                        \"index_name\" : doc[\"index_name\"],\n                        \"dimension\" : doc[\"dimension\"],\n                        \"similarity_metric\" : doc[\"similarity_metric\"],\n                        \"filename\" : [namespace[\"details\"][\"filename\"] for namespace in doc[\"namespaces\"]],\n                        \"embedding_model\" : [namespace[\"details\"][\"embedding_model\"] for namespace in doc[\"namespaces\"]]\n                    }\n                )\n                \n            return configurations\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Error in fetching previous configurations: {str(e)}\")",
        "size": 1602,
        "parent-class": "IndexRepository",
        "function_name": "fetch_user_previous_configurations"
    },
    {
        "id": "ccdd8945-80b0-45bd-9458-3ff575555108",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers",
        "size": 126,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "aaf77c32-257b-4385-a16a-dbdf6fafb2cc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.raw_data",
        "size": 64,
        "parent-class": "RawDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "23be6e23-4a79-444e-a546-de1465563dde",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})",
        "size": 79,
        "parent-class": "RawDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "3f8dd7f0-efaa-40f4-a410-e7877939966c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 13,
        "end_line": 14,
        "content": "async def insert_documents(self, document: dict):\n        await self.collection.insert_one(document)",
        "size": 100,
        "parent-class": "RawDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "eab8c954-f979-4781-a238-8821cd5edf1f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 16,
        "end_line": 21,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)",
        "size": 209,
        "parent-class": "RawDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "4787a2c2-3762-4d4f-9d74-b9aa3b72de81",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 23,
        "end_line": 41,
        "content": "async def fetch_texts_by_ids(self,file_name: str, ids: list):\n        try:\n            \n            query = {\"file_name\": file_name}\n            ids_list = []\n            # projection = {\"data.$\": 1}  # Use positional projection to get the matching element\n            document = await self.collection.find_one(query)\n            for doc in document[\"data\"]:\n                if doc[\"_id\"] in ids:\n                    ids_list.append(doc[\"text\"])\n            # print(document)\n            return ids_list\n            # if document and \"data\" in document and document[\"data\"]:\n            #     return document[\"data\"][0][\"text\"]\n            \n\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside fetch_texts_by_ids error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))",
        "size": 851,
        "parent-class": "RawDataRepo",
        "function_name": "fetch_texts_by_ids"
    },
    {
        "id": "01fbc3bb-393f-4677-810c-029f31d32333",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.queryembed import QueryEmbeddings\nimport time\nfrom datetime import datetime, timezone\nfrom app.utils.logging_util import loggers",
        "size": 227,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5806767a-5ee1-43e1-9b45-85cfdda64826",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 13,
        "end_line": 14,
        "content": "def __init__(self):\n        self.collection = db_helper.query_embeddings_collection",
        "size": 83,
        "parent-class": "QueryRepository",
        "function_name": "__init__"
    },
    {
        "id": "2648ac32-e28f-4e81-9daa-279be781adcd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 16,
        "end_line": 57,
        "content": "async def insert_or_update_embeddings(\n        self,\n        query_embeddings: QueryEmbeddings\n    ):\n        \"\"\"\n        Upsert embeddings - either update existing document or create new one\n        \"\"\"\n        try:\n            # Construct the unique identifier for the document\n            filter_query = {\n                \"filename\": query_embeddings.filename,\n                \"embedding_model\": query_embeddings.embedding_model,\n                \"dimension\": query_embeddings.dimension\n            }\n            \n            # Prepare the update operation\n            update_query = {\n                \"$set\": {\n                    \"filename\": query_embeddings.filename,\n                    \"embedding_model\": query_embeddings.embedding_model,\n                    \"dimension\": query_embeddings.dimension,\n                    \"updated_at\": datetime.now(timezone.utc).isoformat()\n                },\n                \"$addToSet\": {\n                    \"questions\": {\n                        \"$each\": query_embeddings.questions\n                    }\n                }\n            }\n            \n            # Perform upsert operation\n            result = await self.collection.update_one(\n                filter_query, \n                update_query, \n                upsert=True\n            )\n            \n            # Return the upserted or updated document's ID\n            return str(result.upserted_id) if result.upserted_id else str(result.modified_count)\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in upserting query embeds: {str(e)}\")",
        "size": 1600,
        "parent-class": "QueryRepository",
        "function_name": "insert_or_update_embeddings"
    },
    {
        "id": "358d00d3-e8a6-40a2-8fc1-4ab35ba1ca1e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 70,
        "end_line": 111,
        "content": "async def retrieve_question_embeddings(\n        self,\n        file_name: str,\n        embed_model: str,\n        dimension: int,\n        question_text: str \n    ):\n        query = {\n            \"filename\": file_name,\n            \"embedding_model\": embed_model,\n            \"dimension\": dimension,\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        projection = {\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        \n        try:\n            s = time.time()\n            document = await self.collection.find_one(query, projection)\n            if document is None:\n                return None\n            \n            matching_questions = document.get('questions', [])\n            if matching_questions:\n                return matching_questions[0].get('embedding')\n            e = time.time()\n            loggers[\"main\"].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n            return None\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in retrieving query embeds in motor : {str(e)}\")",
        "size": 1287,
        "parent-class": "QueryRepository",
        "function_name": "retrieve_question_embeddings"
    },
    {
        "id": "6ee45552-99a1-4a96-b1ca-413c84586811",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.indexupsert import IndexUpsert",
        "size": 129,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "510d322e-9db9-4660-8353-69006971b6d0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self):\n        self.collection = db_helper.index_upsert_collection",
        "size": 79,
        "parent-class": "IndexUpsertRepository",
        "function_name": "__init__"
    },
    {
        "id": "4c93a994-2895-4516-87ce-7178560caba8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 12,
        "end_line": 30,
        "content": "async def find_matching_index_upsert(\n        self,\n        dimension: str,\n        similarity_metric: str,\n        file_name: str,\n        embed_model: str,\n    ):\n        query = {\n            \"dimension\": dimension,\n            \"similarity_metric\": similarity_metric,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": file_name,\n                    \"details.embedding_model\": embed_model,\n                }\n            },\n        }\n        document = await self.collection.find_one(query)\n        return document",
        "size": 565,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index_upsert"
    },
    {
        "id": "64960cd9-3087-4e95-86b1-62bd87e19dbc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 32,
        "end_line": 35,
        "content": "async def find_matching_index(self, dimension: str, similarity_metric: str):\n        query = {\"dimension\": dimension, \"similarity_metric\": similarity_metric}\n        document = await self.collection.find_one(query)\n        return document",
        "size": 238,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index"
    },
    {
        "id": "f5d4f533-23cb-4d19-803e-d38f7e14e0da",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 37,
        "end_line": 83,
        "content": "async def add_index_upsert_details(self, indexupsert: IndexUpsert):\n        try:\n            # Check if an index with same dimension and similarity_metric exists\n            existing_index = await self.collection.find_one(\n                {\n                    \"dimension\": indexupsert.dimension,\n                    \"similarity_metric\": indexupsert.similarity_metric,\n                }\n            )\n\n            if existing_index:\n                # Get the first namespace from the new data\n                new_namespace = indexupsert.namespaces[0]\n\n                # Check if namespace with same name already exists\n                namespace_exists = any(\n                    ns[\"name\"] == new_namespace.name\n                    for ns in existing_index.get(\"namespaces\", [])\n                )\n\n                if namespace_exists:\n                    # Namespace already exists, no need to update\n                    return str(existing_index[\"_id\"])\n\n                # Add new namespace to existing index\n                result = await self.collection.update_one(\n                    {\"_id\": existing_index[\"_id\"]},\n                    {\n                        \"$push\": {\n                            \"namespaces\": {\n                                \"name\": new_namespace.name,\n                                \"details\": {\n                                    \"filename\": new_namespace.details.filename,\n                                    \"embedding_model\": new_namespace.details.embedding_model,\n                                },\n                            }\n                        }\n                    },\n                )\n                return str(existing_index[\"_id\"])\n            else:\n                # Create new index document\n                index_upsert_dict = indexupsert.to_dict()\n                result = await self.collection.insert_one(index_upsert_dict)\n                return str(result.inserted_id)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 2021,
        "parent-class": "IndexUpsertRepository",
        "function_name": "add_index_upsert_details"
    },
    {
        "id": "07a70dfd-f464-4e0f-945b-ce74b36183a2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from app.config.database import db_helper\nimport random\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers",
        "size": 140,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "41234e28-5d6e-4e6d-93c3-443efda05e66",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.gt_data",
        "size": 63,
        "parent-class": "GTDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "6d775aa9-1c84-4493-a761-24800c125d2d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})",
        "size": 79,
        "parent-class": "GTDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "90c3941e-157e-4474-a793-54e7dff6564e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 13,
        "end_line": 17,
        "content": "async def insert_documents(self, document: dict):\n        try :\n            await self.collection.insert_one(document)\n        except Exception as e :\n            loggers[\"main\"].info(f\"inside insert documents : {str(e)}\")",
        "size": 222,
        "parent-class": "GTDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "5091c7e7-4ca7-477d-b43f-ef2f28131858",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 19,
        "end_line": 24,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)",
        "size": 209,
        "parent-class": "GTDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "dd0fda1f-a8cb-46bb-bb28-17a373246f50",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 27,
        "end_line": 49,
        "content": "async def get_random_question(self, file_name: str):\n        try:\n            document = await self.collection.find_one({\"file_name\": file_name})\n            if not document:\n                return {\"message\": \"ground truth file not found in database\"}\n            \n            data = document.get(\"data\", [])\n            if not data:\n                return {\"message\": \"no data found in ground truth file\"}\n            \n            total_length = len(data)\n            random_number = random.randint(0, total_length - 1)\n            index = random_number % total_length\n\n            chunks = data[index].get(\"chunks\", [])\n            ids = []\n            for chunk in chunks:\n                ids.append(chunk.get(\"_id\", \"\"))\n            selected_question_gt = data[index]\n            return selected_question_gt, ids\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside get_random_question error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))",
        "size": 1028,
        "parent-class": "GTDataRepo",
        "function_name": "get_random_question"
    },
    {
        "id": "e30aecdc-eb46-4fd6-b219-29c1c9e60fe0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nfrom pydantic.config import ConfigDict\nfrom pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nimport logging",
        "size": 239,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "add21e8d-98b3-4d59-8091-38daf0eee066",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 39,
        "end_line": 42,
        "content": "def validate_similarity_metric(cls, value):\n        if value.lower() not in cls.ALLOWED_METRICS:\n            raise ValueError(f\"Invalid similarity_metric '{value}'. Must be one of {cls.ALLOWED_METRICS}.\")\n        return value.lower()  # Normalize to lowercase",
        "size": 259,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_similarity_metric"
    },
    {
        "id": "6ba80763-f5f6-4c30-b0eb-4409830d774b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 47,
        "end_line": 59,
        "content": "def validate_dimension(cls, value, info):\n        # Use info.data to access the context dictionary containing input data\n        embed_model = info.data.get(\"embed_model\")\n\n        if not embed_model:\n            raise ValueError(\"embed_model must be provided before validating dimension.\")\n\n        valid_dimensions = cls.MODEL_TO_DIMENSIONS.get(embed_model)\n\n        if valid_dimensions and value not in valid_dimensions:\n            raise ValueError(f\"Invalid dimension '{value}' for model '{embed_model}'. Must be one of {valid_dimensions}.\")\n\n        return value",
        "size": 568,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_dimension"
    },
    {
        "id": "85376e00-6632-41d6-9442-9be6412aea6d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/file_upload_schema.py",
        "file_name": "file_upload_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Optional",
        "size": 65,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "afcac3ff-d33b-4575-bcea-0ffc81da75fe",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/query_schema.py",
        "file_name": "query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Optional, Literal\nfrom pydantic import BaseModel, Field",
        "size": 74,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "bcab1d5b-74fd-42dc-8e09-ca7dd1faa5f7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/random_query_schema.py",
        "file_name": "random_query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal, Optional",
        "size": 74,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "1276d378-6b29-4a0f-ad24-155b0e4ede47",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/reranking_schema.py",
        "file_name": "reranking_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Any, Dict\nfrom pydantic import BaseModel",
        "size": 59,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "58682ffb-2492-4cbf-9b6e-900c1e77dbbd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from datetime import datetime\nfrom typing import Any, Dict, List\nfrom bson import ObjectId",
        "size": 90,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "bbfdca60-a9b3-4f7d-a3c6-6c9595f61a7b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 8,
        "end_line": 10,
        "content": "def __init__(self, filename: str, embedding_model: str):\n        self.filename = filename\n        self.embedding_model = embedding_model",
        "size": 136,
        "parent-class": "NamespaceDetails",
        "function_name": "__init__"
    },
    {
        "id": "5af877f0-1c6b-4dd0-8f9d-b28a8435eb44",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 12,
        "end_line": 16,
        "content": "def to_dict(self) -> Dict[str, str]:\n        return {\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n        }",
        "size": 155,
        "parent-class": "NamespaceDetails",
        "function_name": "to_dict"
    },
    {
        "id": "c7287209-aa6a-452b-b91f-a4fb434f4789",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 20,
        "end_line": 22,
        "content": "def __init__(self, name: str, filename: str, embedding_model: str):\n        self.name = name\n        self.details = NamespaceDetails(filename, embedding_model)",
        "size": 159,
        "parent-class": "Namespace",
        "function_name": "__init__"
    },
    {
        "id": "1be83662-3cf9-42ab-b8cd-92cc73ec245b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 24,
        "end_line": 25,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\"name\": self.name, \"details\": self.details.to_dict()}",
        "size": 106,
        "parent-class": "Namespace",
        "function_name": "to_dict"
    },
    {
        "id": "3b51bc7d-575e-47ce-9165-ba5ee169d93b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 29,
        "end_line": 43,
        "content": "def __init__(\n        self,\n        index_name: str,\n        index_host: str,\n        dimension: int,\n        similarity_metric: str,\n    ):\n        self._id = ObjectId()\n        self.index_name = index_name\n        self.index_host = index_host\n        self.dimension = dimension\n        self.similarity_metric = similarity_metric\n        self.created_at = datetime.utcnow()\n        self.updated_at = datetime.utcnow()\n        self.namespaces: List[Namespace] = []",
        "size": 464,
        "parent-class": "IndexUpsert",
        "function_name": "__init__"
    },
    {
        "id": "ac62db38-aa27-4ff1-8307-096651207102",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 45,
        "end_line": 47,
        "content": "def add_namespace(self, namespace: Namespace) -> None:\n        self.namespaces.append(namespace)\n        self.updated_at = datetime.utcnow()",
        "size": 140,
        "parent-class": "IndexUpsert",
        "function_name": "add_namespace"
    },
    {
        "id": "ae6108cc-bd40-4000-89de-f7e6c19c40b2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 49,
        "end_line": 61,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"_id\": str(self._id),\n            \"index_name\": self.index_name,\n            \"index_host\": self.index_host,\n            \"dimension\": self.dimension,\n            \"similarity_metric\": self.similarity_metric,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n            \"namespaces\": [\n                namespace.to_dict() for namespace in self.namespaces\n            ],\n        }",
        "size": 503,
        "parent-class": "IndexUpsert",
        "function_name": "to_dict"
    },
    {
        "id": "c1f384f1-a8e6-4bd4-8974-ac491fd2c9a0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 64,
        "end_line": 103,
        "content": "def from_dict(cls, data: Dict[str, Any]) -> \"IndexUpsert\":\n        index = cls(\n            index_name=data[\"index_name\"],\n            index_host=data[\"index_host\"],\n            dimension=data[\"dimension\"],\n            similarity_metric=data[\"similarity_metric\"],\n        )\n\n        # Set ID if it exists\n        if \"_id\" in data:\n            if isinstance(data[\"_id\"], str):\n                index._id = ObjectId(data[\"_id\"])\n            else:\n                index._id = data[\"_id\"]\n\n        # Set dates if they exist\n        if \"created_at\" in data:\n            if isinstance(data[\"created_at\"], str):\n                index.created_at = datetime.fromisoformat(data[\"created_at\"])\n            else:\n                index.created_at = data[\"created_at\"]\n\n        if \"updated_at\" in data:\n            if isinstance(data[\"updated_at\"], str):\n                index.updated_at = datetime.fromisoformat(data[\"updated_at\"])\n            else:\n                index.updated_at = data[\"updated_at\"]\n\n        # Add namespaces if they exist\n        if \"namespaces\" in data:\n            for namespace_data in data[\"namespaces\"]:\n                details = namespace_data[\"details\"]\n                namespace = Namespace(\n                    name=namespace_data[\"name\"],\n                    filename=details[\"filename\"],\n                    embedding_model=details[\"embedding_model\"],\n                )\n                index.namespaces.append(namespace)\n\n        return index",
        "size": 1461,
        "parent-class": "IndexUpsert",
        "function_name": "from_dict"
    },
    {
        "id": "e2492563-1246-419a-86d5-65849b955ae6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from typing import List, Union\nimport numpy as np\nfrom bson import ObjectId\nfrom datetime import datetime, timezone",
        "size": 115,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "087c89a8-1bfe-4fce-bcde-dc4ce6545aab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 7,
        "end_line": 19,
        "content": "def __init__(self, \n                 filename: str, \n                 embedding_model: str, \n                 dimension: int, \n                 questions: List[dict] = None):\n        \n        self._id = ObjectId()\n        self.filename = filename\n        self.embedding_model = embedding_model\n        self.dimension = dimension\n        self.created_at = datetime.now(timezone.utc).isoformat()\n        self.updated_at = datetime.now(timezone.utc).isoformat()\n        self.questions = questions or []",
        "size": 499,
        "parent-class": "QueryEmbeddings",
        "function_name": "__init__"
    },
    {
        "id": "50ed08b1-7d77-4b06-b0c6-ba1eee150a10",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 21,
        "end_line": 35,
        "content": "def add_question(self, question_text: str, embedding: Union[List[float], np.ndarray]):\n        \n        # Ensure embedding is converted to a list\n        if isinstance(embedding, np.ndarray):\n            embedding = embedding.tolist()\n        \n        # Validate embedding dimension\n        if len(embedding) != self.dimension:\n            raise ValueError(f\"Embedding must have {self.dimension} dimensions\")\n        \n        question = {\n            \"question_text\": question_text,\n            \"embedding\": embedding\n        }\n        self.questions.append(question)",
        "size": 567,
        "parent-class": "QueryEmbeddings",
        "function_name": "add_question"
    },
    {
        "id": "e2d7d825-9401-4a17-9233-3df8537617fc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 37,
        "end_line": 47,
        "content": "def to_dict(self) -> dict:\n        \n        return {\n            \"_id\": str(self._id),\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n            \"dimension\": self.dimension,\n            \"questions\": self.questions,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n        }",
        "size": 380,
        "parent-class": "QueryEmbeddings",
        "function_name": "to_dict"
    },
    {
        "id": "a9edf828-a287-4283-aded-2bd7875fcb5b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\nfrom app.usecases.file_upload_usecase import FileUploadUseCase\nimport logging",
        "size": 171,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "a8c9917a-192b-4cd0-8413-91c9730770ea",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: FileUploadUseCase = Depends()):\n        self.usecase = usecase",
        "size": 90,
        "parent-class": "FileUploadController",
        "function_name": "__init__"
    },
    {
        "id": "3422e77b-0e4d-41ef-a6a4-e570ed9a9ab8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def upload_files(self, request_data: dict):\n        return await self.usecase.execute(request_data)",
        "size": 105,
        "parent-class": "FileUploadController",
        "function_name": "upload_files"
    },
    {
        "id": "875dc66f-dd11-4c6d-923d-59cb375cd410",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.usecases.reranking_usecase import RerankingUseCase",
        "size": 184,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5a7d1858-4a6f-4d98-95cc-0e6797aaf247",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "def __init__(self, reranking_usecase: RerankingUseCase = Depends()):\n        self.reranking_usecase = reranking_usecase",
        "size": 119,
        "parent-class": "RerankingController",
        "function_name": "__init__"
    },
    {
        "id": "da6cc60c-d4d9-41ff-94e8-8e18615ffcc7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 14,
        "end_line": 17,
        "content": "async def rerank_documents(\n        self, request: RerankingRequest\n    ) -> RerankingResponse:\n        return await self.reranking_usecase.execute(request)",
        "size": 156,
        "parent-class": "RerankingController",
        "function_name": "rerank_documents"
    },
    {
        "id": "39e9b297-7103-49d5-a55b-b151fafe6532",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.index_upsert_usecase import IndexUpsertUseCase",
        "size": 92,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "48d20e65-d10b-4129-9cdc-4ff3b95a4c1b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self, index_upsert_usecase=Depends(IndexUpsertUseCase)):\n        self.index_upsert_usecase = index_upsert_usecase",
        "size": 126,
        "parent-class": "IndexUpsertController",
        "function_name": "__init__"
    },
    {
        "id": "4a6e9ad3-a965-4a77-907d-ab9725382a17",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 10,
        "end_line": 12,
        "content": "async def index_upsert(self, request):\n\n        return await self.index_upsert_usecase.index_upsert(request)",
        "size": 108,
        "parent-class": "IndexUpsertController",
        "function_name": "index_upsert"
    },
    {
        "id": "c1d853de-01a8-4351-a35e-eade5969d5fc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.usecases.query_usecase import QueryUseCase",
        "size": 144,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "26b1b040-2489-4ba0-8f90-313fca668463",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: QueryUseCase = Depends()):\n        self.query_usecase = usecase",
        "size": 91,
        "parent-class": "QueryController",
        "function_name": "__init__"
    },
    {
        "id": "97058242-466f-425e-8d25-924671d559f8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def make_query(self, request: QueryEndPointRequest):\n        return await self.query_usecase.execute(request)",
        "size": 115,
        "parent-class": "QueryController",
        "function_name": "make_query"
    },
    {
        "id": "c3735477-2850-461a-bb71-8004e7870dc5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.config_usecase import ConfigUsecase",
        "size": 81,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "06a8d042-f1c9-451a-8821-f1a16e4ee93e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, usecase: ConfigUsecase = Depends()):\n        self.query_usecase = usecase",
        "size": 92,
        "parent-class": "ConfigurationController",
        "function_name": "__init__"
    },
    {
        "id": "803b4215-30f6-48d7-9707-d7bc7fbb5079",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "async def get_config(self):\n        return await self.query_usecase.get_config()",
        "size": 80,
        "parent-class": "ConfigurationController",
        "function_name": "get_config"
    },
    {
        "id": "e8f4b95d-91e1-4488-9b7e-29658e939a97",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.usecases.random_query_usecase import RandomQueryUseCase\nfrom app.models.schemas.random_query_schema import RandomQueryRequest",
        "size": 162,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b5192cf9-d551-4752-88dc-49a892c1a1e6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 8,
        "end_line": 9,
        "content": "def __init__(self, random_query_usecase: RandomQueryUseCase = Depends()):\n        self.random_query_usecase = random_query_usecase",
        "size": 130,
        "parent-class": "RandomQueryController",
        "function_name": "__init__"
    },
    {
        "id": "2d13c4ce-108b-425a-9c5e-595c9d2ec148",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "async def random_query(self, request: RandomQueryRequest):\n        return await self.random_query_usecase.random_query(request)",
        "size": 127,
        "parent-class": "RandomQueryController",
        "function_name": "random_query"
    },
    {
        "id": "3c72c493-259d-4f8e-b140-35abddb5dead",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.random_question_usecase import RandomQuestionUseCase",
        "size": 98,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "7c7b7c5b-c07e-47e1-93de-0ee4ea166740",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 8,
        "end_line": 9,
        "content": "def __init__(self, random_question_usecase: RandomQuestionUseCase = Depends()):\n        self.random_question_usecase = random_question_usecase",
        "size": 142,
        "parent-class": "RandomQuestionController",
        "function_name": "__init__"
    },
    {
        "id": "1752844d-1f37-40b9-b5d7-9fd666851ad9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "async def random_question(self, file_name: str):\n        return await self.random_question_usecase.random_question(file_name)",
        "size": 125,
        "parent-class": "RandomQuestionController",
        "function_name": "random_question"
    },
    {
        "id": "9f90dca6-29fc-4533-a7fd-7be11b16c4f3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.repositories.index_repository import IndexRepository",
        "size": 89,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "01c190d8-c6c9-46c1-adbe-b3ba5f2d1205",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, index_repository: IndexRepository = Depends()):\n        self.index_repository = index_repository",
        "size": 115,
        "parent-class": "ConfigUsecase",
        "function_name": "__init__"
    },
    {
        "id": "53e364f7-ead5-428e-aea3-acb698f66f72",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 9,
        "end_line": 13,
        "content": "async def get_config(self):\n        response = await self.index_repository.fetch_user_previous_configurations()\n        if response is None:\n            return {\"message\": \"No configurations found\"}\n        return response",
        "size": 222,
        "parent-class": "ConfigUsecase",
        "function_name": "get_config"
    },
    {
        "id": "057380e9-1147-4f51-8ff9-c736e5ed105e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import os\nimport json\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom fastapi import Depends, HTTPException\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.repositories.index_repository import IndexRepository\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.reranking_service import RerankerService\nfrom app.utils.logging_util import loggers",
        "size": 452,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "be407369-0d06-4050-9362-2f684d33f713",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 18,
        "end_line": 24,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        reranker_service: RerankerService = Depends(),\n    ):\n        self.reranker_service = reranker_service\n        self.index_repository = index_repository",
        "size": 242,
        "parent-class": "RerankingUseCase",
        "function_name": "__init__"
    },
    {
        "id": "0476063a-4b97-45bf-ba23-7c7a178bebea",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 26,
        "end_line": 90,
        "content": "async def execute(self, request: RerankingRequest) -> RerankingResponse:\n        \"\"\"\n        Execute the reranking use case by processing queries and documents \n        from the saved first_stage_retrieval.json file.\n\n        Args:\n            request: RerankingRequest containing model_name and top_n\n\n        Returns:\n            RerankingResponse with evaluation metrics\n        \"\"\"\n        try:\n            model_name = request.model_name\n            top_n = request.top_n\n            top_k=request.top_k\n\n            if top_n > top_k:\n                raise HTTPException(\n                    status_code=400, \n                    detail=f\"Invalid request: top_n ({top_n}) cannot be greater than top_k ({top_k}).\"\n                )\n\n            # Load first stage retrieval results\n            first_stage_file_path = \"results/first_stage_retrieval.json\"\n            if not os.path.exists(first_stage_file_path):\n                raise HTTPException(\n                    status_code=404, \n                    detail=\"First stage retrieval results not found. Run query_usecase first.\"\n                )\n                \n            with open(first_stage_file_path, \"r\") as f:\n                questions_data = json.load(f)\n                \n            # Process each question in parallel\n            tasks = [\n                self._process_question(question, model_name, top_n)\n                for question in questions_data\n            ]\n            \n            processed_questions = await asyncio.gather(*tasks)\n            \n            # Extract questions and evaluation metrics\n            questions, evaluation_metrics_list = zip(*processed_questions)\n            \n            # Calculate average metrics\n            with ThreadPoolExecutor() as executor:\n                average_evaluation_metrics = executor.submit(\n                    self.average_metrics,\n                    evaluation_metrics_list,\n                    top_n\n                ).result()\n                \n            # Save results\n            os.makedirs(\"results\", exist_ok=True)\n            with open(\"results/second_stage_retrieval.json\", \"w\") as f:\n                json.dump(list(questions), f, indent=4)\n                \n            with open(\"results/second_stage_evaluation.json\", \"w\") as f:\n                json.dump(average_evaluation_metrics, f, indent=4)\n                \n            return RerankingResponse(evaluation_metrics=average_evaluation_metrics)\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking execution: {str(e)}\", exc_info=True)\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 2632,
        "parent-class": "RerankingUseCase",
        "function_name": "execute"
    },
    {
        "id": "2f9fa06f-21a8-44de-8a7b-61fa4ed7760f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 92,
        "end_line": 113,
        "content": "async def _process_question(self, question, model_name, top_n):\n        \"\"\"Process a single question with reranking.\"\"\"\n        try:\n            query = question[\"question\"]\n            documents = question[\"relevant_docs\"]\n            ground_truth_chunk_ids = question[\"ground_truth_chunk_ids\"]\n            \n            reranked_docs = await self._rerank_documents(model_name, query, documents, top_n)\n            \n            # Update the question with reranked documents\n            question[\"reranked_docs\"] = reranked_docs\n            \n            evaluation_metrics = self._calculate_evaluation_metrics(\n                reranked_docs, ground_truth_chunk_ids, top_n\n            )\n            \n            return question, evaluation_metrics\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error processing question '{query}': {str(e)}\", exc_info=True)\n            question[\"error\"] = str(e)\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 991,
        "parent-class": "RerankingUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "2fa6ceb2-e858-42af-8591-29112625ff2c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 115,
        "end_line": 217,
        "content": "async def _rerank_documents(self, model_name, query, documents, top_n):\n        \"\"\"Rerank documents using the specified reranker.\"\"\"\n\n        try:\n            pinecone_models = [\n                \"cohere-rerank-3.5\",\n                \"bge-reranker-v2-m3\",\n                \"pinecone-rerank-v0\",\n            ]\n            cohere_models = [\n                \"rerank-v3.5\",\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n            ]\n            jina_models = [\"jina-reranker-v2-base-multilingual\"]\n            voyage_models=[\"rerank-lite-1\",\"rerank-1\",\"rerank-2\"]\n            \n            # Extract text from documents for non-Pinecone rerankers\n            docs_text = [doc[\"text\"] for doc in documents]\n            # Format documents for Pinecone reranker\n            pinecone_docs = [{\"text\": doc[\"text\"]} for doc in documents]\n            \n            results = []\n            \n            # Determine which reranker to use based on the model name\n            if model_name.lower() in pinecone_models:\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model_name, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    # Find the original document to preserve the id\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            elif model_name.lower() in cohere_models:\n                reranking_result = await self.reranker_service.cohere_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n                        \n            elif model_name.lower() in jina_models:\n                reranking_result = await self.reranker_service.jina_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n\n            elif model_name.lower() in voyage_models:\n                reranking_result = await self.reranker_service.voyage_rerank(\n                    model_name,query,docs_text,top_n\n                )\n                for result in reranking_result.get(\"data\",[]):\n                    idx=result.get(\"index\",0)\n                    if 0<=idx <len(documents):\n                        results.append({\n                            \"id\":documents[idx][\"id\"],\n                            \"text\":documents[idx][\"text\"],\n                            \"score\":result.get(\"relevance_score\",0.0)\n                        })\n                        \n            else:\n                # Default to Pinecone\n                model = \"bge-reranker-v2-m3\"\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            return results\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 4639,
        "parent-class": "RerankingUseCase",
        "function_name": "_rerank_documents"
    },
    {
        "id": "f9799f92-e944-499a-81d0-fc8af0b6a9ee",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 219,
        "end_line": 260,
        "content": "def _calculate_evaluation_metrics(self, retrieved_docs, ground_truth_ids, top_n):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n        return {\n            \"precision_at_k\": EvaluationService.precision_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"recall_at_k\": EvaluationService.recall_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids, \n                k=top_n\n            ),\n            \"bpref\": EvaluationService.bpref(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids\n            ),\n            \"mrr\": EvaluationService.reciprocal_rank(\n            retrieved_docs=retrieved_docs,\n            ground_truth=ground_truth_ids\n            ),\n            \"map\": EvaluationService.mean_average_precision(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n\n            ),\n        }",
        "size": 1710,
        "parent-class": "RerankingUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "a89fe188-2309-4b31-8ef0-9950b666ff15",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 262,
        "end_line": 314,
        "content": "def average_metrics(self, metrics_list, top_n):\n        \"\"\"Calculate average metrics across all questions.\"\"\"\n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_n + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n    \n        avg_dict = sum_dict.copy()\n        \n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    for sub_key, sub_value in value.items():\n                        if sub_key in sum_dict.get(key, {}):\n                            sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] if count_dict[key] > 0 else 0.0\n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key] if count_dict[key] > 0 else 0.0\n        \n        return avg_dict",
        "size": 1918,
        "parent-class": "RerankingUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "229bd981-bba2-4949-95a3-0ab66be71dac",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 1,
        "end_line": 16,
        "content": "import os\nimport time\nimport json\nimport asyncio\nfrom typing import List\nfrom typing import List\nfrom fastapi import Depends, HTTPException\nfrom concurrent.futures import ThreadPoolExecutor\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.repositories.index_repository import IndexRepository\nfrom app.repositories.query_repository import QueryRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.pinecone_service import PineconeService\nfrom app.models.domain.queryembed import QueryEmbeddings\nfrom app.utils.logging_util import loggers",
        "size": 658,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "be56b4c1-bb35-40f6-abf0-f6d97cd5176c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 23,
        "end_line": 70,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        query_repository: QueryRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(),\n    ):\n        self.index_repository = index_repository\n        self.query_repository = query_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        self.semaphore = asyncio.Semaphore(50)\n        self.embedding_batch = 90\n        self.embedding_batch = 90",
        "size": 2088,
        "parent-class": "QueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "69797f6b-5e5e-4978-b29f-e43c525e094c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 72,
        "end_line": 145,
        "content": "async def execute(self, request_data: QueryEndPointRequest):\n        \"\"\"\n        Main execution function for processing query endpoint requests.\n        Breaks down the request handling into smaller, focused functions.\n        \"\"\"\n        \n        total_chunks = await self.index_repository.fetch_total_chunks(request_data.file_name)\n        if total_chunks < request_data.top_k:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Top K value cannot be greater than the total number of chunks: {total_chunks}\",\n            )\n        \n        try:\n            model = self.embeddings_provider_mapping[request_data.embedding_model]\n        except KeyError:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Invalid embedding model. Please provide a valid model.\",\n            )\n            \n        if request_data.dimension not in self.model_to_dimensions[request_data.embedding_model]:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Invalid dimension. Please provide a valid dimension for embedding model: {request_data.embedding_model}\",\n            )\n            \n        namespace_name, host = await self._get_namespace_and_host(request_data)\n        questions_with_ground_turth_chunks = await self.index_repository.fetch_questions(request_data.file_name)\n        \n        batches = [questions_with_ground_turth_chunks[i:min(i + self.embedding_batch, len(questions_with_ground_turth_chunks))]\n            for i in range(0, len(questions_with_ground_turth_chunks), self.embedding_batch)\n        ]\n        \n        embedding_tasks = [self._generate_batch_embeddings(batch, request_data) for batch in batches]\n        embeddings = await asyncio.gather(*embedding_tasks, return_exceptions=True)\n        \n        dense_embeddings = []\n        for x in embeddings:\n            dense_embeddings.extend(x)\n\n        loggers['evaluation'].info(f\"Total number of questions: {len(questions_with_ground_turth_chunks)}\")\n        loggers['evaluation'].info(f\"Total number of dense embeddings: {len(dense_embeddings)}\")\n\n        \n        s = time.time()\n        tasks = [self._process_question(embedding, question, namespace_name, host, request_data) for question, embedding in zip(questions_with_ground_turth_chunks, dense_embeddings)]\n        processed_questions = await asyncio.gather(*tasks)\n        \n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices: {e-s}\")\n        if processed_questions:\n            loggers['evaluation'].info(f\"processed_questions: {len(processed_questions)}\")\n        \n        questions, evaluation_metrics_list = zip(*processed_questions)\n\n        s = time.time()\n        with ThreadPoolExecutor() as executor:\n            average_evaluation_metrics = executor.submit(\n                self.average_metrics,\n                evaluation_metrics_list,\n                request_data.top_k,\n            ).result()\n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices (Average): {e-s}\")\n\n        os.makedirs(\"results\", exist_ok=True)\n        with open(\"results/first_stage_retrieval.json\", \"w\") as f:\n            json.dump(list(questions), f, indent=4)\n        \n        with open(\"results/first_stage_evaluation.json\", \"w\") as f:\n            json.dump(average_evaluation_metrics, f, indent=4)\n            \n        return {\"questions\": questions, \"evaluation_result\" : average_evaluation_metrics}",
        "size": 3529,
        "parent-class": "QueryUseCase",
        "function_name": "execute"
    },
    {
        "id": "5c3c7ff3-de74-4148-b6a4-8db83b93823e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 147,
        "end_line": 156,
        "content": "async def _generate_batch_embeddings(self, questions: List[dict], request_data: QueryEndPointRequest):\n        \n        questions = [question[\"question\"] for question in questions]\n        loggers['evaluation'].info(f'Generating embeddings for {len(questions)} questions.')\n        dense_embeddings = await self._generate_dense_embedding(request_data, questions)\n            \n        if not dense_embeddings:\n            raise HTTPException(status_code=500, detail=\"Error generating dense embedding.\")\n            \n        return dense_embeddings",
        "size": 546,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_batch_embeddings"
    },
    {
        "id": "4104201e-df02-4744-acbf-eb38e876dfec",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 159,
        "end_line": 203,
        "content": "async def _process_question(self, dense_embedding: list, question: dict, namespace_name: str, host:str, request_data: QueryEndPointRequest):\n        \n        async with self.semaphore:\n            \n            results = None\n            if request_data.is_hybrid:\n                results = await self._perform_hybrid_search(\n                    request_data, namespace_name, host, dense_embedding, question['question']\n                )\n            else:\n                results = await self._perform_regular_search(\n                    request_data, namespace_name, host, dense_embedding\n                )\n                \n            if not results:\n                loggers['evaluation'].info(\"No results found.\")\n                \n            relevant_docs_ids = []\n            relevant_docs = []\n            for result in results[\"matches\"]:\n                relevant_docs_ids.append(result[\"id\"])\n                relevant_docs.append(\n                    {\"id\": result[\"id\"], \"text\": result[\"metadata\"][\"text\"]}\n                )\n            \n            question['relevant_docs'] = relevant_docs\n            \n            ground_truth_chunk_ids = question['ground_truth_chunk_ids']\n            \n            if not relevant_docs_ids:\n                return {\n                    \"relevant_docs\": {},\n                    \"error\": \"No relevant documents found.\",\n                }\n\n            else:\n                with ThreadPoolExecutor() as executor:\n                    evaluation_metrics = executor.submit(\n                        self._calculate_evaluation_metrics,\n                        relevant_docs,\n                        ground_truth_chunk_ids,\n                        request_data.top_k\n                    ).result()\n                    \n            return question, evaluation_metrics",
        "size": 1802,
        "parent-class": "QueryUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "795eff03-f6dc-48a2-affe-83edb5ebe015",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 206,
        "end_line": 229,
        "content": "async def _get_namespace_and_host(self, request_data: QueryEndPointRequest):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{request_data.similarity_metric}-{request_data.dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    request_data.embedding_model,\n                    request_data.file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers['evaluation'].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 979,
        "parent-class": "QueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "00842196-4d7b-4b1f-8e5f-3c549d22ee64",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 231,
        "end_line": 304,
        "content": "async def _generate_dense_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate dense embedding for the query using the appropriate provider.\"\"\"\n\n        try:\n            s = time.perf_counter()\n            existing_embeddings = []\n            for question in questions:\n                already_embeddings = await self.query_repository.retrieve_question_embeddings(\n                    request_data.file_name,\n                    request_data.embedding_model,\n                    request_data.dimension,\n                    question,\n                )\n                e = time.perf_counter()\n                if already_embeddings:\n                    loggers['evaluation'].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n                    loggers['evaluation'].info(\"Embeddings already present in the database.\")  \n                    existing_embeddings.append(already_embeddings)\n            \n            loggers['evaluation'].info(f'Existing embeddings: {len(existing_embeddings)}')\n            if existing_embeddings and len(existing_embeddings) == len(questions):\n                return existing_embeddings\n\n            embedding_provider = None\n            for key, value in self.embeddings_provider_mapping.items():\n                if key == request_data.embedding_model:\n                    embedding_provider = value\n\n            embeddings = None\n            if embedding_provider == \"pinecone\":\n                embeddings =  await self._generate_pinecone_embedding(request_data, questions)\n                        \n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by pinecone.')\n                \n            elif embedding_provider == \"cohere\":\n                embeddings = await self._generate_cohere_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by cohere.')\n                \n            elif embedding_provider == \"jina\":\n                embeddings = await self._generate_jina_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by jina.')\n        \n            elif embedding_provider == \"voyage\":\n                embeddings = await self._generate_voyage_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by voyage.')\n                \n            for question, embedding in zip(questions, embeddings):\n                    query_embeddings = QueryEmbeddings(\n                        filename=request_data.file_name,\n                        embedding_model = request_data.embedding_model,\n                        dimension=request_data.dimension,\n                    )\n                    query_embeddings.add_question(question, embedding)\n                    result = await self.query_repository.insert_or_update_embeddings(query_embeddings)\n                    if result is None:\n                        loggers['evaluation'].error(\"Error inserting embeddings in motor\")\n                \n            if not len(embeddings) == len(questions):\n                loggers['main'].error(\"Error generating embeddings by pinecone\")\n                loggers[\"embedding\"].error(\"Error generating embeddings for questions: {questions}\")\n                \n            for question, embedding in zip(questions, embeddings):\n                self.validate_embedding(question, embedding, request_data.dimension)\n            \n            return embeddings\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error generating embedding: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 3818,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_dense_embedding"
    },
    {
        "id": "ff6f92af-ee37-43f9-ae52-f867b27ae714",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 306,
        "end_line": 319,
        "content": "async def _generate_pinecone_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Pinecone.\"\"\"\n    \n        pinecone_input = [{\"text\": question} for question in questions]\n        embeddings = await self.embedding_service.pinecone_dense_embeddings(\n            inputs=pinecone_input,\n            embedding_model=request_data.embedding_model,\n            dimension=request_data.dimension,\n            input_type=\"query\",\n        )\n        \n        return embeddings",
        "size": 537,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_pinecone_embedding"
    },
    {
        "id": "fc864b0e-9cbc-4df1-9b00-48c472c7b1d1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 321,
        "end_line": 331,
        "content": "async def _generate_cohere_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Cohere.\"\"\"\n        embeddings = await self.embedding_service.cohere_dense_embeddings(\n            texts=questions,\n            model_name=request_data.embedding_model,\n            input_type=\"search_query\",\n        )\n    \n        return embeddings",
        "size": 400,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_cohere_embedding"
    },
    {
        "id": "acc18ded-96b4-4df1-9392-c56195b2c25a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 333,
        "end_line": 345,
        "content": "async def _generate_jina_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Jina.\"\"\"\n\n        embeddings = await self.embedding_service.jina_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"retrieval.query\",\n        )\n        \n        return embeddings",
        "size": 449,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_jina_embedding"
    },
    {
        "id": "9f133ff9-0226-420f-9b01-bbc7f73fa761",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 347,
        "end_line": 357,
        "content": "async def _generate_voyage_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        embeddings = await self.embedding_service.voyageai_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"query\",\n        )\n\n        return embeddings",
        "size": 390,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_voyage_embedding"
    },
    {
        "id": "a13a8248-ad80-4d96-9a5d-75f2dbe23274",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 359,
        "end_line": 381,
        "content": "async def _perform_hybrid_search(\n        self, request_data, namespace_name, host, dense_embedding, question\n    ):\n        \"\"\"Perform hybrid search using both dense and sparse embeddings.\"\"\"\n\n        try:\n            sparse_embedding = self.embedding_service.pinecone_sparse_embeddings(\n                inputs=[question]\n            )\n\n            return await self.pinecone_service.pinecone_hybrid_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                alpha=request_data.alpha,\n                query_vector_embeds=dense_embedding,\n                query_sparse_embeds=sparse_embedding[0],\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing hybrid search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 942,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_hybrid_search"
    },
    {
        "id": "ea4d3049-ab9d-476d-854e-f5faa6696add",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 383,
        "end_line": 399,
        "content": "async def _perform_regular_search(\n        self, request_data, namespace_name, host, dense_embedding\n    ):\n        \"\"\"Perform regular dense vector search.\"\"\"\n\n        try:\n            return await self.pinecone_service.pinecone_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                vector=dense_embedding,\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing regular search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 659,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_regular_search"
    },
    {
        "id": "d288dae7-2bfb-401f-8b33-5a79594fe1f9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 401,
        "end_line": 404,
        "content": "async def _get_ground_truth(self, query):\n        \"\"\"Fetch ground truth data for the query.\"\"\"\n\n        return await self.index_repository.fetch_ground_truth(query=query)",
        "size": 170,
        "parent-class": "QueryUseCase",
        "function_name": "_get_ground_truth"
    },
    {
        "id": "18fdde02-d482-4628-8160-021bd6e0d5b8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 406,
        "end_line": 450,
        "content": "def _calculate_evaluation_metrics(self, relevant_docs, ground_truth_ids, top_k):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n\n        try:\n            return {\n                \"precision_at_k\": EvaluationService.precision_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"recall_at_k\": EvaluationService.recall_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids, k=top_k\n                ),\n                \"bpref\": EvaluationService.bpref(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids\n                ),\n                \"mrr\": EvaluationService.reciprocal_rank(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids\n                ),\n                \"map\": EvaluationService.mean_average_precision(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k\n                ),\n            }\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error calculating evaluation metrics: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 2014,
        "parent-class": "QueryUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "40085847-1051-4635-9405-7465c91a3f43",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 452,
        "end_line": 504,
        "content": "def average_metrics(self, metrics_list, top_k):\n    \n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_k + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n        \n        avg_dict = sum_dict.copy()\n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    \n                    for sub_key, sub_value in value.items():\n                        sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    \n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] \n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key]\n        \n        return avg_dict",
        "size": 1770,
        "parent-class": "QueryUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "efa863d9-5daa-4b00-8303-fe859717b89a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 506,
        "end_line": 515,
        "content": "def validate_embedding(self, question: str, embedding: list, expected_dim: int):\n        \"\"\"Check if embedding is valid; otherwise, log failure.\"\"\"\n        if embedding is None or not isinstance(embedding, list):\n            loggers[\"embedding\"].error(f\"Invalid embedding for question: {question}\")\n\n        elif len(embedding) != expected_dim:\n            loggers[\"embedding\"].error(f\"Invalid embedding dimension for question: {question}\")\n    \n        elif any(np.isnan(embedding)) or any(np.isinf(embedding)):\n            loggers[\"embedding\"].error(f\"Invalid embedding values for question: {question}\")",
        "size": 605,
        "parent-class": "QueryUseCase",
        "function_name": "validate_embedding"
    },
    {
        "id": "8d7410d3-8072-4a48-87f9-9898496c877d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 1,
        "end_line": 11,
        "content": "import asyncio\nimport json\nimport os\nfrom uuid import uuid4\nfrom fastapi import UploadFile, HTTPException, status\nimport aiofiles\nfrom app.config.settings import settings\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\nfrom app.utils.llm_utils import LLMUtils\nfrom app.utils.logging_util import loggers",
        "size": 362,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "313e3b3b-311a-4628-9a41-0cffcdf9412c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 14,
        "end_line": 17,
        "content": "def __init__(self):\n        self.raw_data_repo = RawDataRepo()\n        self.gt_data_repo = GTDataRepo()\n        self.llm_utils = LLMUtils()",
        "size": 139,
        "parent-class": "FileUploadUseCase",
        "function_name": "__init__"
    },
    {
        "id": "5f120e01-0990-44ee-b28c-e53e2327352a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 19,
        "end_line": 25,
        "content": "async def store_file_locally(self, file: UploadFile):\n        os.makedirs(settings.UPLOAD_DIR, exist_ok=True)\n        file_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n        async with aiofiles.open(file_path, \"wb\") as f:\n            while chunk := await file.read(2 * 1024 * 1024):  # Read in 2MB chunks\n                await f.write(chunk)\n        return file_path",
        "size": 393,
        "parent-class": "FileUploadUseCase",
        "function_name": "store_file_locally"
    },
    {
        "id": "cdc13214-9d34-4afa-9704-bfca2e2136ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 27,
        "end_line": 39,
        "content": "async def process_and_enrich_json(self, file_path: str):\n        async with aiofiles.open(file_path, \"r\") as f:\n            content = await f.read()\n            data = json.loads(content)\n        if not isinstance(data, list):\n            raise ValueError(\"JSON data must be a list\")\n        enriched_data = []\n        for item in data:\n            item[\"_id\"] = str(uuid4())\n            enriched_data.append(item)\n        async with aiofiles.open(file_path, \"w\") as f:\n            await f.write(json.dumps(enriched_data))\n        return enriched_data",
        "size": 551,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_and_enrich_json"
    },
    {
        "id": "25b899b7-f1dd-44b2-8f1c-f91d241da6fa",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 41,
        "end_line": 73,
        "content": "async def process_multi_chunk(self, data: dict):\n\n        loggers['main'].info(f\"length of data before : {len(data)}\")\n        chunks = [item for item in data[\"chunks\"] if item.get(\"text\", \"\").strip()]\n        loggers['main'].info(f\"length of data after : {len(chunks)}\")\n\n        chunk_data_for_llm = [\n            {\"text\": chunk[\"text\"], \"_id\": chunk[\"_id\"]} for chunk in data[\"chunks\"]\n        ]\n\n        response_json = await self.llm_utils.generate_multi_chunk_question(\n            {\"chunks\": chunk_data_for_llm, \"file_type\": data[\"file_type\"]}\n        )\n        # loggers['main'].info(f\"response_json from generate multi : {response_json}\")\n\n        if isinstance(response_json, str):\n            try:\n                response = json.loads(response_json)\n            except Exception as e:\n                raise ValueError(str(e))\n        else:\n            response = response_json\n\n        final_results = []\n        for question_item in response:\n            relevant_ids = question_item[\"relevant_ids\"]\n            relevant_chunks = [chunk for chunk in data[\"chunks\"] if str(chunk[\"_id\"]) in relevant_ids]\n            \n            final_results.append({\n                \"question\": question_item[\"question\"],\n                \"chunks\": relevant_chunks\n            })\n        return final_results",
        "size": 1304,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_multi_chunk"
    },
    {
        "id": "3d401cdb-0433-4cfb-b154-b7c58037dd7d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 75,
        "end_line": 92,
        "content": "async def generate_multi_chunk_queries(self, data):\n        dataset = []\n        tasks = []\n        for i in range(\n            0,\n            min(len(data[\"chunks_with_metadata\"]), settings.NO_OF_CHUNKS_AT_A_TIME*settings.MULTI_CHUNK_QUERIES_COUNT),\n            settings.NO_OF_CHUNKS_AT_A_TIME\n        ):\n\n            selected_items = data[\"chunks_with_metadata\"][i:i+settings.NO_OF_CHUNKS_AT_A_TIME]\n            task = self.process_multi_chunk({\"chunks\": selected_items, \"file_type\": data[\"file_type\"]})\n            tasks.append(task)\n        \n        results = await asyncio.gather(*tasks)\n        for result in results:\n            dataset.extend(result)\n        loggers['main'].info(f\"length of results in generate multi : {len(results)}\")\n        return dataset",
        "size": 767,
        "parent-class": "FileUploadUseCase",
        "function_name": "generate_multi_chunk_queries"
    },
    {
        "id": "2e49b7f3-6b5a-4171-a354-2bf866cc2558",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 94,
        "end_line": 171,
        "content": "async def execute(self, request_data):\n        try:\n\n            # File Store\n            file = request_data.get(\"input_data\")\n            file_name = request_data.get(\"file_name\")\n            file_type = request_data.get(\"file_type\")\n\n            if not isinstance(file_name, str):\n                raise ValueError(\"File name must be a string\")\n            _, file_extension = os.path.splitext(file_name)\n            if file_extension.lower() != \".json\":\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file is not in .json format\")\n\n            file_path = await self.store_file_locally(file)\n\n            existing_gt_data = await self.gt_data_repo.is_exist(file_name, file_type)\n            \n            if existing_gt_data:\n                doc = await self.raw_data_repo.is_exist(file_name, file_type)\n                doc = doc[\"data\"][0]\n                file_schema = {key: type(value).__name__ for key, value in doc.items() if key != \"_id\"}\n                if \"text\" not in file_schema.keys():\n                    raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n                \n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_gt_data.get(\"data\", []), default=str))\n                \n                existing_raw_data = await self.raw_data_repo.is_exist(file_name, file_type)\n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_raw_data.get(\"data\", []), default=str))\n                return {\"data\": \"File already processed\", \"file_schema\": json.dumps(file_schema)}\n            \n            enriched_data = await self.process_and_enrich_json(file_path)\n\n            loggers['main'].info(f\"length of data before : {len(enriched_data)}\")\n            enriched_data = [item for item in enriched_data if item.get(\"text\", \"\").strip()]\n            loggers['main'].info(f\"length of data after : {len(enriched_data)}\")\n\n            file_schema = {key: type(value).__name__ for key, value in enriched_data[0].items() if key != \"_id\"}\n            if \"text\" not in list(file_schema.keys()):\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n            \n            # Generate Queries\n            multi_chunk_dataset = await self.generate_multi_chunk_queries(\n                {\"chunks_with_metadata\": enriched_data, \"file_type\": file_type}\n            )\n            loggers[\"main\"].info(f\"length of multi chunk dataset : {len(multi_chunk_dataset)}\")\n            raw_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": enriched_data\n            }\n            await self.raw_data_repo.insert_documents(raw_data_document)\n\n            gt_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": [\n                    item.copy() for item in multi_chunk_dataset\n                ]\n            }\n            # loggers[\"main\"].info(f\"gt_data_document{gt_data_document}\")\n            try:\n                await self.gt_data_repo.insert_documents(gt_data_document)\n            except Exception as e:\n                loggers['main'].error(f\"documents were not inserted in mongodb , length of gt: {len(gt_data_document.get('data', []))}\")\n\n            dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n            async with aiofiles.open(dataset_path, \"w\") as f:\n                await f.write(json.dumps(multi_chunk_dataset))\n\n            return {\"data\": \"File processed and dataset generated successfully\", \"file_schema\": json.dumps(file_schema)}\n        except Exception as e:\n            loggers['main'].error(f\"file upload usecase outermost code breaks : {str(e)}\")\n            raise Exception(str(e))",
        "size": 4151,
        "parent-class": "FileUploadUseCase",
        "function_name": "execute"
    },
    {
        "id": "760e6c03-926a-4c9c-ba36-4995c7e8d87a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi import Depends, HTTPException, status\nfrom app.models.domain.indexupsert import IndexUpsert, Namespace\nfrom app.repositories.index_upsert_repository import IndexUpsertRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.utils.logging_util import loggers\nimport time",
        "size": 441,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c8694a25-8bcd-4a98-a6fc-b578de78b846",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 17,
        "end_line": 49,
        "content": "def __init__(\n        self,\n        index_upsert_repository=Depends(IndexUpsertRepository),\n        pinecone_service=Depends(PineconeService),\n        embedding_service=Depends(EmbeddingService),\n    ):\n        self.index_upsert_repository = index_upsert_repository\n        self.pinecone_service = pinecone_service\n        self.embedding_service = embedding_service\n        self.file_path = \"uploads/raw_dataset.json\"\n        self.chunk_size = 90\n        self.semaphore = asyncio.Semaphore(3)\n        self.upsert_batch_size = 50\n        self.model_provider = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"jina-clip-v2\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }",
        "size": 1368,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "__init__"
    },
    {
        "id": "94705b6a-ff60-4aa8-8537-0135914537fd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 51,
        "end_line": 76,
        "content": "async def process_chunk(self, chunk, provider, embed_model, dimension=None):\n        async with self.semaphore:\n            try:\n                if provider == \"pinecone\":\n                    return (\n                        await self.embedding_service.pinecone_dense_embeddings(\n                            chunk, embed_model, dimension=dimension\n                        )\n                    )\n                elif provider == \"cohere\":\n                    return await self.embedding_service.cohere_dense_embeddings(\n                        embed_model, chunk\n                    )\n                elif provider == \"jina\":\n                    return await self.embedding_service.jina_dense_embeddings(\n                        embed_model, dimension, chunk, \"retrieval.passage\"\n                    )\n                elif provider == \"voyage\":\n                    return await self.embedding_service.voyageai_dense_embeddings(\n                        embed_model, dimension, chunk\n                    )\n            except Exception as e:\n                loggers[\"main\"].error(\n                    f\"Error processing chunk with {provider} provider: {str(e)}\"\n                )\n                raise HTTPException(status_code=500, detail=str(e))",
        "size": 1245,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "process_chunk"
    },
    {
        "id": "81cc3d3b-c86c-41d7-8869-8d00f31d5221",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 78,
        "end_line": 112,
        "content": "async def _get_embeddings(self, data, embed_model, dimension):\n        try:\n            all_embeddings = []\n            embedding_provider = self.model_provider.get(embed_model)\n\n            if embedding_provider == \"pinecone\":\n                inputs = [{\"text\": item[\"text\"]} for item in data]\n            elif embedding_provider == \"cohere\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"jina\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"voyage\":\n                inputs = [item.get(\"text\", item.get(\"code\")) for item in data]\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            chunks = [\n                inputs[i : i + self.chunk_size]\n                for i in range(0, len(inputs), self.chunk_size)\n            ]\n            tasks = [\n                self.process_chunk(\n                    chunk, embedding_provider, embed_model, dimension\n                )\n                for chunk in chunks\n            ]\n            chunk_results = await asyncio.gather(*tasks)\n\n            for embeddings in chunk_results:\n                all_embeddings.extend(embeddings)\n\n            return all_embeddings\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1464,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_get_embeddings"
    },
    {
        "id": "45561cb6-46fc-4c31-abf7-b792278a9485",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 114,
        "end_line": 122,
        "content": "async def _upsert_batch(self, index_host, batch, namespace_name):\n        \"\"\"Helper function to upsert a single batch of vectors\"\"\"\n        try:\n            return await self.pinecone_service.upsert_vectors(\n                index_host, batch, namespace_name\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error upserting batch: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 436,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_upsert_batch"
    },
    {
        "id": "94a233ef-578d-4210-8af2-c4cdb56a942c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 124,
        "end_line": 167,
        "content": "async def _prepare_and_upsert(\n        self, data, embed_model, dimension, index_host, namespace_name\n    ):\n        try:\n            all_embeddings = await self._get_embeddings(\n                data, embed_model, dimension\n            )\n\n            text_list = [item[\"text\"] for item in data]\n            sparse_embeds = self.embedding_service.pinecone_sparse_embeddings(\n                text_list\n            )\n            final_upsert_format = await self.pinecone_service.upsert_format(\n                data, all_embeddings, sparse_embeds\n            )\n\n            batches = [\n                final_upsert_format[i : i + self.upsert_batch_size]\n                for i in range(0, len(final_upsert_format), self.upsert_batch_size)\n            ]\n\n            loggers[\"main\"].info(f\"Upserting {len(final_upsert_format)} vectors in {len(batches)} batches\")\n\n            upsert_tasks = [\n                self._upsert_batch(index_host, batch, namespace_name)\n                for batch in batches\n            ]\n            \n            # Gather results from all batches\n            batch_results = await asyncio.gather(*upsert_tasks)\n            \n            # Combine results\n            total_upserted = sum(result.get(\"upserted_count\", 0) for result in batch_results)\n            time.sleep(15)\n            return {\n                \"upserted_count\": total_upserted,\n                \"batches_processed\": len(batches),\n                \"batch_results\": batch_results\n            }\n\n    \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in preparing and upserting vectors : {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1668,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_prepare_and_upsert"
    },
    {
        "id": "fc9164ad-7037-417f-947b-248190cc21b0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 169,
        "end_line": 196,
        "content": "async def _save_in_db(\n        self,\n        file_name,\n        embed_model,\n        index_name,\n        index_host,\n        dimension,\n        similarity_metric,\n    ):\n        namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n        namespace = Namespace(\n            name=namespace_name, filename=file_name, embedding_model=embed_model\n        )\n\n        index_upsert = IndexUpsert(\n            index_name=index_name,\n            index_host=index_host,\n            dimension=dimension,\n            similarity_metric=similarity_metric,\n        )\n\n        index_upsert.add_namespace(namespace)\n        return (\n            await self.index_upsert_repository.add_index_upsert_details(\n                index_upsert\n            ),\n        )",
        "size": 746,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_save_in_db"
    },
    {
        "id": "3a09f67c-c73b-4f8e-b4b2-7526cd7bdfa9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 198,
        "end_line": 300,
        "content": "async def index_upsert(self, request):\n        try:\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            embed_model = request.embed_model\n\n            already_upserted = (\n                await self.index_upsert_repository.find_matching_index_upsert(\n                    dimension, similarity_metric, file_name, embed_model\n                )\n            )\n\n            if already_upserted:\n                return {\n                    \"message\": \"such dimension, similarity metric, filename and embed_model configuration already exists, move on to query\"\n                }\n\n            with open(self.file_path, \"r\") as file:\n                data = json.load(file)\n\n            loggers[\"main\"].info(f\"length of data before : {len(data)}\")\n            data = [item for item in data if item.get(\"text\", \"\").strip()]\n            loggers[\"main\"].info(f\"length of data after : {len(data)}\")\n\n\n\n            already_index = (\n                await self.index_upsert_repository.find_matching_index(\n                    dimension, similarity_metric\n                )\n            )\n\n            if not already_index:\n                index_json = await self.pinecone_service.list_pinecone_indexes()\n                index_list = index_json.get(\"indexes\")\n                index_names = [index[\"name\"] for index in index_json[\"indexes\"]]\n                if(len(index_list) >= 5):\n                    loggers[\"main\"].error(f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n                    raise HTTPException(status_code= status.HTTP_403_FORBIDDEN, detail = f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n\n                loggers[\"main\"].info(f\"already index {already_index}\")\n                loggers[\"main\"].info(f\"index list {index_json}\")\n\n\n                index_name = f\"{similarity_metric}-{dimension}\"\n                response = await self.pinecone_service.create_index(\n                    index_name, dimension, similarity_metric\n                )\n                index_host = response.get(\"host\")\n\n                namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n                upsert_result = await self._prepare_and_upsert(\n                    data, embed_model, dimension, index_host, namespace_name\n                )\n\n                db_result = await self._save_in_db(\n                    file_name,\n                    embed_model,\n                    index_name,\n                    index_host,\n                    dimension,\n                    similarity_metric,\n                )\n\n                return {\n                    \"upsert_result\": upsert_result,\n                    \"database_result\": db_result,\n                }\n\n            index_name = already_index.get(\"index_name\")\n            index_host = already_index.get(\"index_host\")\n\n            index_json = await self.pinecone_service.list_pinecone_indexes()\n            index_list = index_json.get(\"indexes\")\n            loggers[\"main\"].info(f\"length of index list : {len(index_list)}\")\n\n            loggers[\"main\"].info(f\"already index outside if{already_index}\")\n            loggers[\"main\"].info(f\"index list outside if {index_list}\")\n\n            namespace_name = f\"{file_name}-{embed_model}-namespace\"\n            upsert_result = await self._prepare_and_upsert(\n                data, embed_model, dimension, index_host, namespace_name\n            )\n\n            db_result = await self._save_in_db(\n                file_name,\n                embed_model,\n                index_name,\n                index_host,\n                dimension,\n                similarity_metric,\n            )\n\n            return {\n                \"upsert_result\": upsert_result,\n                \"database_result\": db_result,\n            }\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in index upsert {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 4085,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "index_upsert"
    },
    {
        "id": "858b85bb-7950-4c31-b142-5c4f46994c1f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.repositories.index_repository import IndexRepository\nfrom app.utils.logging_util import loggers",
        "size": 273,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "2182200d-6dac-4f1c-a625-405a4d1fa1b3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 10,
        "end_line": 52,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(), \n    ):\n        self.index_repository = index_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }",
        "size": 1870,
        "parent-class": "RandomQueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "3ef73739-18ca-496a-abd5-755a494e4f7a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 55,
        "end_line": 78,
        "content": "async def _get_namespace_and_host(self, similarity_metric, dimension, embedding_model, file_name):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{similarity_metric}-{dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    embedding_model,\n                    file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers[\"main\"].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 937,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "f047a245-24df-4897-bd02-a22d29c78b70",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 81,
        "end_line": 119,
        "content": "async def _get_query_embeddings(self, query, embed_model, dimension):\n        try:\n            embedding_provider = self.embeddings_provider_mapping.get(embed_model)\n            if embedding_provider == \"pinecone\":\n\n                pinecone_input = [{\"text\": query}]\n                embeddings =  await self.embedding_service.pinecone_dense_embeddings(\n                    pinecone_input, embed_model, dimension=dimension,input_type=\"query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"cohere\":\n                cohere_input = [query]\n                embeddings = await self.embedding_service.cohere_dense_embeddings(\n                    cohere_input, embed_model, input_type=\"search_query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"jina\":\n                jina_input = [query]\n                embeddings = await self.embedding_service.jina_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = jina_input, input_type = \"retrieval.query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"voyage\":\n                voyage_input = [query]\n                embeddings = await self.embedding_service.voyageai_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = voyage_input, input_type = \"query\"\n                )\n                return embeddings[0]\n\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1802,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_query_embeddings"
    },
    {
        "id": "ba167d90-b6a2-4052-9043-0ef52950a4fd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 122,
        "end_line": 166,
        "content": "async def random_query(self, request):\n        try:\n            query = request.query\n            embed_model = request.embedding_model\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            top_k = request.top_k\n            include_metadata = request.include_metadata\n            namespace, host = await self._get_namespace_and_host(similarity_metric, dimension, embed_model,file_name)\n        \n           \n            query_dense_vector = await self._get_query_embeddings(query, embed_model, dimension)\n            \n            if request.is_hybrid:\n                query_sparse_vector = self.embedding_service.pinecone_sparse_embeddings([query])\n                query_sparse_vector = query_sparse_vector[0]\n                alpha = request.alpha\n                loggers[\"main\"].info(\"sparse embeddings generated in random query use case\")\n                pinecone_response = await self.pinecone_service.pinecone_hybrid_query(\n                    host, namespace, top_k, alpha, query_dense_vector, query_sparse_vector, include_metadata\n                )\n            else:\n                pinecone_response = await self.pinecone_service.pinecone_query(\n                    host, namespace, top_k, query_dense_vector, include_metadata\n                )\n            \n            matches = pinecone_response.get(\"matches\", [])\n            final_responses = []\n            for match in matches:\n                score = match.get(\"score\", None)\n                id = match.get(\"id\", None)\n                text = match.get(\"metadata\", None).get(\"text\", None)\n                metadata = {key: value for key, value in match.get(\"metadata\").items() if key != \"text\"}\n                final_responses.append({\n                    \"id\": id,\n                    \"score\": score,\n                    \"text\": text,\n                    \"metadata\": metadata\n                })\n            return final_responses\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in random_query_usecase: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))",
        "size": 2207,
        "parent-class": "RandomQueryUseCase",
        "function_name": "random_query"
    },
    {
        "id": "486eff4b-8c03-4db5-b02d-5baa836d287b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo",
        "size": 158,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9d868b28-864f-4a77-92bb-a570cec17ad0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 9,
        "end_line": 15,
        "content": "def __init__(\n        self, \n        gt_data_repo: GTDataRepo = Depends(),\n        raw_data_repo: RawDataRepo = Depends(),\n    ):\n        self.gt_data_repo = gt_data_repo\n        self.raw_data_repo = raw_data_repo",
        "size": 213,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "__init__"
    },
    {
        "id": "cb397aca-eb64-4665-bc72-2697035c7bd9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 17,
        "end_line": 28,
        "content": "async def random_question(self, file_name):\n        try:\n            question_with_groundtruth, ids = await self.gt_data_repo.get_random_question(file_name)\n           \n            text_content = await self.raw_data_repo.fetch_texts_by_ids(file_name,ids)\n            \n            for i in range(len(ids)):\n                question_with_groundtruth[\"chunks\"][i][\"text\"] = text_content[i]\n               \n            return question_with_groundtruth\n        except Exception as e:\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))",
        "size": 576,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "random_question"
    },
    {
        "id": "c5759684-fe2f-4a13-bf28-bafa4dd28281",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict\nimport httpx\nfrom fastapi import HTTPException\nfrom pinecone import Pinecone\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers",
        "size": 258,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "20ac647c-6fa6-4a9a-b870-62541970fe4c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 16,
        "end_line": 31,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.api_version = settings.PINECONE_API_VERSION\n        self.index_url = settings.PINECONE_CREATE_INDEX_URL\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.upsert_url = settings.PINECONE_UPSERT_URL\n        self.query_url = settings.PINECONE_QUERY_URL\n        self.list_index_url = settings.PINECONE_LIST_INDEXES_URL\n        self.semaphore = asyncio.Semaphore(10)\n        self.pc = Pinecone(api_key=settings.PINECONE_API_KEY)\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )",
        "size": 878,
        "parent-class": "PineconeService",
        "function_name": "__init__"
    },
    {
        "id": "03bbeff2-ee1f-4797-85c6-9f7a7cc64feb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 33,
        "end_line": 53,
        "content": "async def list_pinecone_indexes(self):\n        url = self.list_index_url\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url, headers=headers)\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n\n            loggers[\"main\"].error(f\"Error creating index: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 782,
        "parent-class": "PineconeService",
        "function_name": "list_pinecone_indexes"
    },
    {
        "id": "bbd51c3a-6f6e-4ca6-9960-5da95eddc50e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 55,
        "end_line": 118,
        "content": "async def create_index(\n        self, index_name: str, dimension: int, metric: str\n    ) -> Dict[str, Any]:\n        if self.pc.has_index(index_name) == False:\n            index_data = {\n                \"name\": index_name,\n                \"dimension\": dimension,\n                \"metric\": metric,\n                \"spec\": {\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}},\n            }\n\n            headers = {\n                \"Accept\": \"application/json\",\n                \"Content-Type\": \"application/json\",\n                \"Api-Key\": self.pinecone_api_key,\n                \"X-Pinecone-API-Version\": self.api_version,\n            }\n\n            try:\n                async with httpx.AsyncClient() as client:\n                    response = await client.post(\n                        self.index_url, headers=headers, json=index_data\n                    )\n                    response.raise_for_status()\n\n                    retry_count = 0\n                    max_retries = 30\n                    while retry_count < max_retries:\n                        status = (\n                            self.pc.describe_index(index_name)\n                            .get(\"status\")\n                            .get(\"state\")\n                        )\n                        loggers[\"main\"].info(f\"Index status: {status}\")\n\n                        if status == \"Ready\":\n                            loggers[\"main\"].info(f\"Index {index_name} is ready\")\n                            break\n\n                        retry_count += 1\n                        time.sleep(2)\n\n                    if retry_count > max_retries:\n                        raise HTTPException(\n                            status_code=500, detail=\"Index creation timed out\"\n                        )\n\n                    loggers[\"main\"].info(\"Index Created\")\n                    return response.json()\n\n            except httpx.HTTPStatusError as e:\n                parsed_response = json.loads(response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\n                    \"message\", \"Unknown error occurred\"\n                )\n                loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            except Exception as e:\n                loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        else:\n            loggers[\"main\"].info(\"index already created\")\n            return {\"host\": self.pc.describe_index(index_name).get(\"host\")}",
        "size": 2610,
        "parent-class": "PineconeService",
        "function_name": "create_index"
    },
    {
        "id": "f4d0ce94-7fb9-4e9a-b323-4901c7a930db",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 120,
        "end_line": 138,
        "content": "async def upsert_format(\n        self, chunks: list, vector_embeddings: list, sparse_embeddings: list\n    ):\n        results = []\n        for i in range(len(chunks)):\n            metadata = {key: value for key, value in chunks[i].items() if key != \"_id\"}\n\n            metadata[\"created_at\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            result = {\n                \"id\": chunks[i][\"_id\"],\n                \"values\": vector_embeddings[i],\n                \"metadata\": metadata,\n                \"sparse_values\": {\n                    \"indices\": sparse_embeddings[i][\"indices\"],\n                    \"values\": sparse_embeddings[i][\"values\"],\n                },\n            }\n            results.append(result)\n        return results",
        "size": 738,
        "parent-class": "PineconeService",
        "function_name": "upsert_format"
    },
    {
        "id": "dc13c190-7b25-45f8-8abd-9229e92f1cc0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 140,
        "end_line": 169,
        "content": "async def upsert_vectors(self, index_host, input, namespace):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        url = self.upsert_url.format(index_host)\n\n        payload = {\"vectors\": input, \"namespace\": namespace}\n        try:\n            async with httpx.AsyncClient(timeout= self.timeout) as client:\n                response = await client.post(\n                    url=url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors http status error : {str(e)} - {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)    \n        \n        except httpx.HTTPError as e:    \n            loggers[\"main\"].error(f\"Error in upsert vectors http error : {str(e)}\")\n            raise HTTPException(status_code=400, detail=str(e))\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors : {str(e)} \")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1248,
        "parent-class": "PineconeService",
        "function_name": "upsert_vectors"
    },
    {
        "id": "ae371955-0a89-42a2-8759-b5c65b96dcdd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 171,
        "end_line": 181,
        "content": "def hybrid_scale(self, dense, sparse, alpha: float):\n\n        if alpha < 0 or alpha > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        # scale sparse and dense vectors to create hybrid search vecs\n        hsparse = {\n            \"indices\": sparse[\"indices\"],\n            \"values\": [v * (1 - alpha) for v in sparse[\"values\"]],\n        }\n        hdense = [v * alpha for v in dense]\n        return hdense, hsparse",
        "size": 434,
        "parent-class": "PineconeService",
        "function_name": "hybrid_scale"
    },
    {
        "id": "a8396bec-918c-4de8-af08-a45a9cb596a0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 183,
        "end_line": 247,
        "content": "async def pinecone_hybrid_query(\n        self,\n        index_host,\n        namespace,\n        top_k,\n        alpha: int,\n        query_vector_embeds: list,\n        query_sparse_embeds: dict,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        if query_vector_embeds is None or query_sparse_embeds is None:\n            time.sleep(2)\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        hdense, hsparse = self.hybrid_scale(\n            query_vector_embeds, query_sparse_embeds, alpha\n        )\n\n        payload = {\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n            \"vector\": hdense, \n            \"sparseVector\": {\n                \"indices\": hsparse.get(\n                    \"indices\"\n                ),  \n                \"values\": hsparse.get(\n                    \"values\"\n                ),  \n            },\n            \"topK\": top_k,\n            \"namespace\": namespace,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone hybrid query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error performing hybrid query: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 2347,
        "parent-class": "PineconeService",
        "function_name": "pinecone_hybrid_query"
    },
    {
        "id": "1fe58e0b-5c6e-4078-8994-5a4d649dac94",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 249,
        "end_line": 297,
        "content": "async def pinecone_query(\n        self,\n        index_host: str,\n        namespace: str,\n        top_k: int,\n        vector: list,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        payload = {\n            \"namespace\": namespace,\n            \"vector\": vector,\n            # \"filter\": filter_dict,\n            \"topK\": top_k,\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone Normal query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1814,
        "parent-class": "PineconeService",
        "function_name": "pinecone_query"
    },
    {
        "id": "2a5211dd-200e-46da-b407-69e725d4fbea",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nimport pickle\nimport httpx\nfrom fastapi import HTTPException, status\nfrom pinecone_text.sparse import BM25Encoder\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers",
        "size": 224,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "55faaedc-83aa-4ebc-814f-7dda044793bd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 18,
        "end_line": 38,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.pinecone_embedding_url = settings.PINECONE_EMBED_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.togetherai_api_key = settings.TOGETHERAI_API_KEY\n        self.voyageai_api_key = settings.VOYAGEAI_API_KEY\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.togetherai_base_url = settings.TOGETHERAI_BASE_URL\n        self.voyageai_base_url = settings.VOYAGEAI_BASE_URL\n        self.EMBED_SUFFIX = \"embed\"\n        self.JINA_EMBED_SUFFIX = \"embeddings\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=300.0,    # Time to read the response\n                        write=300.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )",
        "size": 1149,
        "parent-class": "EmbeddingService",
        "function_name": "__init__"
    },
    {
        "id": "48eeb36e-9c08-4488-9f24-fa35558fd5bf",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 40,
        "end_line": 84,
        "content": "async def pinecone_dense_embeddings(\n        self,\n        inputs: list,\n        embedding_model: str = \"llama-text-embed-v2\",\n        input_type: str = \"passage\",\n        truncate: str = \"END\",\n        dimension: int = 1024,\n    ):\n        payload = {\n            \"model\": embedding_model,\n            \"parameters\": {\n                \"input_type\": input_type,\n                \"truncate\": truncate,\n                # \"dimension\": dimension,\n            },\n            \"inputs\": inputs,\n        }\n\n        if embedding_model != \"multilingual-e5-large\":\n            payload[\"parameters\"][\"dimension\"] = dimension \n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n        }\n\n        url = self.dense_embed_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"embeddings generated\")\n                response = response.json()\n                loggers[\"pinecone\"].info(f\"pinecone hosted embedding model tokens usage: {response['usage']}\")\n                list_result = [item[\"values\"] for item in response[\"data\"]]\n                return list_result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=f\"{str(e)}-{e.response.text}\")\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1813,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_dense_embeddings"
    },
    {
        "id": "3bc38820-0209-4cc9-8743-6c39d9eb3230",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 86,
        "end_line": 93,
        "content": "def pinecone_sparse_embeddings(self, inputs):\n        try:\n            sparse_vector = bm25.encode_documents(inputs)\n            return sparse_vector\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating sparse embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 326,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_sparse_embeddings"
    },
    {
        "id": "7a1e5a31-02fb-484e-8191-eca35ef5101e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 95,
        "end_line": 137,
        "content": "async def cohere_dense_embeddings(\n        self,\n        model_name: str,\n        texts: list[str],\n        input_type: str = \"search_document\",\n    ):\n\n        url = f\"{self.cohere_base_url}/{self.EMBED_SUFFIX}\"\n\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.cohere_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"texts\": texts,\n            \"input_type\": input_type,\n            \"embedding_types\": [\"float\"],\n        }\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout,verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                # return response.json()\n                response = response.json()\n                loggers[\"cohere\"].info(f\"cohere hosted embedding model tokens usage: { response.get('meta', {}).get('billed_units', {})}\")\n                result = response[\"embeddings\"][\"float\"]\n                return result\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}-{e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense cohere embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1759,
        "parent-class": "EmbeddingService",
        "function_name": "cohere_dense_embeddings"
    },
    {
        "id": "24670a6a-f3b9-45fe-a0f3-fa11e47cbe77",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 139,
        "end_line": 187,
        "content": "async def jina_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n\n        url = f\"{self.jina_base_url}/{self.JINA_EMBED_SUFFIX}\"\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"embedding_type\": \"float\",\n            \"input\": inputs,\n        }\n\n        if model_name == \"jina-embeddings-v3\":\n            data[\"task\"] = input_type\n            data[\"late_chunking\"] = False\n            data['dimensions'] = dimension\n        elif model_name == \"jina-embeddings-v2-base-code\":\n            data[\"normalized\"] = True\n        else:\n            data[\"normalized\"] = True\n            data['dimensions'] = dimension\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout, verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"jina\"].info(f\"jina hosted embedding model tokens usage: {response.get('usage', {})}\")\n                result = [item[\"embedding\"] for item in response[\"data\"]]\n                return result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.content} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}, {e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502,  # Bad Gateway (Failed to connect)\n                detail= f\"Failed to connect to API httpx Request error : {str(e)}\",\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense jina embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 2068,
        "parent-class": "EmbeddingService",
        "function_name": "jina_dense_embeddings"
    },
    {
        "id": "0fb6f66b-0fbd-4e27-8f44-48bb75b26522",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 189,
        "end_line": 219,
        "content": "async def togetherai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n        url = f\"{self.togetherai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        headers = {\n            \"accept\": \"application/json\",\n            \"authorization\": f\"Bearer {self.togetherai_api_key}\",\n            \"content-type\": \"application/json\"\n        }\n        payload = {\n            \"model\": model_name,\n            \"input\": inputs\n        }\n\n        try:\n            async with httpx.AsyncClient(verify = False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error:{str(e)} {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx : {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in togetherai_dense_embedding: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured : {str(e)}\")",
        "size": 1529,
        "parent-class": "EmbeddingService",
        "function_name": "togetherai_dense_embeddings"
    },
    {
        "id": "24ed1cfe-64ea-4372-a0de-54a1e55b3a2a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 223,
        "end_line": 263,
        "content": "async def voyageai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list, input_type: str = \"document\"\n    ):\n        url = f\"{self.voyageai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.voyageai_api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        data = {\n            \"input\": inputs,\n            \"model\": model_name,\n            \"input_type\": input_type,\n            \"output_dimension\": dimension\n        }\n\n        try:\n\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"voyage\"].info(f\"Embedding model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                embedding_list = [item[\"embedding\"] for item in response[\"data\"]]\n                return embedding_list\n            \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {e.response.text}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error occurred in httpx status error  : {str(e)} - {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx voyage dense embed: {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in voyageai_dense_embedding: {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured in voyageai_dense_embedding: {str(e)}, \")",
        "size": 2232,
        "parent-class": "EmbeddingService",
        "function_name": "voyageai_dense_embeddings"
    },
    {
        "id": "16268e07-63f1-4a43-872a-5575c4a42ea5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import math\nimport logging\nfrom typing import Dict, List\nfrom app.utils.logging_util import loggers",
        "size": 99,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "50711123-900e-440e-a4af-5126f20b8bae",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 10,
        "end_line": 45,
        "content": "def _discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Discounted Cumulative Gain (DCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            retrieved_texts = [doc[\"id\"] for doc in retrieved_docs[:k]]\n            relevance_scores = [\n                1 if doc in ground_truth else 0 for doc in retrieved_texts\n            ]\n\n            if not relevance_scores:\n                return 0.0\n\n            dcg_at_k = relevance_scores[0] if relevance_scores else 0\n            for i in range(1, len(relevance_scores)):\n                dcg_at_k += relevance_scores[i] / math.log2(i + 1)\n\n            return dcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 1290,
        "parent-class": "EvaluationService",
        "function_name": "_discounted_cumulative_gain_at_k"
    },
    {
        "id": "30098b60-60ec-453f-b1db-862abbc3d149",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 48,
        "end_line": 78,
        "content": "def _ideal_discounted_cumulative_gain_at_k(\n        ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Ideal Discounted Cumulative Gain (IDCG) @ K.\n        \"\"\"\n        try:\n            if not isinstance(ground_truth, list) or not isinstance(k, int):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ideal_relevance_scores = [1] * min(len(ground_truth), k)\n\n            if not ideal_relevance_scores:\n                return 0.0\n\n            idcg_at_k = (\n                ideal_relevance_scores[0] if ideal_relevance_scores else 0\n            )\n            for i in range(1, len(ideal_relevance_scores)):\n                idcg_at_k += ideal_relevance_scores[i] / math.log2(i + 1)\n\n            return idcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in ideal_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 1105,
        "parent-class": "EvaluationService",
        "function_name": "_ideal_discounted_cumulative_gain_at_k"
    },
    {
        "id": "b9ca7822-42c3-40bf-9c72-f3653ef2c073",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 81,
        "end_line": 119,
        "content": "def normalized_discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Normalized Discounted Cumulative Gain (NDCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ndcg_at_k = {}\n            for i in range(k):\n                dcg_at_i = EvaluationService._discounted_cumulative_gain_at_k(\n                    retrieved_docs, ground_truth, i + 1\n                )\n                idcg_at_i = (\n                    EvaluationService._ideal_discounted_cumulative_gain_at_k(\n                        ground_truth, i + 1\n                    )\n                )\n                ndcg_at_i = dcg_at_i / idcg_at_i if idcg_at_i > 0 else 0.0\n\n                ndcg_at_k[f\"NDCG@{i+1}\"] = ndcg_at_i\n\n            loggers['evaluation'].info(f\"NDCG Result: {ndcg_at_k}\")\n            return ndcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in normalized_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 1473,
        "parent-class": "EvaluationService",
        "function_name": "normalized_discounted_cumulative_gain_at_k"
    },
    {
        "id": "269748ad-fbb4-4a9b-9cef-914b7a0c74c5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 122,
        "end_line": 153,
        "content": "def bpref(retrieved_docs: List[Dict], ground_truth: List[str]) -> float:\n        \"\"\"\n        Computes BPREF (Binary Preference).\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            relevant_docs = set(ground_truth)\n            irrelevant_count = 0\n            total_relevant = len(relevant_docs)\n            bpref_score = 0.0\n\n            if total_relevant == 0:\n                return 0.0\n\n            for doc in retrieved_docs:\n                if doc[\"id\"] in relevant_docs:\n                    bpref_score += 1 - (min(irrelevant_count, total_relevant) / total_relevant)\n                else:\n                    irrelevant_count += 1\n\n            loggers['evaluation'].info(f\"BPREF Result: {bpref_score / total_relevant}\")\n            return bpref_score / total_relevant\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in bpref: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 1151,
        "parent-class": "EvaluationService",
        "function_name": "bpref"
    },
    {
        "id": "90b2d191-e9e3-4d1b-b286-92c630c3851c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 156,
        "end_line": 201,
        "content": "def precision_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Precision@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Precision@k' to precision scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            precision_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision_results[f\"Precision@{k}\"] = (\n                    round(matches / float(k), 2) if k > 0 else 0.0\n                )\n            loggers['evaluation'].info(f\"Precision Result: {precision_results}\")\n            return precision_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in precision_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 1803,
        "parent-class": "EvaluationService",
        "function_name": "precision_at_k"
    },
    {
        "id": "a59e7a95-fad8-4f70-a037-d2db61938b3b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 204,
        "end_line": 251,
        "content": "def recall_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Recall@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Recall@k' to recall scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            recall_results = {}\n\n            if len(ground_truth) == 0:\n                return {f\"Recall@{k}\": 0.0 for k in range(1, max_k + 1)}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                matches = len(ground_truth_ids.intersection(retrieved_at_k))\n                recall_results[f\"Recall@{k}\"] = round(\n                    matches / float(len(ground_truth)), 2\n                )\n            loggers['evaluation'].info(f\"Recall Results: {recall_results}\")\n            return recall_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in recall_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 1885,
        "parent-class": "EvaluationService",
        "function_name": "recall_at_k"
    },
    {
        "id": "d0e29522-e3ce-4b01-89e5-da421a613a0c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 254,
        "end_line": 314,
        "content": "def f1_score_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes F1-Score@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'F1-Score@k' to F1 scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            f1_score_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n\n                # Calculate precision\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision = matches / float(k) if k > 0 else 0.0\n\n                # Calculate recall\n                recall = (\n                    matches / float(len(ground_truth))\n                    if ground_truth\n                    else 0.0\n                )\n\n                # Calculate F1 score\n                f1 = 0.0\n                if precision + recall > 0:\n                    f1 = 2 * (precision * recall) / (precision + recall)\n\n                f1_score_results[f\"F1-Score@{k}\"] = round(f1, 2)\n\n            loggers['evaluation'].info(f\"F1-Score Results: {f1_score_results}\")\n            return f1_score_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in f1_score_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}",
        "size": 2199,
        "parent-class": "EvaluationService",
        "function_name": "f1_score_at_k"
    },
    {
        "id": "378aea0d-2f21-4972-9975-682b52dcf3cd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 317,
        "end_line": 365,
        "content": "def hit_rate_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Hit Rate@K for all k values from 1 to max_k.\n        (Binary outcome: 1 if at least one relevant document is in top-K, 0 otherwise)\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Hit_Rate@k' to binary hit values for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            hit_rate_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                hit = (\n                    1.0\n                    if len(ground_truth_ids.intersection(retrieved_at_k)) > 0\n                    else 0.0\n                )\n                hit_rate_results[f\"Hit_Rate@{k}\"] = hit\n\n            loggers[\"evaluation\"].info(f\"Hit Rate Results: {hit_rate_results}\")\n            return hit_rate_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in hit_rate_at_k: {e}\")\n            return {}",
        "size": 1870,
        "parent-class": "EvaluationService",
        "function_name": "hit_rate_at_k"
    },
    {
        "id": "cc26202f-c296-43a9-89b5-45681205e37c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 368,
        "end_line": 401,
        "content": "def reciprocal_rank(\n        retrieved_docs: List[Dict], ground_truth: List[str]\n    ) -> float:\n        \"\"\"\n        Computes Mean Reciprocal Rank (MRR).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n\n        Returns:\n            MRR score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            reciprocal_rank = 0.0\n            ground_truth_set = set(ground_truth)\n\n            for rank, doc in enumerate(retrieved_docs, start=1):\n                if doc[\"id\"] in ground_truth_set:\n                    reciprocal_rank = 1.0 / rank\n                    break\n\n            return reciprocal_rank\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_reciprocal_rank: {e}\")\n            return 0.0",
        "size": 1092,
        "parent-class": "EvaluationService",
        "function_name": "reciprocal_rank"
    },
    {
        "id": "f4aa50a5-2900-47ee-9eb2-f3bc12174c6b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 404,
        "end_line": 452,
        "content": "def mean_average_precision(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> float:\n        \"\"\"\n        Computes Mean Average Precision (MAP).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            MAP score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_set = set(ground_truth)\n            average_precision = 0.0\n            relevant_count = 0\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_docs[:k]\n                matches = sum(\n                    1 for doc in retrieved_at_k if doc[\"id\"] in ground_truth_set\n                )\n                precision_at_k = matches / float(k) if k > 0 else 0.0\n\n                if retrieved_at_k[-1][\"id\"] in ground_truth_set:\n                    average_precision += precision_at_k\n                    relevant_count += 1\n\n            return average_precision / relevant_count if relevant_count > 0 else 0.0\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_average_precision: {e}\")\n            return 0.0",
        "size": 1783,
        "parent-class": "EvaluationService",
        "function_name": "mean_average_precision"
    },
    {
        "id": "764c9cc3-a701-49ad-98fa-1630c8074ecc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nfrom fastapi import HTTPException\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers",
        "size": 142,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "3578ffa7-955a-4456-9a17-f250e5854a70",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 11,
        "end_line": 27,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.voyage_api_key=settings.VOYAGEAI_API_KEY\n        self.pinecone_rerank_url = settings.PINECONE_RERANK_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.voyage_base_url=settings.VOYAGEAI_BASE_URL\n        self.RERANK_SUFFIX = \"rerank\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )",
        "size": 910,
        "parent-class": "RerankerService",
        "function_name": "__init__"
    },
    {
        "id": "63a2d531-a1fa-4675-8686-4043ef4d2c0f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 29,
        "end_line": 70,
        "content": "async def pinecone_reranker(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n            \"Api-Key\": self.pinecone_api_key,\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"return_documents\": True,\n            \"top_n\": top_n,\n            \"documents\": documents,\n            \"parameters\": {\n                \"truncate\": \"END\",\n            },\n        }\n\n        url = self.pinecone_rerank_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done\")\n                loggers[\"pinecone\"].info(f\"Reranking model hosted by Pinecone tokens usage : {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            parsed_response = json.loads(response.content.decode(\"utf-8\"))\n            error_message = parsed_response.get(\"error\", {}).get(\n                \"message\", \"Unknown error occurred\"\n            )\n            loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n            raise HTTPException(status_code=400, detail=error_message)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1643,
        "parent-class": "RerankerService",
        "function_name": "pinecone_reranker"
    },
    {
        "id": "60dee7ff-9fa9-41bc-937f-7f926a4a93a6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 72,
        "end_line": 114,
        "content": "async def cohere_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        rerank_url = f\"{self.cohere_base_url}/{self.RERANK_SUFFIX}\"\n\n        headers = {\n            \"content-type\": \"application/json\",\n            \"accept\": \"application/json\",\n            \"Authorization\": f\"bearer {self.cohere_api_key}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url,\n                    headers=headers,\n                    json=payload,\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by cohere\")\n                loggers[\"cohere\"].info(f\"Reranking model hosted by Cohere tokens usage : {response.json().get('meta',{}).get('billed_units', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in cohere {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1775,
        "parent-class": "RerankerService",
        "function_name": "cohere_rerank"
    },
    {
        "id": "50dcbcf0-a057-48fc-9a46-932740d1e359",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 116,
        "end_line": 155,
        "content": "async def jina_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.jina_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by jina\")\n                loggers[\"jina\"].info(f\"Reranking model hosted by Jina tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in jina {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1698,
        "parent-class": "RerankerService",
        "function_name": "jina_rerank"
    },
    {
        "id": "abac5137-6c1e-44a8-bbce-c7874c641503",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 158,
        "end_line": 196,
        "content": "async def voyage_rerank(\n            self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        headers = {\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.voyage_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_k\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.voyage_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by voyage\")\n                loggers[\"voyage\"].info(f\"Reranking model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail = f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in Voyage {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))",
        "size": 1733,
        "parent-class": "RerankerService",
        "function_name": "voyage_rerank"
    }
]