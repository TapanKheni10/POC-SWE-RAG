[
    {
        "id": "aee4158e-7414-413f-8204-2732ced01630",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nimport asyncio\nimport streamlit as st\nfrom typing import Dict, Tuple, List, Optional\n\nModule imports for a Streamlit application that uses asynchronous HTTP requests, JSON handling, and typed data structures for building a RAG pipeline comparison tool that evaluates different information retrieval methods.",
        "size": 332,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "40f998ed-28d8-40d2-a8ce-b96595321216",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 11,
        "end_line": 47,
        "content": "def initialize():\n        \"\"\"Initialize all session state variables\"\"\"\n        if \"pipeline_states\" not in st.session_state:\n            st.session_state.pipeline_states = {\n                \"1\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                },\n                \"2\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                }\n            }\n        \n        if \"file_uploaded\" not in st.session_state:\n            st.session_state.file_uploaded = False\n        \n        if \"file_name\" not in st.session_state:\n            st.session_state.file_name = \"\"\n\nStatic method in the SessionState class that initializes Streamlit session state variables for tracking the state of two retrieval pipelines. Creates default pipeline state dictionaries with flags for search status, reranking status, results storage, and random question generation. Also initializes file upload tracking variables. This method ensures consistent state management across the application's execution lifecycle.",
        "size": 1936,
        "parent-class": "SessionState",
        "function_name": "initialize"
    },
    {
        "id": "3d7a0da5-93df-483f-a056-c805dbb0b432",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 50,
        "end_line": 53,
        "content": "def reset_search_result(pipeline_id: str):\n        \"\"\"Reset search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = {}\n\nStatic method in the SessionState class that resets search-related state variables for a specified pipeline, clearing search results and marking the search as not performed. Used for state management within the Streamlit application's RAG pipeline comparison tool.",
        "size": 526,
        "parent-class": "SessionState",
        "function_name": "reset_search_result"
    },
    {
        "id": "89fef6d3-6d0b-48c9-8843-0b6a5eb846e3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 56,
        "end_line": 59,
        "content": "def reset_reranking_result(pipeline_id: str):\n        \"\"\"Reset reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = {}\n\nStatic method within the SessionState class that resets reranking data for a specified pipeline by setting the reranking_performed flag to False and clearing the reranking_results dictionary in the Streamlit session state. This allows for fresh reranking operations without residual data from previous runs.",
        "size": 581,
        "parent-class": "SessionState",
        "function_name": "reset_reranking_result"
    },
    {
        "id": "c536f503-7e97-484e-9029-0925579b08ce",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 62,
        "end_line": 65,
        "content": "def set_search_performed(pipeline_id: str, top_k: int):\n        \"\"\"Mark search as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = True\n        st.session_state.pipeline_states[pipeline_id][\"top_k\"] = top_k\n\nMethod in SessionState class that updates session state variables when a search operation completes successfully. It marks a specific pipeline's search as performed by setting the \"search_performed\" flag to True and stores the top_k parameter value that was used for the search, which is later needed for validation in the reranking process.",
        "size": 613,
        "parent-class": "SessionState",
        "function_name": "set_search_performed"
    },
    {
        "id": "733d371d-32d8-41e3-8338-478a85667bbc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 68,
        "end_line": 70,
        "content": "def set_reranking_performed(pipeline_id: str):\n        \"\"\"Mark reranking as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = True\n\nStatic method in the SessionState class that updates a pipeline's state to indicate reranking has been performed. Part of session state management that tracks pipeline operations in a Streamlit-based RAG (Retrieval Augmented Generation) evaluation application. Works with other methods like reset_reranking_result and store_reranking_results to track the complete reranking workflow for search pipeline comparisons.",
        "size": 613,
        "parent-class": "SessionState",
        "function_name": "set_reranking_performed"
    },
    {
        "id": "bd739b95-b8a7-4a66-bd12-c8189aa29784",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 73,
        "end_line": 75,
        "content": "def set_index_created(pipeline_id: str):\n        \"\"\"Mark index as created for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"index_created\"] = True\n\nStatic method in the SessionState class that updates the session state to mark an index as created for a specific pipeline by setting the \"index_created\" flag to True. This is used in the RAG pipeline comparison tool to track when an index has been successfully created and is ready for search operations.",
        "size": 485,
        "parent-class": "SessionState",
        "function_name": "set_index_created"
    },
    {
        "id": "a80fb15c-22ec-4320-ba42-dd8b44baf743",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 78,
        "end_line": 80,
        "content": "def store_search_results(pipeline_id: str, results: Dict):\n        \"\"\"Store search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = results\n\nA method within the SessionState class for storing first-stage retrieval results in Streamlit's session state. It takes a pipeline identifier and search results dictionary as parameters and associates these results with the specific pipeline in the centralized state management system. This enables persistence of search results between different UI interactions and comparison between pipelines.",
        "size": 597,
        "parent-class": "SessionState",
        "function_name": "store_search_results"
    },
    {
        "id": "39f5d08f-01f5-4ecd-9619-6b3880cb4d6a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 83,
        "end_line": 85,
        "content": "def store_reranking_results(pipeline_id: str, results: Dict):\n        \"\"\"Store reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = results\n\nStatic method within the SessionState class that stores reranking results in the session state for a specific pipeline. Takes a pipeline identifier and results dictionary as parameters and updates the corresponding pipeline's state with the reranking results. Part of the centralized session state management system for tracking RAG pipeline evaluation data.",
        "size": 568,
        "parent-class": "SessionState",
        "function_name": "store_reranking_results"
    },
    {
        "id": "d1c04336-f095-4a25-8785-c29f9399e5cd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 88,
        "end_line": 89,
        "content": "def store_random_question(pipeline_id: str, generated_question: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_question\"] = generated_question\n\nMethod in SessionState class that stores generated random question data for a specific pipeline in the session state, enabling tracking of random questions across pipeline invocations for retrieval evaluation",
        "size": 374,
        "parent-class": "SessionState",
        "function_name": "store_random_question"
    },
    {
        "id": "3eed4429-80a7-454d-9688-75b78d04d037",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 92,
        "end_line": 94,
        "content": "def store_random_question_answer(pipeline_id: str, query: str, results: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_query\"] = query\n        st.session_state.pipeline_states[pipeline_id][\"random_question_results\"] = results\n\nSession state management method for storing random question answer results in the Streamlit application. This method is part of the SessionState class which tracks pipeline states across user sessions. It saves the query string and results dictionary for a specific pipeline, allowing the retrieval pipeline comparison tool to track and display user-initiated query results in the interface.",
        "size": 640,
        "parent-class": "SessionState",
        "function_name": "store_random_question_answer"
    },
    {
        "id": "c4470b6b-047e-4291-ba5d-210ef99ec733",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 100,
        "end_line": 116,
        "content": "def get_embedding_models() -> List[str]:\n        \"\"\"Get list of available embedding models\"\"\"\n        return [\n            \"\",\n            \"llama-text-embed-v2\",\n            \"multilingual-e5-large\",\n            \"embed-english-v3.0\",\n            \"embed-multilingual-v3.0\",\n            \"embed-english-light-v3.0\",\n            \"embed-multilingual-light-v3.0\",\n            \"embed-english-v2.0\",\n            \"embed-english-light-v2.0\",\n            \"embed-multilingual-v2.0\",\n            \"jina-embeddings-v3\",\n            \"jina-clip-v2\",\n            \"voyage-3-large\"\n        ]\n\nStatic method within the ModelRegistry class that returns a list of available text embedding models for use in the RAG pipeline comparison tool. This function is part of the central model management system that catalogs all available embedding options for text retrieval tasks.",
        "size": 849,
        "parent-class": "ModelRegistry",
        "function_name": "get_embedding_models"
    },
    {
        "id": "888086df-72da-43d8-b4b1-92855ae61dd1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 119,
        "end_line": 124,
        "content": "def get_code_embedding_models() -> List[str]:\n        return [\n            \"\",\n            \"jina-embeddings-v2-base-code\",\n            \"voyage-code-3\",\n        ]\n\nA static method in the ModelRegistry class that returns a list of available code-specific embedding models. This function complements the general embedding models method by providing specialized models for code analysis. The returned models include empty string (default/none selection), jina-embeddings-v2-base-code, and voyage-code-3.",
        "size": 499,
        "parent-class": "ModelRegistry",
        "function_name": "get_code_embedding_models"
    },
    {
        "id": "b14aa419-8119-41a6-a05d-e335938a3ef3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 126,
        "end_line": 139,
        "content": "def get_reranking_models() -> List[str]:\n        \"\"\"Get list of available reranking models\"\"\"\n        return [\n            \"\",\n            \"pinecone-rerank-v0\",\n            \"bge-reranker-v2-m3\",\n            \"rerank-v3.5\",\n            \"rerank-english-v3.0\",\n            \"rerank-multilingual-v3.0\",\n            \"jina-reranker-v2-base-multilingual\",\n            \"rereank-lite-1\",\n            \"rerank-2\",\n            \"rerank-1\"\n        ]\n\nStatic method in the ModelRegistry class that returns a list of available reranking model options for the RAG pipeline comparison tool. This function provides the selection options that appear in the UI when configuring reranking components of the search pipeline.",
        "size": 699,
        "parent-class": "ModelRegistry",
        "function_name": "get_reranking_models"
    },
    {
        "id": "253e68a8-ffcc-4a42-84a0-22eae0ba8d4f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 142,
        "end_line": 158,
        "content": "def get_dimensions(dense_embedding_model: str) -> List[int]:\n        \"\"\"Get available dimensions for a specific embedding model\"\"\"\n        model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        return model_to_dimensions.get(dense_embedding_model, [])\n\nStatic method within the ModelRegistry class that returns available dimensions for specified embedding models. Maps model names to their supported vector dimensions using a dictionary lookup. Used during index creation to help users select appropriate dimension values for vector embeddings in the RAG pipeline comparison tool.",
        "size": 1185,
        "parent-class": "ModelRegistry",
        "function_name": "get_dimensions"
    },
    {
        "id": "8eff3e73-d6b2-48e7-9581-ba16544afd56",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 164,
        "end_line": 180,
        "content": "def display_results_tabs(pipeline_id: str):\n        \"\"\"Display results in tabbed interface\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        tab1, tab2 = st.tabs([\"Search Results\", \"Reranking Results\"])\n        \n        with tab1:\n            if pipeline_state[\"search_performed\"]:\n                UIComponents.display_search_results(pipeline_state[\"search_results\"], pipeline_id)\n            else:\n                st.info(\"Run a search to see results here.\")\n        \n        with tab2:\n            if pipeline_state[\"reranking_performed\"]:\n                UIComponents.display_reranking_results(pipeline_state[\"reranking_results\"], pipeline_id)\n            else:\n                st.info(\"Run reranking to see results here.\")\n\nStreamlit UI method in the UIComponents class that creates a tabbed interface for displaying search and reranking results. It checks pipeline state to determine if search or reranking has been performed and displays appropriate results or information messages. Part of a RAG pipeline evaluation tool that presents search metrics in an organized UI structure.",
        "size": 1127,
        "parent-class": "UIComponents",
        "function_name": "display_results_tabs"
    },
    {
        "id": "80cb3cb8-83b1-4a5b-a5a7-b9788d86c6e5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 183,
        "end_line": 196,
        "content": "def display_search_results(results: Dict, pipeline_id: str):\n        \"\"\"Display search results\"\"\"\n        if not results:\n            st.info(\"No search results available.\")\n            return\n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Search metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_search_{pipeline_id}\"\n        )\n        st.json(results, expanded = False)\n\n\nStatic method inside the UIComponents class that formats and displays search results within the Streamlit application. It creates a download button for the results in JSON format and displays the results in a collapsible JSON viewer. The method handles empty result cases with an info message and appends a unique identifier to component keys using the pipeline_id parameter.\n",
        "size": 944,
        "parent-class": "UIComponents",
        "function_name": "display_search_results"
    },
    {
        "id": "c3f51ae5-9d58-4867-80e5-09ae1fadcdba",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 200,
        "end_line": 215,
        "content": "def display_reranking_results(results: Dict, pipeline_id: str):\n        \"\"\"Display reranking results\"\"\"\n        if not results:\n            st.info(\"No reranking results available.\")\n            return\n        \n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Rerank metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_reranking_{pipeline_id}\"\n        )\n        \n        st.json(results, expanded = False)\n\nStatic method in the UIComponents class that renders reranking evaluation results in the Streamlit interface. Displays a message when no results exist, creates a download button for saving metrics as JSON, and renders the results in a collapsible JSON format. Each pipeline has its own uniquely keyed download button.",
        "size": 914,
        "parent-class": "UIComponents",
        "function_name": "display_reranking_results"
    },
    {
        "id": "7de881c9-ff58-4911-ad7a-0464c0d954f3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 218,
        "end_line": 245,
        "content": "def display_random_question(pipeline_id: str):\n\n        if st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"]:\n            results = st.session_state.pipeline_states[pipeline_id][\"random_question\"]\n            question = results[\"question\"]\n\n            if len(results) > 0:\n                st.markdown(f\"### Random Question: \\n> {question}\")\n\n                for i, res in enumerate(results[\"chunks\"]):\n\n                    col1, col2 = st.columns([1, 1])\n                    with col1:\n                        st.markdown(f\"**Ground Truth Chunk {i+1}**\")\n                    with col2:\n                        st.markdown(f\"**ID:** {res['_id']}\")\n                # Create expander for each chunk\n                    with st.expander(\"Ground Truth\", expanded=False):\n                        \n                        # Display the text with wrapping\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"gt_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\n\nStatic method within the UIComponents class that renders the results of a randomly generated question in the Streamlit interface. Displays the question text, followed by expandable UI elements for each ground truth chunk that contains source information. Checks session state to confirm if a random question was generated before attempting to display results.",
        "size": 1604,
        "parent-class": "UIComponents",
        "function_name": "display_random_question"
    },
    {
        "id": "d7de5aa9-8047-4cf0-8820-a48d27f49a65",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 248,
        "end_line": 276,
        "content": "def display_random_question_answer(pipeline_id: str):\n        \n        if st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"]:\n            response = st.session_state.pipeline_states[pipeline_id][\"random_question_results\"]\n            query = st.session_state.pipeline_states[pipeline_id][\"random_query\"]\n            \n            # Container for the results to improve layout\n            if len(response) > 0:\n                st.markdown(\"### Search Results\")\n                st.markdown(f\"**Query:** \\n> {query}\")\n\n                for i, res in enumerate(response):\n                    # Create expander for each chunk\n                    score_indicator = \"\ud83d\udfe9\" if res['score'] > 0.8 else \"\ud83d\udfe7\" if res['score'] > 0.5 else \"\ud83d\udfe5\"\n                    col1, col2 = st.columns([4, 1])\n                    with col1:\n                        st.markdown(f\"**Relevant chunk {i+1}** || **ID:** {res['id']}\")\n                    with col2:\n                        st.markdown(f\"{score_indicator} **Score:** {res['score']:.4f}\")\n\n                    with st.expander(\"**Chunk**\",expanded=False):\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"chunk_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\n        \n\nStatic method in the UIComponents class that displays search results from a random query. It formats results with visual score indicators (green/orange/red emojis based on relevance), creates expandable sections for each chunk, and shows content with appropriate sizing. The method checks if results were generated, retrieves response data from session state, and handles empty result cases with appropriate messaging.",
        "size": 1912,
        "parent-class": "UIComponents",
        "function_name": "display_random_question_answer"
    },
    {
        "id": "1fd3f730-2f96-4783-addb-fbe52d11f0ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 287,
        "end_line": 297,
        "content": " fetch_user_previous_configurations():\n        \"\"\"Fetch user's previous configurations\"\"\"\n        async with httpx.AsyncClient() as client:\n            try:\n                response = await client.get(\n                    f\"{APIClient.BASE_URL}/get-configurations\",\n                    timeout=APIClient.TIMEOUT,\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n    \n   \n\nAsynchronous method in the APIClient class that retrieves a user's previous pipeline configurations by making an HTTP GET request to the /get-configurations endpoint. Returns a tuple containing success status, response object, and error message if applicable. Part of the retrieval system's client-side API communication functionality.",
        "size": 882,
        "parent-class": ":\n    \"\"\"",
        "function_name": "r_previous_configurations():\n     "
    },
    {
        "id": "94e6fa64-473d-4f54-9524-2767903f9cd5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 300,
        "end_line": 315,
        "content": " upload_file(data):\n        \"\"\"Upload a file to the backend service\"\"\"\n        \n        files = {\"file\": data['uploaded_file']}\n        form_data = {\"file_type\" : data[\"file_type\"]}\n\n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/upload-files\",\n                    files=files,\n                    data=form_data\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nFile upload method within the APIClient class that posts files to a backend endpoint. Handles HTTP requests asynchronously using httpx, constructs multipart form data with file and file type, and returns a standardized tuple response with success status, response object, and error message if applicable.",
        "size": 987,
        "parent-class": ":\n    \"\"\"",
        "function_name": "le(data):\n "
    },
    {
        "id": "19872ebd-1688-4bee-a59d-3e9f10427caa",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 318,
        "end_line": 335,
        "content": " create_index(file_name: str, embed_model: str, similarity_metric: str, dimension: int) -> Tuple[bool, str]:\n        \"\"\"Create an index and upsert dataset\"\"\"\n        payload = {\n            \"file_name\": file_name,\n            \"embed_model\": embed_model,\n            \"similarity_metric\": similarity_metric,\n            \"dimension\": dimension,\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/index-upsert\",\n                    json=payload,\n                )\n                return response.status_code == 200, response.json()[\"error\"] if response.status_code != 200 else \"\"\n            except Exception as e:\n                return False, str(e)\n        \n\nAPI method within the APIClient class that handles index creation by sending an HTTP POST request to the backend service. This asynchronous function collects file name, embedding model, similarity metric, and dimension parameters to create a new vector index and populate it with document data. Returns a success flag and error message if applicable. Part of a RAG pipeline evaluation system's client-side API communication layer.",
        "size": 1239,
        "parent-class": ":\n    \"\"\"",
        "function_name": "dex(file_nam"
    },
    {
        "id": "7f535ffb-e9db-438e-b963-638bfdbf6bd2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 338,
        "end_line": 366,
        "content": " perform_search(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform a search query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/query\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_result\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nStatic method in the APIClient class that performs vector search against a backend API. Handles sending a search query with configurable parameters including hybrid search options, embedding model, dimensions, and similarity metrics. Returns a tuple containing success status, evaluation results, and error message if applicable. Part of the retrieval pipeline in the RetrieveWise application.",
        "size": 1630,
        "parent-class": ":\n    \"\"\"",
        "function_name": "earch(is_hybri"
    },
    {
        "id": "1f97602d-a02d-4177-970c-6dea086700dc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 369,
        "end_line": 390,
        "content": " perform_reranking(model_name: str, top_n: int, top_k: int) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform reranking\"\"\"\n        payload = {\n            \"model_name\": model_name,\n            \"top_n\": top_n,\n            \"top_k\": top_k\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/rerank\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_metrics\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nAsynchronous method within the APIClient class that makes a POST request to the rerank endpoint, sending specified reranking parameters (model name, top_n, and top_k). Returns a tuple containing success status, evaluation metrics from the response, and error message if applicable. Part of the retrieval-augmented generation (RAG) pipeline that handles the reranking stage of search results.",
        "size": 1260,
        "parent-class": ":\n    \"\"\"",
        "function_name": "eranking(model_na"
    },
    {
        "id": "89d416fb-80ab-42c0-967e-cb9dd85c7d49",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 393,
        "end_line": 411,
        "content": " random_question(file_name: str) -> Tuple[bool, Dict, str]:\n        \"\"\"Generate a random question\"\"\"\n        payload = {\n            \"file_name\": file_name\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-question\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nAPI method within the APIClient class for generating a random question based on a file. It sends an asynchronous HTTP POST request to the server endpoint, handles response processing, and returns a tuple containing success status, response data, and error information. Part of the RAG pipeline comparison tool's backend communication functionality.",
        "size": 1091,
        "parent-class": ":\n    \"\"\"",
        "function_name": "estion(file_nam"
    },
    {
        "id": "1d41b23f-56a3-441c-bcea-d65a67e29de3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 414,
        "end_line": 442,
        "content": " random_query(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, query: str, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None):\n        \"\"\"Perform a random query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n            \"query\": query,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-query\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nStatic method in the APIClient class that performs custom searches with configurable parameters. It constructs a payload with search configuration, handles optional hybrid search parameters (alpha or similarity metric), makes an asynchronous HTTP request to the random-query endpoint, and returns a tuple containing success status, response data, and error message if applicable. This enables users to test search functionality with arbitrary queries rather than using evaluation datasets.",
        "size": 1687,
        "parent-class": ":\n    \"\"\"",
        "function_name": "ery(is_hybri"
    },
    {
        "id": "fc67a602-4b04-4140-876a-50cc202db020",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 448,
        "end_line": 500,
        "content": " index_creation_section(pipeline_id: str, is_hybrid: bool) -> bool:\n        \"\"\"Handle index creation section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = \"\"\n        if st.session_state.get(f'file_type', None) == \"Code\":\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_code_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        else:\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        \n        dimensions = ModelRegistry.get_dimensions(dense_embedding_model)\n        dense_dimension = st.selectbox(\n            \"Enter Dimension of the Dense Model:\",\n            dimensions,\n            key=f\"dense_dimension_{pipeline_id}\",\n        )\n        \n        if not dense_embedding_model or not dense_dimension:\n            st.warning(\"Please select the required models and dimensions.\")\n            return False\n        \n        similarity_metric = \"dotproduct\"\n        if not is_hybrid:\n            similarity_metric = st.selectbox(\n                \"Enter Similarity Metric:\",\n                [\"dotproduct\", \"cosine\", \"euclidean\"],\n                key=f\"similarity_metric_{pipeline_id}\",\n            )\n        else:\n            st.warning(\"By default, dot product similarity is used for the hybrid search.\")\n        \n        if st.button(\"Create Index and Upsert Dataset\", key=f\"create_index_{pipeline_id}\"):\n            with st.spinner(\"Creating index and upserting dataset...\"):\n                success, error_msg = await APIClient.create_index(\n                    file_name, dense_embedding_model, similarity_metric, dense_dimension\n                )\n                \n                if success:\n                    st.success(\"Index created and dataset upserted successfully!\")\n                    SessionState.set_index_created(pipeline_id)\n                else:\n                    st.error(f\"Index creation and dataset upsert failed: {error_msg}\")\n        \n        return pipeline_state[\"index_created\"]\n    \n   \n\nA static method in the PipelineManager class that handles the index creation UI section in the RAG pipeline. It manages embedding model selection (different options for code vs text), dimension selection, similarity metric configuration, and index creation through the API. The method renders UI components like dropdowns and buttons, handles user selections, and communicates with the backend to create indexes with selected parameters. It returns a boolean indicating whether the index is ready for use in subsequent pipeline steps.",
        "size": 2893,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ation_section(pipeline"
    },
    {
        "id": "175cda02-32ac-4cca-89ea-3ae45f650e6f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 503,
        "end_line": 554,
        "content": " search_section(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Handle search section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.number_input(\"Enter the value for top_k:\", min_value=1, value=\"min\", step=1, key=f\"top_k_{pipeline_id}\")\n        \n        alpha = None\n        if is_hybrid:\n            alpha = st.slider(\n                \"Select alpha value (between 0 and 1):\",\n                min_value=0.0,\n                max_value=1.0,\n                step=0.1,\n                value=0.5,\n                key=f\"alpha_{pipeline_id}\",\n            )\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get First Stage Evaluation Metrics\",\n                key=f\"perform_search_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing search...\"):\n                    success, results, error_msg = await APIClient.perform_search(\n                        is_hybrid=is_hybrid,\n                        file_name=file_name,\n                        embedding_model=dense_embedding_model,\n                        dimension=dense_dimension,\n                        top_k=top_k,\n                        similarity_metric=similarity_metric,\n                        alpha=alpha,\n                    )\n                    \n                    if success:\n                        st.success(\"Search performed successfully!\")\n                        SessionState.store_search_results(pipeline_id, results)\n                        SessionState.set_search_performed(pipeline_id, top_k)\n                    else:\n                        st.error(f\"First stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_similarity_{pipeline_id}\",\n            ):\n                SessionState.reset_search_result(pipeline_id)\n    \n   \n\nAsynchronous method in the PipelineManager class that creates the search configuration UI section and handles search functionality. Retrieves session parameters, configures search parameters including embedding model settings and top_k value, provides hybrid search options with alpha parameter slider when enabled, sends search requests to the API, and manages search result storage. Features buttons for executing searches and resetting results with appropriate session state updates.",
        "size": 2767,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ction(pipeline"
    },
    {
        "id": "27b9d6e5-07bf-4c52-badf-ed6bfe73876e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 557,
        "end_line": 605,
        "content": " reranking_section(pipeline_id: str):\n        \"\"\"Handle reranking section of the UI\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        if not pipeline_state[\"search_performed\"] or not pipeline_state[\"search_results\"]:\n            return\n        \n        reranking_model = st.selectbox(\n            \"Select Reranking Model:\",\n            ModelRegistry.get_reranking_models(),\n            key=f\"reranking_model_{pipeline_id}\",\n        )\n        \n        top_n = st.number_input(\"Enter the value for top_n:\", min_value=1, value=\"min\", step=1, key=f\"top_n_{pipeline_id}\")\n        \n        if pipeline_state[\"top_k\"] < top_n:\n            st.warning(\"The value of top_n should be less than or equal to the value of top_k.\")\n            return\n        \n        if not reranking_model or not top_n:\n            st.warning(\"Please select the reranking model and enter the top_n value.\")\n            return\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get Reranking Evaluation Metrics\",\n                key=f\"perform_reranking_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing reranking...\"):\n                    success, results, error_msg = await APIClient.perform_reranking(\n                        model_name=reranking_model,\n                        top_n=top_n,\n                        top_k=pipeline_state[\"top_k\"],\n                    )\n                    \n                    if success:\n                        st.success(\"Reranking performed successfully!\")\n                        SessionState.store_reranking_results(pipeline_id, results)\n                        SessionState.set_reranking_performed(pipeline_id)\n                    else:\n                        st.error(f\"Second stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_reranked_{pipeline_id}\",\n            ):\n                SessionState.reset_reranking_result(pipeline_id)\n        \n\nStatic method in PipelineManager class that handles the reranking functionality in the RAG pipeline UI. Creates UI controls for selecting reranking models and parameters, validates user inputs, makes API calls to perform reranking operations, and handles success/error states. Integrates with SessionState for maintaining pipeline state across the application flow. Part of a larger pipeline comparison tool for evaluating retrieval performance.",
        "size": 2528,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "_section(pipeline"
    },
    {
        "id": "a1c8399b-a0e9-4417-a8d9-281aa4223347",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 608,
        "end_line": 627,
        "content": " random_question_section(pipeline_id: str):\n        if \"file_name\" in st.session_state:\n            file_name = st.session_state.file_name\n            \n            if st.button(\n                \"Get random question\",\n                key=f\"generate_random_question_{pipeline_id}\",\n            ):\n                with st.spinner(\"processing random question...\"):\n                    success, response, error_msg = await APIClient.random_question(file_name)\n                    \n                    if success:\n                        st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"] = True\n                        SessionState.store_random_question(pipeline_id = pipeline_id, generated_question = response)\n\n                    else:\n                        st.error(f\"Random question generation failed: {error_msg}\")\n\n        else:\n            st.warning(\"No file selected. Please upload a file first.\")\n        \n\nStatic method in the PipelineManager class that generates a random question for evaluation purposes. It checks if a file has been uploaded, displays a button for question generation, makes an API call to get a random question based on the uploaded file, and updates the session state with the results. This method is part of the RAG (Retrieval Augmented Generation) pipeline evaluation flow, allowing users to test retrieval performance with randomly generated questions against the document corpus.",
        "size": 1438,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "estion_section(pipeline"
    },
    {
        "id": "24d6395b-55cf-455f-93bd-cf3a863a778d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 630,
        "end_line": 670,
        "content": " random_query_section(pipeline_id: str):\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.session_state.get(f\"top_k_{pipeline_id}\", 0)\n        is_hybrid = st.session_state.get(f\"hybrid_search_{pipeline_id}\", \"No\") == \"Yes\"\n        alpha = st.session_state.get(f\"alpha_{pipeline_id}\", None)\n            \n        query = st.text_input(\"Enter the query for random search:\", key=f\"query_{pipeline_id}\")\n        \n        if not query:\n            st.warning(\"Please enter a query for random search.\")\n            return\n        \n        if st.button(\n            \"Search custom query\", \n            key=f\"search_custom_query_{pipeline_id}\"\n        ):\n            with st.spinner(\"Performing search...\"):\n                success, response, error_msg = await APIClient.random_query(\n                    is_hybrid=is_hybrid,\n                    file_name=file_name,\n                    embedding_model=dense_embedding_model,\n                    dimension=dense_dimension,\n                    top_k=top_k,\n                    query=query,\n                    similarity_metric=similarity_metric,\n                    alpha=alpha,\n                )\n                \n                if success:\n                    st.success(\"Search performed successfully!\")\n                    st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"] = True\n                    SessionState.store_random_question_answer(pipeline_id = pipeline_id, query=query, results = response)\n                        \n                else:\n                    st.error(f\"Error performing search: {error_msg}\")\n    \n   \n\nImplements the custom query functionality in the PipelineManager class, allowing users to enter and search an arbitrary query against the selected index. Retrieves necessary configuration parameters from session state, handles the UI for query input, executes the search via the APIClient's random_query method, and stores results for display. Part of the RAG pipeline evaluation workflow that enables testing specific queries alongside the main evaluation metrics.",
        "size": 2457,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ery_section(pipeline"
    },
    {
        "id": "85dbcb83-7a97-448d-9f16-dea7144eb1f4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 673,
        "end_line": 691,
        "content": " run_pipeline(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Run a complete RAG pipeline\"\"\"\n\n        index_ready = await PipelineManager.index_creation_section(pipeline_id, is_hybrid)\n        \n        if index_ready:\n            \n            await PipelineManager.search_section(pipeline_id, is_hybrid)\n            \n            await PipelineManager.reranking_section(pipeline_id)\n            \n            await PipelineManager.random_question_section(pipeline_id)\n            UIComponents.display_random_question(pipeline_id=pipeline_id)\n            \n            await PipelineManager.random_query_section(pipeline_id)\n            UIComponents.display_random_question_answer(pipeline_id=pipeline_id)\n        \n        st.subheader(\"Results\")\n        UIComponents.display_results_tabs(pipeline_id)\n        \n\nStatic method in the PipelineManager class that orchestrates the entire Retrieval Augmented Generation (RAG) workflow sequence. It coordinates the pipeline execution by: creating indexes, performing search retrieval, applying reranking, generating random questions, and displaying results through the UI. The method controls the flow between different pipeline stages, only proceeding with search operations if the index creation is successful. It represents the central coordination point for executing complete RAG pipelines with specified configurations in the application.",
        "size": 1383,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ine(pipeline"
    },
    {
        "id": "5f8c0942-a624-4305-ba25-8d1ebff8df81",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 693,
        "end_line": 721,
        "content": " handle_file_upload():\n    \"\"\"Handle file upload\"\"\"\n    file_type = st.radio(\"Select File Type:\", [\"Text\", \"Code\"])\n    if \"file_type\" not in st.session_state:\n        st.session_state.file_type = file_type\n    st.session_state.file_type = file_type\n\n\n    uploaded_file = st.file_uploader(\"Upload a file:\", type=[\"json\"])\n    \n    if uploaded_file and not st.session_state.file_uploaded:\n        with st.spinner(\"Uploading file...\"):\n            data = {\"uploaded_file\": uploaded_file, \"file_type\": file_type}\n            success, response, error_msg = await APIClient.upload_file(data)\n\n            if success:\n                success_message = response.json()[\"detail\"]\n                st.success(f\"Success Message: {success_message}\")\n\n                st.session_state.file_uploaded = True\n                st.session_state.file_name = uploaded_file.name\n\n                st.write(\"Here is the schema of the uploaded file:\")\n                st.json(response.json()[\"data\"][\"file_schema\"])\n            else:\n                st.error(f\"Upload failed: {error_msg}\")\n\n    \n    return st.session_state.file_uploaded\n\nasync d\n\nFile upload handler function for a Streamlit RAG evaluation app that manages the user interface for uploading JSON files, processes the upload through an API client, and updates session state with upload status and file metadata. The function captures file type selection (Text/Code), handles API responses including displaying file schema, and returns the upload status for downstream pipeline configuration.",
        "size": 1532,
        "parent-class": null,
        "function_name": "le_upload():\n    \""
    },
    {
        "id": "ec6946a8-651c-414b-81e7-a0d702a37591",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 723,
        "end_line": 788,
        "content": " main():\n    \"\"\"Main application entry point\"\"\"\n    \n    SessionState.initialize()\n    \n    st.set_page_config(\n        page_title=\"RAG Pipeline Comparison Tool | Pinecone\",\n        layout=\"wide\",\n        page_icon=\"\ud83e\uddca\",\n    )\n    \n    st.title(\"RetrieveWise\")\n    st.divider()\n    st.markdown(\n        \"\"\"\n        Compare and Evaluate different Information Retrieval Pipelines, Configure two retrieval pipelines side by side \n        with different settings, embedding models, rerankers. Once set compare key performance metrics like precision, recall\n        NDCG, MRR, F1 etc \n    \"\"\"\n    )\n    \n    success, response, error_msg = await APIClient.fetch_user_previous_configurations()\n    \n    if success:\n        data = response.json().get(\"data\", None)\n        if isinstance(data, dict) and \"message\" in data:\n            st.info(data[\"message\"])\n        else:\n            st.write(\"Here are your previous configurations:\")\n            st.json(response.json()[\"data\"], expanded = False)\n    else:\n        st.error(f\"Failed to fetch previous configurations: {error_msg}\")\n    \n    file_uploaded = await handle_file_upload()\n    \n    if not file_uploaded:\n        st.warning(\"Please upload the JSON files for the pipelines to compare.\")\n        return\n\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.header(\"Pipeline 1\")\n        hybrid_search_1 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_1\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"1\", \n            is_hybrid=(hybrid_search_1 == \"Yes\")\n        )\n        \n    with col2:\n        st.header(\"Pipeline 2\")\n        hybrid_search_2 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_2\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"2\", \n            is_hybrid=(hybrid_search_2 == \"Yes\")\n        )\n        \nif\n\nMain application function that initializes the Streamlit interface for the RetrieveWise tool. Sets up the page configuration, displays the application title and description, fetches user configurations from the API, handles file upload process, and creates two parallel pipeline configurations for side-by-side comparison. Each pipeline allows selection of hybrid search options and calls the PipelineManager to set up and run retrieval pipelines with different embedding models and rerankers for comparative evaluation of information retrieval metrics.",
        "size": 2569,
        "parent-class": null,
        "function_name": "   \""
    },
    {
        "id": "fa011841-3000-47b9-939c-e8cc3d4de9c6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom app.apis import file_upload, index_upsert_route, query, reranking_router, configuration_route, random_question_route, random_query_route\nfrom app.config.database import db_helper\n\nImport statements for a FastAPI application that implements a RAG Playground. Imports the asynccontextmanager for database lifecycle management, FastAPI framework, various API route modules (file upload, indexing, querying, reranking, configuration, random questions/queries), and a database helper from the app configuration.",
        "size": 582,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b51de8d5-00a0-4b5d-8abe-f2cb52911e9c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 10,
        "end_line": 14,
        "content": "async def lifespan(app: FastAPI):\n    await db_helper.connect()\n    db = await db_helper.get_db()\n    yield\n    await db_helper.disconnect()\n\nFastAPI application lifecycle management function that connects to the database at application startup, obtains a database connection, and ensures proper disconnection when the application shuts down. This async context manager handles database connection lifecycle for the RAG Playground API.",
        "size": 435,
        "parent-class": null,
        "function_name": "lifespan"
    },
    {
        "id": "78c47ff4-d309-473b-86f4-5ddbcc9c1885",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 30,
        "end_line": 31,
        "content": "async def root():\n    return {\"message\": \"Welcome to the RAG Playground\"}\n\nRoot endpoint handler for the FastAPI application that returns a welcome message for the RAG Playground. This function is decorated with @app.get(\"/\") to serve as the application's homepage endpoint, providing a simple greeting when users access the base URL. Part of the main application setup alongside database connection management and router inclusion.",
        "size": 432,
        "parent-class": null,
        "function_name": "root"
    },
    {
        "id": "61fcbca7-9454-4d73-a3a6-94f8a866895f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.query_controller import QueryController\nfrom app.models.schemas.query_schema import QueryEndPointRequest\n\nImport statements for FastAPI router component that manages query endpoints, including dependencies for API response handling, error handling decorator, query controller, and request schema model.",
        "size": 467,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b45fe59a-872c-4c88-9591-47b6433decf5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 12,
        "end_line": 26,
        "content": "async def make_query(\n    request: QueryEndPointRequest, query_controller: QueryController = Depends()\n):\n\n    response_data = await query_controller.make_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Query execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI route handler function that processes query requests. Accepts a QueryEndPointRequest payload, delegates to QueryController for query execution, and returns a structured JSON response with data and status information. Part of a RESTful API endpoint for executing queries with proper error handling.",
        "size": 721,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "7cac2ea1-fb80-4810-b130-e7e5b8860fb2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.models.schemas.random_query_schema import RandomQueryRequest\nfrom app.controllers.random_query_controller import RandomQueryController\n\nImport statements for FastAPI router implementation of the random query endpoint, including dependencies for error handling, schema validation, and controller integration.",
        "size": 460,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b0a8c98a-aced-4c48-8dbf-8345a3b6702e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 13,
        "end_line": 28,
        "content": "async def random_query(\n    request: RandomQueryRequest,\n    random_query_controller: RandomQueryController = Depends(),\n):\n\n    response = await random_query_controller.random_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Query Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI route handler function for processing random queries through a POST endpoint. Accepts a RandomQueryRequest payload, delegates processing to a RandomQueryController dependency, and returns a structured JSON response with HTTP 200 status on successful query generation. Part of an API router implementation with error handling decoration.",
        "size": 815,
        "parent-class": null,
        "function_name": "random_query"
    },
    {
        "id": "da4d3f11-833c-4935-9b2e-e4f78fd9f7fe",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.random_question_controller import RandomQuestionController\n\nImport statements for a FastAPI router that handles random question generation, including dependencies for API routing, response handling, data validation, error handling, and the RandomQuestionController that contains the core business logic.",
        "size": 499,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c769e0a2-2c20-424d-970c-e839483e6ab1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 16,
        "end_line": 31,
        "content": "async def random_question(\n    request: RQRequest,\n    random_question_controller: RandomQuestionController=Depends(),\n):\n\n    response = await random_question_controller.random_question(request.file_name)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Question Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler that processes random question requests. Takes an RQRequest object containing a file_name parameter and a RandomQuestionController dependency, calls the controller's random_question method with the provided file name, and returns a structured JSON response with HTTP 200 status code. Part of a router for random question generation functionality.",
        "size": 859,
        "parent-class": null,
        "function_name": "random_question"
    },
    {
        "id": "11bd5501-9534-4a61-b26d-5db2a70af7cc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/configuration_route.py",
        "file_name": "configuration_route.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.config_controller import ConfigurationController\n\nAPI router imports for configuration endpoint that fetches system configurations, including FastAPI components, error handling decorators, and the controller class that manages configuration operations.",
        "size": 417,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b729299a-7ae9-4dcd-aeb5-ca6c2c71b81c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/configuration_route.py",
        "file_name": "configuration_route.py",
        "start_line": 11,
        "end_line": 25,
        "content": "async def make_query(\n    config_controller: ConfigurationController = Depends()\n):\n\n    response_data = await config_controller.get_config()\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Configuration fetching successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler function for GET route \"/get-configurations\" that retrieves application configurations through the ConfigurationController dependency. Returns a standardized JSONResponse with the configuration data and success status. Part of a router implementing configuration retrieval functionality.",
        "size": 707,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "42364170-10c0-4e6e-9888-77278de3d4ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Body, Depends,status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.reranking_controller import RerankingController\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest\n)\n\nImport statements for a FastAPI reranking endpoint, importing router components, response handling, error handling, the reranking controller, and schema definitions that define the expected request format for document reranking operations.",
        "size": 531,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "0d1723a5-9e85-4330-a12b-4b42bce58b61",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 15,
        "end_line": 31,
        "content": "async def rerank_documents(\n    request: RerankingRequest = Body(...),\n    controller: RerankingController = Depends(),\n):\n    \n    response_data = await controller.rerank_documents(request)\n    response = response_data.model_dump()\n\n    return JSONResponse(\n        content={\n            \"data\": response,\n            \"statuscode\": 200,\n            \"detail\": \"Rerank execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nReranking API endpoint handler that processes document reranking requests using FastAPI. The function accepts a RerankingRequest body, delegates processing to the RerankingController, transforms the controller response to a dictionary, and returns a standardized JSONResponse with successful reranking status information.",
        "size": 796,
        "parent-class": null,
        "function_name": "rerank_documents"
    },
    {
        "id": "ad3c6e99-9555-484a-91d6-4004dca0b832",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.index_upsert_controller import IndexUpsertController\nfrom app.models.schemas.index_upsert_schema import IndexUpsertRequest\n\nImport statements for FastAPI router with dependencies for index upsert endpoint. Includes error handling utilities, controller class, and request schema model for data indexing operations.",
        "size": 478,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "187fcb08-46e2-4adc-9a5b-a7aa29b0fabb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 13,
        "end_line": 30,
        "content": "async def index_upsert(\n    request: IndexUpsertRequest,\n    index_upsert_controller: IndexUpsertController = Depends(\n        IndexUpsertController\n    ),\n):\n    \n    response = await index_upsert_controller.index_upsert(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"host\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Upserted Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler for index-upsert operations. Receives IndexUpsertRequest data, processes it through IndexUpsertController, and returns a formatted JSONResponse with successful operation details. Implements dependency injection for controller access. Part of a router definition for document indexing functionality.",
        "size": 815,
        "parent-class": null,
        "function_name": "index_upsert"
    },
    {
        "id": "337e825d-a784-4577-aadb-42c2dfcdc16e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, UploadFile, File, status, Form\nfrom fastapi.responses import JSONResponse\nfrom app.controllers.file_upload_controller import FileUploadController\nfrom app.utils.error_handler import handle_exceptions\nimport logging\n\nImport statements for FastAPI file upload endpoint, including dependencies for API routing, file handling, form data processing, status codes, JSON responses, error handling, and logging functionality.",
        "size": 457,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "308f0153-234c-47e3-84ff-5c302fbacab6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 14,
        "end_line": 32,
        "content": "async def upload_files(\n    file_type: str = Form(),\n    file: UploadFile = File(...),\n    file_controller: FileUploadController = Depends(),\n):\n    response_data = await file_controller.upload_files({\n        \"input_data\": file,\n        \"file_name\": file.filename,\n        \"file_type\": file_type\n    })\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": response_data[\"data\"],\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI route handler function for file uploads that accepts a file type via form data, a file upload, and a FileUploadController dependency. Processes the upload through the controller and returns a standardized JSON response with HTTP 200 status. Part of a router endpoint defined at \"/upload-files\" and decorated with error handling.",
        "size": 877,
        "parent-class": null,
        "function_name": "upload_files"
    },
    {
        "id": "1c635619-373a-49e6-aeb2-d7d3c36b2caf",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from motor.motor_asyncio import AsyncIOMotorClient\nfrom app.config.settings import settings\n\nMongoDB connection module imports for an async database helper class, featuring AsyncIOMotorClient from the motor library and application settings configuration.",
        "size": 254,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "2b3e12f5-77d0-49ec-b719-5967d8436480",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 7,
        "end_line": 13,
        "content": "def __init__(self):\n        self.client = AsyncIOMotorClient(settings.MONGODB_URL)\n        self.db = self.client[settings.DATABASE_NAME]\n        self.raw_data = self.db[\"raw_data\"]\n        self.index_upsert_collection = self.db[\"index_upsert\"]\n        self.gt_data = self.db[\"gt_data\"]\n        self.query_embeddings_collection = self.db[\"query_embeddings\"]\n\nMongoDB database initialization method within DBHelper class that establishes connection and references to collections including raw_data, index_upsert, gt_data, and query_embeddings using AsyncIOMotorClient for asynchronous database operations.",
        "size": 603,
        "parent-class": "DBHelper",
        "function_name": "__init__"
    },
    {
        "id": "11dcdaeb-6e49-425b-b806-2f2948de836e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 15,
        "end_line": 33,
        "content": "async def connect(self):\n        try:\n            if self.client is None:\n                self.client = AsyncIOMotorClient(\n                    settings.MONGODB_URL,\n                    maxPoolSize=1000,\n                    minPoolSize=50,\n                    maxIdleTimeMS=50000,\n                    connectTimeoutMS=20000,\n                )\n\n                self.db = self.client[settings.DATABASE_NAME]\n                await self.client.admin.command(\"ping\")\n                await self.create_collections()\n\n        except Exception as e:\n            if self.client:\n                await self.disconnect()\n            raise\n\nAsynchronous MongoDB connection method within DBHelper class that establishes a connection with specific pool configurations, pings the database to verify connectivity, creates required collections, and includes error handling with cleanup on failure. Used for initializing the MongoDB client with optimized connection parameters.",
        "size": 959,
        "parent-class": "DBHelper",
        "function_name": "connect"
    },
    {
        "id": "d4bb5b5e-1451-49e7-9d1c-a6ae679741e7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 35,
        "end_line": 40,
        "content": "async def create_collections(self):\n        required_collections = [\"raw_data\", \"gt_data\"]\n        existing_collections = await self.db.list_collection_names()\n        for collection in required_collections:\n            if collection not in existing_collections:\n                await self.db.create_collection(collection)\n\nDatabase initialization method that checks for required MongoDB collections and creates them if missing. Part of the DBHelper class responsible for MongoDB connection management in an async application. Ensures \"raw_data\" and \"gt_data\" collections exist before proceeding with database operations.",
        "size": 621,
        "parent-class": "DBHelper",
        "function_name": "create_collections"
    },
    {
        "id": "a88b533c-b1ff-41ed-83c8-c9d740bb15c7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 42,
        "end_line": 45,
        "content": "async def get_db(self):\n        if self.client is None:\n            await self.connect()\n        return self.db\n\nMongoDB database connection method that checks if a client connection exists, establishes one if needed, and returns the database instance for async operations in a FastAPI application",
        "size": 297,
        "parent-class": "DBHelper",
        "function_name": "get_db"
    },
    {
        "id": "b487d24f-f201-4b76-8ed4-7738d8f4f33c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 47,
        "end_line": 51,
        "content": "async def disconnect(self):\n        if self.client:\n            self.client.close()\n            self.client = None\n            self.db = None\n\nMongoDB connection cleanup method that closes the database client connection and resets client and database instance variables to None when the application terminates or needs to disconnect from the database.",
        "size": 351,
        "parent-class": "DBHelper",
        "function_name": "disconnect"
    },
    {
        "id": "9029c537-3ee2-43b2-a44d-d92b5fc319e9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/settings.py",
        "file_name": "settings.py",
        "start_line": 1,
        "end_line": 1,
        "content": "from pydantic_settings import BaseSettings\n\nImport statement for BaseSettings class from pydantic_settings package, used to create the application configuration class that handles environment variables and validation in this settings module.",
        "size": 241,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "e67d35d2-ad5b-474a-aaa3-22d4a1cf0936",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import os\nimport json\nimport logging\nfrom datetime import datetime\n\nPython imports for file system operations, JSON processing, logging framework, and date-time handling in a structured logging module",
        "size": 200,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "db37e136-3b20-46ef-8e6f-3e10a0c130df",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 8,
        "end_line": 27,
        "content": "def format(self, record):\n        log_entry = {\n            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n            \"levelname\": record.levelname,\n            \"module\": record.module,\n            \"funcName\": record.funcName,\n            \"lineno\": record.lineno\n        }\n\n        message = record.getMessage()\n        try:\n            parsed_message = json.loads(message)\n            log_entry[\"message\"] = json.dumps(parsed_message, indent=4, ensure_ascii=False)\n        except json.JSONDecodeError:\n            log_entry[\"message\"] = message\n        \n        if record.args:\n            log_entry[\"extra\"] = record.args\n            \n        return json.dumps(log_entry, ensure_ascii = False, indent=4)\n\nFormat method within JSONFormatter logging class that converts log records into structured JSON format. Creates a log entry dictionary with timestamp, level, module, function name, and line number. Attempts to parse messages as JSON, falling back to plain text if parsing fails. Includes record arguments as extra data and returns the formatted log entry as a JSON string with indentation.",
        "size": 1109,
        "parent-class": "JSONFormatter",
        "function_name": "format"
    },
    {
        "id": "890e9c92-a970-4989-98b0-8d9241455a1b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 29,
        "end_line": 52,
        "content": "def setup_logger(name: str, log_file: str, log_dir: str = \"struct_logs\", level=logging.INFO) -> logging.Logger:\n    \"\"\"\n    Sets up a logger with a specified name and log file.\n    \n    Args:\n        name (str): The name of the logger.\n        log_file (str): The name of the log file.\n        log_dir (str): Directory where logs will be stored.\n        level (int): Logging level (default: logging.INFO).\n    \n    Returns:\n        logging.Logger: Configured logger instance.\n    \"\"\"\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    handler = logging.FileHandler(log_path)\n    handler.setFormatter(JSONFormatter())\n\n    logger.addHandler(handler)\n    return logger\n\nFunction that creates and configures a structured JSON-based logging system. Creates the log directory if it doesn't exist, establishes a logger with the specified name, sets its level, creates a file handler with the custom JSONFormatter, and returns the configured logger. Used to initialize the various loggers defined in the loggers dictionary for different components (Pinecone, OpenAI, Cohere, etc.).",
        "size": 1180,
        "parent-class": null,
        "function_name": "setup_logger"
    },
    {
        "id": "abe4e242-d3c2-4659-962d-3449de954668",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nfrom typing import Dict, List\nimport httpx\nfrom app.config.settings import Settings\nfrom app.prompts import rag_generation\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers\n\nImport statements for the LLMUtils class, including dependencies for HTTP requests, logging, JSON handling, type annotations, and application-specific modules needed for OpenAI API integration and RAG functionality.",
        "size": 443,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "3019401e-be19-4b89-a5cf-599507667119",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 11,
        "end_line": 24,
        "content": "def __init__(self):\n        self.settings = Settings()\n        self.rag_generation = rag_generation\n        self.OPENAI_BASE_URL = self.settings.OPENAI_BASE_URL \n        self.model = self.settings.OPENAI_MODEL\n        self.openai_api_key = self.settings.OPENAI_API_KEY\n        self.OPENAI_CHAT_SUFFIX = \"chat/completions\"\n        self.openai_url = f\"{self.OPENAI_BASE_URL}/{self.OPENAI_CHAT_SUFFIX}\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nConstructor method for the LLMUtils class that initializes OpenAI API connection parameters. Sets up API endpoints, authentication credentials, model selection, and configures HTTP request timeouts. Part of a utility class for making LLM API calls to OpenAI's chat completion service.",
        "size": 1028,
        "parent-class": "LLMUtils",
        "function_name": "__init__"
    },
    {
        "id": "6808cdaf-08af-4492-ac81-3cef665e4965",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 26,
        "end_line": 53,
        "content": "async def _make_openai_request(\n        self, messages: List[Dict[str, str]], **params\n    ):\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.openai_api_key}\",\n        }\n\n        data = {\"model\": self.model, \"messages\": messages, **params}\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(\n                    self.openai_url, headers=headers, json=data\n                )\n                \n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {e.response.text}\")\n            raise HTTPException(detail = f\"error in openai call httpx error : {str(e)} - {e.response.text}\", status_code = e.response.status_code)\n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\n        except Exception as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\n\nCore HTTP helper method within LLMUtils class for making asynchronous API calls to OpenAI's chat completion endpoint. Handles request formatting, authentication, error handling with specific exception types for different failure scenarios, and proper logging. Used by other class methods like generate_questions and generate_multi_chunk_question to communicate with OpenAI's API.",
        "size": 1652,
        "parent-class": "LLMUtils",
        "function_name": "_make_openai_request"
    },
    {
        "id": "5249fa8f-64d8-40b7-88f1-d920b1779377",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 55,
        "end_line": 80,
        "content": "async def generate_questions(self, chunk: str):\n        user_msg = f\"Text chunk:\\n{chunk}\"\n\n        response = await self._make_openai_request(\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": self.rag_generation.GENERATE_QUESTIONS_PROMPT,\n                },\n                {\"role\": \"user\", \"content\": user_msg}\n            ],\n            temperature=0.3,\n            max_tokens=512\n        )\n        print(json.dumps(response, indent=4))\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n\n\n        if \"error\" in response:\n            return [\"Could not generate questions - API error\"]\n\n        content = response[\"choices\"][0][\"message\"][\"content\"]\n        return [q.strip() for q in content.split(\"\\n\") if q.strip()]\n\nLLM utility method for generating questions from a text chunk via OpenAI API. The method formats a request with system and user prompts, calls the API with specified parameters, logs token usage, handles errors, and processes the resulting content by splitting it into individual questions. Part of a larger RAG system for question generation from document chunks.",
        "size": 1207,
        "parent-class": "LLMUtils",
        "function_name": "generate_questions"
    },
    {
        "id": "e3730a89-0c77-43f4-8a22-bd78e16d3bed",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 82,
        "end_line": 123,
        "content": "async def generate_multi_chunk_question(self, data: dict):\n        formatted_chunks = \"\\n\\n\".join(\n            f\"Chunk ID: {c['_id']}\\nContent: {c['text']}\" for c in data[\"chunks\"]\n        )\n        if data[\"file_type\"] == 'Text':\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_TXT\n        if data[\"file_type\"] == \"Code\":\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_CODE\n\n        messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": content,\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Text chunks:\\n{formatted_chunks}\"\n                }\n            ]\n        \n        response = await self._make_openai_request(\n            messages=messages,\n            temperature=0.7,\n            max_tokens=1024\n        )\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n        if \"error\" in response:\n            return {\n                \"question\": \"Could not generate question - API error\",\n                \"relevant_ids\": [\n                    data[\"chunks\"][0][\"_id\"], \n                    data[\"chunks\"][1][\"_id\"]\n                ] if len(data[\"chunks\"]) >= 2 else []\n            }\n        loggers[\"main\"].info(f\"response_json from generate multi : {response}\")\n\n        raw_content = response[\"choices\"][0][\"message\"][\"content\"]\n        loggers[\"main\"].info(raw_content)\n        return self._parse_multi_chunk_response(raw_content, data)\n\nAsynchronous method in LLMUtils class that generates questions across multiple text or code chunks. Takes a dictionary containing chunks and file type, formats the content for OpenAI API, selects appropriate prompt templates based on file type, makes API request via _make_openai_request, logs token usage, handles errors, and processes the response through _parse_multi_chunk_response. Supports RAG (Retrieval-Augmented Generation) functionality for multi-document question generation.",
        "size": 2025,
        "parent-class": "LLMUtils",
        "function_name": "generate_multi_chunk_question"
    },
    {
        "id": "8f0d341d-8a3a-495f-8f30-255325883a12",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 125,
        "end_line": 145,
        "content": "def _parse_multi_chunk_response(self, raw_content: str, chunks: List[Dict]):\n        try:\n            questions = json.loads(raw_content)\n            if not isinstance(questions, list):\n                raise ValueError(\"Expected a list of questions\")\n            \n            result_list = []\n            for q in questions:\n                if \"question\" not in q or \"chunk_ids\" not in q:\n                    raise ValueError(\"Missing required fields in question item\")\n                    \n                result_list.append({\n                    \"question\": q[\"question\"].strip(),\n                    \"relevant_ids\": [str(id) for id in q[\"chunk_ids\"]]\n                })\n            return result_list\n        except (json.JSONDecodeError, ValueError):\n            return {\n                \"question\": raw_content.strip(),\n                \"relevant_ids\": [c[\"_id\"] for c in chunks[:2]]\n            }\n\nHelper method in LLMUtils class that parses JSON response from multi-chunk question generation. Validates that response contains a list of questions with required fields (question and chunk_ids), formats each question with its relevant chunk IDs, and provides a fallback mechanism in case of JSON parsing errors by returning the raw content with default chunk IDs from the first two chunks.",
        "size": 1293,
        "parent-class": "LLMUtils",
        "function_name": "_parse_multi_chunk_response"
    },
    {
        "id": "c184a01b-0c34-44b7-85e1-be916722bc12",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi.responses import JSONResponse\nfrom functools import wraps\nfrom fastapi import status\n\nImport statements for FastAPI error handling, including JSONResponse for returning API responses, wraps decorator for preserving function metadata, and status codes for HTTP response status specification.",
        "size": 303,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "70e25772-b781-4f92-91f2-740635c5065b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 5,
        "end_line": 21,
        "content": "def handle_exceptions(func):\n    \"\"\"A decorator to catch exceptions and return a consistent JSON error response.\"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except Exception as e:\n            return JSONResponse(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                content={\n                    \"data\": {},\n                    \"statuscode\": 500,\n                    \"detail\": \"An internal server error occurred.\",\n                    \"error\": str(e),\n                },\n            )\n    return wrapper\n\nDecorator function that wraps API endpoints to provide standardized error handling, catching exceptions and transforming them into consistent FastAPI JSONResponse objects with HTTP 500 status codes and structured error information. Preserves the original function's metadata using functools.wraps and operates asynchronously.",
        "size": 944,
        "parent-class": null,
        "function_name": "handle_exceptions"
    },
    {
        "id": "c1af44a4-69bb-4c2b-a2d0-2e1963dd92e3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers\n\nDatabase and logging imports for an IndexRepository class that handles data retrieval operations from MongoDB collections for ground truth data, raw data, and index information in a vector search system.",
        "size": 323,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f0e3bc03-50dc-49d5-9bb0-d898e0319c66",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 6,
        "end_line": 9,
        "content": "def __init__(self):\n        self.ground_truth_collection = db_helper.gt_data\n        self.raw_collection = db_helper.raw_data\n        self.index_info_collection = db_helper.index_upsert_collection\n\nConstructor method for the IndexRepository class that initializes database collection references for ground truth data, raw data, and index information using the db_helper object, providing access to MongoDB collections for vector search operations.",
        "size": 447,
        "parent-class": "IndexRepository",
        "function_name": "__init__"
    },
    {
        "id": "9af41585-f1fa-40b3-bcd9-0f546cb24ff8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 11,
        "end_line": 27,
        "content": "async def fetch_ground_truth(self, query):\n\n        query = {\"question\": query}\n\n        ground_truth_doc = await self.ground_truth_collection.find_one(query)\n\n        ground_truth_ids = []\n        for x in ground_truth_doc[\"chunks\"]:\n            ground_truth_ids.append(x[\"_id\"])\n            \n        ground_truth = []\n        for _id in ground_truth_ids:\n            chunk = await self.raw_collection.find_one({\"_id\": _id})\n\n            ground_truth.append({\"id\": _id, \"chunk\": chunk[\"text_content\"]})\n\n        return ground_truth\n\nMongoDB repository method that retrieves ground truth data for a given query by first finding the question document, extracting associated chunk IDs, then retrieving the actual text content of each chunk from a raw collection. Returns a formatted list of ground truth chunks with their IDs and content for evaluation or comparison purposes.",
        "size": 874,
        "parent-class": "IndexRepository",
        "function_name": "fetch_ground_truth"
    },
    {
        "id": "9535b274-d8bf-4d6b-b54b-41205c36018b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 29,
        "end_line": 56,
        "content": "async def get_namespace_and_host(\n        self, index_name: str, embedding_model: str, filename: str\n    ):\n\n        query = {\n            \"index_name\": index_name,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": filename,\n                    \"details.embedding_model\": embedding_model,\n                }\n            },\n        }\n\n        document = await self.index_info_collection.find_one(query)\n        \n        if document is None:\n            return None, None\n        \n        namespace_name = None\n        namespaces = document[\"namespaces\"]\n        for namespace in namespaces:\n            if namespace['details']['embedding_model'] == embedding_model and namespace['details']['filename'] == filename:\n                namespace_name = namespace[\"name\"]\n\n        host = document[\"index_host\"]\n\n        return namespace_name, host\n\nDatabase retrieval method in IndexRepository class that queries MongoDB to find namespace details and host information based on index name, embedding model, and filename parameters. Creates a MongoDB query with $elemMatch to locate matching documents, retrieves namespace name by filtering through namespaces array, and returns both namespace name and index host. Used for vector database retrieval operations in a FastAPI application.",
        "size": 1326,
        "parent-class": "IndexRepository",
        "function_name": "get_namespace_and_host"
    },
    {
        "id": "9c586a94-1608-4fd9-8f39-eb6a2c3499df",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 58,
        "end_line": 84,
        "content": "async def fetch_questions(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.ground_truth_collection.find_one(file_query)\n            \n            if not file_doc:\n                raise HTTPException(status_code=404, detail=\"File not found\")\n            \n            questions_with_ground_truth = []\n\n            data_doc = file_doc[\"data\"]\n\n            for document in data_doc:\n                question = document['question']\n                ground_truth_chunk_ids = [chunk['_id'] for chunk in document['chunks']]\n                questions_with_ground_truth.append({\n                    'question': question,\n                    'ground_truth_chunk_ids': ground_truth_chunk_ids\n                })\n            loggers[\"main\"].info(f\"length of questions with ground truth : {len(questions_with_ground_truth)}\")\n\n            return questions_with_ground_truth\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nDatabase repository method that retrieves evaluation questions and their corresponding ground truth chunk IDs from MongoDB for a specified file. Part of an IndexRepository class that interfaces with database collections for retrieval-based evaluation. Returns a structured list of question objects with associated ground truth identifiers used for testing retrieval accuracy.",
        "size": 1439,
        "parent-class": "IndexRepository",
        "function_name": "fetch_questions"
    },
    {
        "id": "92133b19-00c9-4fde-b34c-56a719c77388",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 86,
        "end_line": 96,
        "content": "async def fetch_total_chunks(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.raw_collection.find_one(file_query)\n            \n            return len(file_doc[\"data\"])\n            \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nDatabase repository method that retrieves the total number of chunks in a document by querying the raw_collection with a specific file_name and returning the count of items in the \"data\" array. Part of the IndexRepository class that interfaces with MongoDB collections for search indexing operations.",
        "size": 679,
        "parent-class": "IndexRepository",
        "function_name": "fetch_total_chunks"
    },
    {
        "id": "12615e45-4d9e-4974-a3ff-b331eec9f580",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 98,
        "end_line": 137,
        "content": "async def fetch_user_previous_configurations(self):\n\n        collection_names = await db_helper.db.list_collection_names()\n        if \"index_upsert\" not in collection_names:\n            return {\"message\": \"You have no previous configurations.\"}\n    \n        count = await self.index_info_collection.count_documents({})\n        if count == 0:\n            return {\"message\": \"You have no previous configurations.\"}\n        \n\n\n        try:\n            cursor = self.index_info_collection.find(\n                {}, \n                {\n                    \"index_name\" : 1, \n                    \"dimension\" : 1, \n                    \"similarity_metric\" : 1, \n                    \"namespaces.details.filename\" : 1, \n                    \"namespaces.details.embedding_model\" : 1\n                }\n            )\n            \n            configurations = []\n            async for doc in cursor:\n                configurations.append(\n                    {\n                        \"index_name\" : doc[\"index_name\"],\n                        \"dimension\" : doc[\"dimension\"],\n                        \"similarity_metric\" : doc[\"similarity_metric\"],\n                        \"filename\" : [namespace[\"details\"][\"filename\"] for namespace in doc[\"namespaces\"]],\n                        \"embedding_model\" : [namespace[\"details\"][\"embedding_model\"] for namespace in doc[\"namespaces\"]]\n                    }\n                )\n                \n            return configurations\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Error in fetching previous configurations: {str(e)}\")\n\nDatabase repository method that retrieves previous vector index configurations from MongoDB. Checks for existence of the index_upsert collection, performs validation, then queries for index metadata including dimensions, similarity metrics, filenames, and embedding models. Returns either a message indicating no configurations exist or an array of configuration objects containing index parameters. Used for displaying user's existing vector search infrastructure.",
        "size": 2069,
        "parent-class": "IndexRepository",
        "function_name": "fetch_user_previous_configurations"
    },
    {
        "id": "0bc1d5db-f30e-4758-b8ed-0fb8ea1e2cb7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers\n\nImport statements for a database repository module, importing MongoDB database connection helper, FastAPI exception handling, and custom logging utilities. Sets up dependencies for the RawDataRepo class.",
        "size": 331,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5a1ae231-ce2f-45fd-bc12-5bebc5b443b5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.raw_data\n\nRepository class constructor initializing MongoDB collection reference for raw data storage and retrieval operations in a FastAPI application",
        "size": 207,
        "parent-class": "RawDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "7eea3c3f-2eaf-4c34-9167-5cc5cf078090",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})\n\nMongoDB collection clearing method in RawDataRepo class that deletes all documents from the raw_data collection, providing database cleanup functionality for raw document data storage",
        "size": 264,
        "parent-class": "RawDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "fde8258b-b427-4bc4-9087-6c8c74b7b681",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 13,
        "end_line": 14,
        "content": "async def insert_documents(self, document: dict):\n        await self.collection.insert_one(document)\n\nMongoDB document insertion method in RawDataRepo class that adds new documents to the raw_data collection using the insert_one operation",
        "size": 238,
        "parent-class": "RawDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "1dcb6d60-92df-41dd-ba61-078e6883ff84",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 16,
        "end_line": 21,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)\n\nRepository method that checks if a document with specified file name and type exists in the MongoDB raw_data collection, returning the matching document if found or None if not found.",
        "size": 394,
        "parent-class": "RawDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "e9deacae-4041-4aab-a679-8b9f1138d9ff",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 23,
        "end_line": 41,
        "content": "async def fetch_texts_by_ids(self,file_name: str, ids: list):\n        try:\n            \n            query = {\"file_name\": file_name}\n            ids_list = []\n            # projection = {\"data.$\": 1}  # Use positional projection to get the matching element\n            document = await self.collection.find_one(query)\n            for doc in document[\"data\"]:\n                if doc[\"_id\"] in ids:\n                    ids_list.append(doc[\"text\"])\n            # print(document)\n            return ids_list\n            # if document and \"data\" in document and document[\"data\"]:\n            #     return document[\"data\"][0][\"text\"]\n            \n\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside fetch_texts_by_ids error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\nMongoDB repository method that retrieves text content from raw data collection by querying with a file name and filtering by document IDs. Searches for documents matching the file name, extracts text data from elements with matching IDs in the data array, handles errors with structured logging, and returns HTTP 500 exceptions when retrieval fails. Part of the RawDataRepo class that manages database operations for raw document storage.",
        "size": 1291,
        "parent-class": "RawDataRepo",
        "function_name": "fetch_texts_by_ids"
    },
    {
        "id": "a1acc4af-22cf-449b-9138-d4436bf5f68a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.queryembed import QueryEmbeddings\nimport time\nfrom datetime import datetime, timezone\nfrom app.utils.logging_util import loggers\n\nImports module for the QueryRepository class, which manages MongoDB operations for query embeddings. Includes FastAPI error handling, database connectivity via db_helper, QueryEmbeddings model for data structure, and utilities for timing, datetime operations, and logging. Prepares dependencies for querying and storing embeddings with timestamp tracking.",
        "size": 584,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "1f578d61-ae08-4d2f-97a6-8da84993c56a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 13,
        "end_line": 14,
        "content": "def __init__(self):\n        self.collection = db_helper.query_embeddings_collection\n\nRepository class constructor initializing a MongoDB collection reference for storing query embeddings, which provides data access for managing and retrieving question-answer embeddings in the database.",
        "size": 286,
        "parent-class": "QueryRepository",
        "function_name": "__init__"
    },
    {
        "id": "43c27fe0-1d75-4874-8d57-5d6337c857b7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 16,
        "end_line": 57,
        "content": "async def insert_or_update_embeddings(\n        self,\n        query_embeddings: QueryEmbeddings\n    ):\n        \"\"\"\n        Upsert embeddings - either update existing document or create new one\n        \"\"\"\n        try:\n            # Construct the unique identifier for the document\n            filter_query = {\n                \"filename\": query_embeddings.filename,\n                \"embedding_model\": query_embeddings.embedding_model,\n                \"dimension\": query_embeddings.dimension\n            }\n            \n            # Prepare the update operation\n            update_query = {\n                \"$set\": {\n                    \"filename\": query_embeddings.filename,\n                    \"embedding_model\": query_embeddings.embedding_model,\n                    \"dimension\": query_embeddings.dimension,\n                    \"updated_at\": datetime.now(timezone.utc).isoformat()\n                },\n                \"$addToSet\": {\n                    \"questions\": {\n                        \"$each\": query_embeddings.questions\n                    }\n                }\n            }\n            \n            # Perform upsert operation\n            result = await self.collection.update_one(\n                filter_query, \n                update_query, \n                upsert=True\n            )\n            \n            # Return the upserted or updated document's ID\n            return str(result.upserted_id) if result.upserted_id else str(result.modified_count)\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in upserting query embeds: {str(e)}\")\n\nMongoDB upsert method for query embeddings that creates or updates documents based on filename, embedding model and dimension identifiers. Uses MongoDB's $set operator to update metadata and $addToSet to append new questions to existing arrays. Returns the document ID for newly created records or the count of modified documents for updates. Handles database operations asynchronously with proper error handling through FastAPI exceptions.",
        "size": 2042,
        "parent-class": "QueryRepository",
        "function_name": "insert_or_update_embeddings"
    },
    {
        "id": "409420bd-562c-4075-b44a-b92e6868930e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 70,
        "end_line": 111,
        "content": "async def retrieve_question_embeddings(\n        self,\n        file_name: str,\n        embed_model: str,\n        dimension: int,\n        question_text: str \n    ):\n        query = {\n            \"filename\": file_name,\n            \"embedding_model\": embed_model,\n            \"dimension\": dimension,\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        projection = {\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        \n        try:\n            s = time.time()\n            document = await self.collection.find_one(query, projection)\n            if document is None:\n                return None\n            \n            matching_questions = document.get('questions', [])\n            if matching_questions:\n                return matching_questions[0].get('embedding')\n            e = time.time()\n            loggers[\"main\"].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n            return None\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in retrieving query embeds in motor : {str(e)}\")\n\nMongoDB query method in QueryRepository class that retrieves question embeddings based on specific criteria. Searches for documents matching filename, embedding model, dimension, and question text. Uses MongoDB's $elemMatch operator to find matching questions within arrays. Returns the embedding vector for the matched question or None if not found. Includes performance timing and error handling with FastAPI HTTP exceptions.",
        "size": 1716,
        "parent-class": "QueryRepository",
        "function_name": "retrieve_question_embeddings"
    },
    {
        "id": "cad0abb1-2e33-4a6f-81cf-16fa41fa42d6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.indexupsert import IndexUpsert\n\nPython import statements for a MongoDB repository class that manages vector index upserts. Imports FastAPI's HTTPException for error handling, a database helper for MongoDB access, and the IndexUpsert domain model that represents vector index configurations with namespaces.",
        "size": 405,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f1f58737-8afc-4d15-8795-5624bdbadc67",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self):\n        self.collection = db_helper.index_upsert_collection\n\nConstructor method for IndexUpsertRepository class that initializes the MongoDB collection reference for storing and retrieving vector index upsert operations. Uses the database helper to access the index_upsert_collection.",
        "size": 304,
        "parent-class": "IndexUpsertRepository",
        "function_name": "__init__"
    },
    {
        "id": "2417e0af-6722-4090-abda-6a1ba8957f10",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 12,
        "end_line": 30,
        "content": "async def find_matching_index_upsert(\n        self,\n        dimension: str,\n        similarity_metric: str,\n        file_name: str,\n        embed_model: str,\n    ):\n        query = {\n            \"dimension\": dimension,\n            \"similarity_metric\": similarity_metric,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": file_name,\n                    \"details.embedding_model\": embed_model,\n                }\n            },\n        }\n        document = await self.collection.find_one(query)\n        return document\n\nMongoDB query method in IndexUpsertRepository that searches for vector index configurations matching specific dimension, similarity metric, filename, and embedding model parameters. Locates documents with exact namespace details using MongoDB's $elemMatch operator to filter nested array elements. Returns the first matching document or None if no match exists.",
        "size": 928,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index_upsert"
    },
    {
        "id": "a46bfcd6-251d-4959-9383-8dd9672bac58",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 32,
        "end_line": 35,
        "content": "async def find_matching_index(self, dimension: str, similarity_metric: str):\n        query = {\"dimension\": dimension, \"similarity_metric\": similarity_metric}\n        document = await self.collection.find_one(query)\n        return document\n\nDatabase query method in IndexUpsertRepository that searches for a vector index based on dimension and similarity metric parameters. Used for finding existing indexes before creating or updating them, without checking for namespace details. Returns the matching MongoDB document or None if no match exists.",
        "size": 546,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index"
    },
    {
        "id": "7d699d72-c2a2-47d1-a72b-bfc15701873d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 37,
        "end_line": 83,
        "content": "async def add_index_upsert_details(self, indexupsert: IndexUpsert):\n        try:\n            # Check if an index with same dimension and similarity_metric exists\n            existing_index = await self.collection.find_one(\n                {\n                    \"dimension\": indexupsert.dimension,\n                    \"similarity_metric\": indexupsert.similarity_metric,\n                }\n            )\n\n            if existing_index:\n                # Get the first namespace from the new data\n                new_namespace = indexupsert.namespaces[0]\n\n                # Check if namespace with same name already exists\n                namespace_exists = any(\n                    ns[\"name\"] == new_namespace.name\n                    for ns in existing_index.get(\"namespaces\", [])\n                )\n\n                if namespace_exists:\n                    # Namespace already exists, no need to update\n                    return str(existing_index[\"_id\"])\n\n                # Add new namespace to existing index\n                result = await self.collection.update_one(\n                    {\"_id\": existing_index[\"_id\"]},\n                    {\n                        \"$push\": {\n                            \"namespaces\": {\n                                \"name\": new_namespace.name,\n                                \"details\": {\n                                    \"filename\": new_namespace.details.filename,\n                                    \"embedding_model\": new_namespace.details.embedding_model,\n                                },\n                            }\n                        }\n                    },\n                )\n                return str(existing_index[\"_id\"])\n            else:\n                # Create new index document\n                index_upsert_dict = indexupsert.to_dict()\n                result = await self.collection.insert_one(index_upsert_dict)\n                return str(result.inserted_id)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in IndexUpsertRepository class that adds or updates vector index metadata. First checks if an index with matching dimension and similarity metric exists. If found, checks for namespace duplication before adding a new namespace to existing index. Otherwise creates a new index document. Returns the MongoDB document ID for the index. Uses asynchronous MongoDB operations and handles errors by raising HTTP 500 exceptions.",
        "size": 2450,
        "parent-class": "IndexUpsertRepository",
        "function_name": "add_index_upsert_details"
    },
    {
        "id": "980c9f28-6254-4e22-802c-773c71a416ce",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from app.config.database import db_helper\nimport random\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers\n\nMongoDB repository imports module for a ground truth data service, including database helper, random number generation for question selection, FastAPI HTTP exception handling, and logging utilities.",
        "size": 340,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "0fa75da4-bce7-4e9a-80b8-092ffd14947f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.gt_data\n\nRepository class initialization that establishes connection to the ground truth data collection in MongoDB through the db_helper service. Used for storing and retrieving ground truth data for question generation and validation.",
        "size": 292,
        "parent-class": "GTDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "2e0bc93b-067a-4804-b590-934ffd1d0629",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})\n\nMongoDB collection method to delete all documents in the 'gt_data' collection, part of the GTDataRepo class that handles ground truth data operations.",
        "size": 231,
        "parent-class": "GTDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "15c7dfe3-16ee-4db7-bad0-3318cbc0e677",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 13,
        "end_line": 17,
        "content": "async def insert_documents(self, document: dict):\n        try :\n            await self.collection.insert_one(document)\n        except Exception as e :\n            loggers[\"main\"].info(f\"inside insert documents : {str(e)}\")\n\nMongoDB document insertion method within GTDataRepo class for ground truth data management. Asynchronously inserts a single document into the gt_data collection with error logging functionality. Part of the database repository layer for handling ground truth data storage operations.",
        "size": 507,
        "parent-class": "GTDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "324492ee-1ee2-43a6-9b20-0802189a4004",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 19,
        "end_line": 24,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)\n\nMethod in GTDataRepo class that checks if a document exists in the MongoDB collection by searching for a specific file name and file type. Returns the document if found or None if not found. Used for ground truth data validation before operations.",
        "size": 458,
        "parent-class": "GTDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "65cc618d-5b85-4b1c-be9b-ab198c6fd2f2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 27,
        "end_line": 49,
        "content": "async def get_random_question(self, file_name: str):\n        try:\n            document = await self.collection.find_one({\"file_name\": file_name})\n            if not document:\n                return {\"message\": \"ground truth file not found in database\"}\n            \n            data = document.get(\"data\", [])\n            if not data:\n                return {\"message\": \"no data found in ground truth file\"}\n            \n            total_length = len(data)\n            random_number = random.randint(0, total_length - 1)\n            index = random_number % total_length\n\n            chunks = data[index].get(\"chunks\", [])\n            ids = []\n            for chunk in chunks:\n                ids.append(chunk.get(\"_id\", \"\"))\n            selected_question_gt = data[index]\n            return selected_question_gt, ids\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside get_random_question error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\nMongoDB repository method for retrieving a random question and associated chunk IDs from ground truth data. Searches for documents by file name, selects a random entry from the data array, extracts chunk IDs, and returns both the selected question data and IDs list. Includes error handling for missing documents, empty data arrays, and database exceptions with HTTP 500 responses.",
        "size": 1411,
        "parent-class": "GTDataRepo",
        "function_name": "get_random_question"
    },
    {
        "id": "c3e0ba8e-a5c7-49ac-908b-65d7a5582639",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nfrom pydantic.config import ConfigDict\nfrom pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nimport logging\n\nImport statements for a Pydantic validation model, including BaseModel for data structure definition, field_validator for custom validation rules, ValidationError for exception handling, ClassVar from typing for class variables, ConfigDict for model configuration, and logging for error reporting.",
        "size": 538,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "2bf6ded0-936c-44f4-903b-5da3b9b23eb0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 39,
        "end_line": 42,
        "content": "def validate_similarity_metric(cls, value):\n        if value.lower() not in cls.ALLOWED_METRICS:\n            raise ValueError(f\"Invalid similarity_metric '{value}'. Must be one of {cls.ALLOWED_METRICS}.\")\n        return value.lower()  # Normalize to lowercase\n\nField validator method for the IndexUpsertRequest Pydantic model that enforces similarity metric values must be one of the predefined allowed options (cosine, dotproduct, or euclidean) stored in the ALLOWED_METRICS class variable. The method normalizes all inputs to lowercase.",
        "size": 538,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_similarity_metric"
    },
    {
        "id": "2af5d9f0-b3ab-4932-880c-fa49c7195e08",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 47,
        "end_line": 59,
        "content": "def validate_dimension(cls, value, info):\n        # Use info.data to access the context dictionary containing input data\n        embed_model = info.data.get(\"embed_model\")\n\n        if not embed_model:\n            raise ValueError(\"embed_model must be provided before validating dimension.\")\n\n        valid_dimensions = cls.MODEL_TO_DIMENSIONS.get(embed_model)\n\n        if valid_dimensions and value not in valid_dimensions:\n            raise ValueError(f\"Invalid dimension '{value}' for model '{embed_model}'. Must be one of {valid_dimensions}.\")\n\n        return value\n\nPydantic field validator method for the IndexUpsertRequest model that validates dimension parameters based on the specified embedding model. The validator retrieves the embedding model from context data, checks if it exists, then confirms the dimension value is valid for that model using a predefined mapping dictionary. Raises ValueError with specific error messages if validation fails.",
        "size": 959,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_dimension"
    },
    {
        "id": "78bafc4d-f2b6-47bd-bc13-c1228354d2ca",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/file_upload_schema.py",
        "file_name": "file_upload_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Optional\n\nPydantic imports for data validation within a model definition that will handle file upload requests with optional chunk count configuration.",
        "size": 208,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c5844e31-cf01-40c0-a93e-fe158792c53b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/query_schema.py",
        "file_name": "query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Optional, Literal\nfrom pydantic import BaseModel, Field\n\nImport statements for Pydantic model definition that handles query endpoint request parameters, including type hints for optional fields, literal values, and validation rules used in the request model.",
        "size": 277,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ddb9bfe0-4d78-406d-b9ec-8f9a8f990aca",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/random_query_schema.py",
        "file_name": "random_query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal, Optional\n\nImport statements for Pydantic models and type annotations used in defining the RandomQueryRequest data model for vector search operations.",
        "size": 215,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "7d390e75-b695-41eb-bded-ee92ca816ed9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/reranking_schema.py",
        "file_name": "reranking_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Any, Dict\nfrom pydantic import BaseModel\n\nImport statements for Python typing annotations and Pydantic data validation, providing foundational dependencies for the document models that follow. These imports support type hinting with Any and Dict types, along with Pydantic's BaseModel which is used to define structured data models with validation in the codebase.",
        "size": 383,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d954ad54-c846-423c-8619-19e6d6548bfc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from datetime import datetime\nfrom typing import Any, Dict, List\nfrom bson import ObjectId\n\nImport statements for datetime handling, type annotations, and MongoDB ObjectId used in a data model for vector index management with namespaces and serialization capabilities.",
        "size": 268,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ae619a5b-fea1-479d-b0e3-fcbbeabd2fae",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 8,
        "end_line": 10,
        "content": "def __init__(self, filename: str, embedding_model: str):\n        self.filename = filename\n        self.embedding_model = embedding_model\n\nConstructor method for the NamespaceDetails class that initializes filename and embedding model attributes for vector database namespaces, used within the vector index management system for tracking document sources and their associated embedding models.",
        "size": 392,
        "parent-class": "NamespaceDetails",
        "function_name": "__init__"
    },
    {
        "id": "13d54339-b865-4557-ad83-406f897932a2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 12,
        "end_line": 16,
        "content": "def to_dict(self) -> Dict[str, str]:\n        return {\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n        }\n\nSerialization method for the NamespaceDetails class that converts object properties to a dictionary with filename and embedding model information, used within vector index namespaces for data storage and retrieval.",
        "size": 371,
        "parent-class": "NamespaceDetails",
        "function_name": "to_dict"
    },
    {
        "id": "e00f4fb2-f469-4ef2-899e-a7d2da26c5a9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 20,
        "end_line": 22,
        "content": "def __init__(self, name: str, filename: str, embedding_model: str):\n        self.name = name\n        self.details = NamespaceDetails(filename, embedding_model)\n\nConstructor method for the Namespace class, initializing with a name, filename, and embedding model, and creating a NamespaceDetails object. Part of a data model for vector database namespaces within an indexing system that tracks metadata about embeddings and their sources.",
        "size": 436,
        "parent-class": "Namespace",
        "function_name": "__init__"
    },
    {
        "id": "8b7d3cb0-766e-4a8a-bb19-9d76f5170970",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 24,
        "end_line": 25,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\"name\": self.name, \"details\": self.details.to_dict()}\n\nNamespace class method that serializes a namespace object into a dictionary format, converting the name attribute and nested details object for data transfer or storage in a vector database index system.",
        "size": 311,
        "parent-class": "Namespace",
        "function_name": "to_dict"
    },
    {
        "id": "7a263a2a-632f-4b7e-b92f-17aa2c7feb33",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 29,
        "end_line": 43,
        "content": "def __init__(\n        self,\n        index_name: str,\n        index_host: str,\n        dimension: int,\n        similarity_metric: str,\n    ):\n        self._id = ObjectId()\n        self.index_name = index_name\n        self.index_host = index_host\n        self.dimension = dimension\n        self.similarity_metric = similarity_metric\n        self.created_at = datetime.utcnow()\n        self.updated_at = datetime.utcnow()\n        self.namespaces: List[Namespace] = []\n\nConstructor for the IndexUpsert class that initializes a vector database index configuration with an ObjectId, index metadata (name, host, dimension, similarity metric), timestamps, and an empty list of namespaces. Used for managing vector index operations in a MongoDB context.",
        "size": 744,
        "parent-class": "IndexUpsert",
        "function_name": "__init__"
    },
    {
        "id": "594c7afc-4be6-4fa5-9502-794b3bfd845c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 45,
        "end_line": 47,
        "content": "def add_namespace(self, namespace: Namespace) -> None:\n        self.namespaces.append(namespace)\n        self.updated_at = datetime.utcnow()\n\nMethod within the `IndexUpsert` class that adds a new namespace to the index's namespace collection and updates the timestamp. Used for managing vector database index namespaces in a document-oriented database system that tracks embedding models and files.",
        "size": 398,
        "parent-class": "IndexUpsert",
        "function_name": "add_namespace"
    },
    {
        "id": "df40ed29-c238-4013-8c0d-b982f300a886",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 49,
        "end_line": 61,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"_id\": str(self._id),\n            \"index_name\": self.index_name,\n            \"index_host\": self.index_host,\n            \"dimension\": self.dimension,\n            \"similarity_metric\": self.similarity_metric,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n            \"namespaces\": [\n                namespace.to_dict() for namespace in self.namespaces\n            ],\n        }\n\nSerialization method for the IndexUpsert class that converts its attributes including ID, index metadata, timestamps, and namespaces collection into a dictionary format with appropriate data conversions like ObjectId to string and datetime to ISO format for JSON compatibility. Part of a vector database index management system.",
        "size": 833,
        "parent-class": "IndexUpsert",
        "function_name": "to_dict"
    },
    {
        "id": "6fd9f826-38ed-4d53-84a5-135e1bfba4a2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 64,
        "end_line": 103,
        "content": "def from_dict(cls, data: Dict[str, Any]) -> \"IndexUpsert\":\n        index = cls(\n            index_name=data[\"index_name\"],\n            index_host=data[\"index_host\"],\n            dimension=data[\"dimension\"],\n            similarity_metric=data[\"similarity_metric\"],\n        )\n\n        # Set ID if it exists\n        if \"_id\" in data:\n            if isinstance(data[\"_id\"], str):\n                index._id = ObjectId(data[\"_id\"])\n            else:\n                index._id = data[\"_id\"]\n\n        # Set dates if they exist\n        if \"created_at\" in data:\n            if isinstance(data[\"created_at\"], str):\n                index.created_at = datetime.fromisoformat(data[\"created_at\"])\n            else:\n                index.created_at = data[\"created_at\"]\n\n        if \"updated_at\" in data:\n            if isinstance(data[\"updated_at\"], str):\n                index.updated_at = datetime.fromisoformat(data[\"updated_at\"])\n            else:\n                index.updated_at = data[\"updated_at\"]\n\n        # Add namespaces if they exist\n        if \"namespaces\" in data:\n            for namespace_data in data[\"namespaces\"]:\n                details = namespace_data[\"details\"]\n                namespace = Namespace(\n                    name=namespace_data[\"name\"],\n                    filename=details[\"filename\"],\n                    embedding_model=details[\"embedding_model\"],\n                )\n                index.namespaces.append(namespace)\n\n        return index\n\nClassMethod in IndexUpsert that deserializes dictionary data into an IndexUpsert object. Handles conversion of string IDs to ObjectId, parses ISO datetime strings, and reconstructs nested Namespace objects from their dictionary representations. Part of a data model for vector search indexing with namespace management functionality.",
        "size": 1796,
        "parent-class": "IndexUpsert",
        "function_name": "from_dict"
    },
    {
        "id": "bc007616-a5db-4d88-ad9b-14b63673b250",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from typing import List, Union\nimport numpy as np\nfrom bson import ObjectId\nfrom datetime import datetime, timezone\n\nImport statements for the QueryEmbeddings class defining data types, NumPy for array operations, MongoDB ObjectId for document identification, and datetime utilities for timestamp management in a vector embedding storage system.",
        "size": 345,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ba96ba5d-898d-4ca5-acfa-dea5c273df3b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 7,
        "end_line": 19,
        "content": "def __init__(self, \n                 filename: str, \n                 embedding_model: str, \n                 dimension: int, \n                 questions: List[dict] = None):\n        \n        self._id = ObjectId()\n        self.filename = filename\n        self.embedding_model = embedding_model\n        self.dimension = dimension\n        self.created_at = datetime.now(timezone.utc).isoformat()\n        self.updated_at = datetime.now(timezone.utc).isoformat()\n        self.questions = questions or []\n\nConstructor method for the QueryEmbeddings class that initializes a document storing questions with their embeddings. Creates a unique ID, stores metadata about the embedding model and dimensions, sets timestamps, and initializes the questions collection. Used for vector search functionality with parameters for filename, model type, vector dimensions, and optional questions list.",
        "size": 883,
        "parent-class": "QueryEmbeddings",
        "function_name": "__init__"
    },
    {
        "id": "97677534-5432-444a-9148-45744d1265b6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 21,
        "end_line": 35,
        "content": "def add_question(self, question_text: str, embedding: Union[List[float], np.ndarray]):\n        \n        # Ensure embedding is converted to a list\n        if isinstance(embedding, np.ndarray):\n            embedding = embedding.tolist()\n        \n        # Validate embedding dimension\n        if len(embedding) != self.dimension:\n            raise ValueError(f\"Embedding must have {self.dimension} dimensions\")\n        \n        question = {\n            \"question_text\": question_text,\n            \"embedding\": embedding\n        }\n        self.questions.append(question)\n\nMethod within QueryEmbeddings class for adding question-embedding pairs, handling numpy arrays or lists, validating dimension consistency, and appending formatted questions to the internal collection. Supports document retrieval functionality by maintaining proper embedding format and dimensions.",
        "size": 866,
        "parent-class": "QueryEmbeddings",
        "function_name": "add_question"
    },
    {
        "id": "7b44fbbd-ffbb-453a-95a6-b725f5f2d91f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 37,
        "end_line": 47,
        "content": "def to_dict(self) -> dict:\n        \n        return {\n            \"_id\": str(self._id),\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n            \"dimension\": self.dimension,\n            \"questions\": self.questions,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n        }\n\nSerialization method in QueryEmbeddings class that converts instance attributes to a dictionary format, transforming ObjectId to string and timestamps to ISO format. Used for data persistence and JSON compatibility when storing question embeddings with their metadata including dimensions, model information, and timestamps.",
        "size": 706,
        "parent-class": "QueryEmbeddings",
        "function_name": "to_dict"
    },
    {
        "id": "cc706323-1e5b-4edc-8cc0-a0d1bab73bd8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\nfrom app.usecases.file_upload_usecase import FileUploadUseCase\nimport logging\n\nImport statements for a FastAPI file upload controller, bringing in necessary dependencies for HTTP operations, response handling, dependency injection, and connecting to the FileUploadUseCase component. Sets up logging functionality for the controller.",
        "size": 426,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d2db5f12-2769-4cda-8462-5d3ecf355a66",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: FileUploadUseCase = Depends()):\n        self.usecase = usecase\n\nConstructor method for the FileUploadController class that injects FileUploadUseCase dependency using FastAPI's Dependency Injection system. This initializes the controller with the use case implementation needed to handle file upload operations.",
        "size": 338,
        "parent-class": "FileUploadController",
        "function_name": "__init__"
    },
    {
        "id": "d6c624d0-1c5a-44ff-a995-91d8dc3a3072",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def upload_files(self, request_data: dict):\n        return await self.usecase.execute(request_data)\n\nAPI controller method that handles file upload requests by delegating to a FileUploadUseCase, accepting request data in dictionary format and returning the asynchronous result from the usecase execution",
        "size": 309,
        "parent-class": "FileUploadController",
        "function_name": "upload_files"
    },
    {
        "id": "68fc8930-f52b-4bd6-a755-32fc9d7ba82f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.usecases.reranking_usecase import RerankingUseCase\n\nImports for the RerankingController component including FastAPI's Depends for dependency injection, the request/response schema models, and the RerankingUseCase that implements the core reranking functionality.",
        "size": 396,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d4ce6511-d7d6-491e-a1e8-002994672328",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "def __init__(self, reranking_usecase: RerankingUseCase = Depends()):\n        self.reranking_usecase = reranking_usecase\n\nConstructor for the RerankingController class that injects a RerankingUseCase dependency using FastAPI's dependency injection system. Initializes the controller with the usecase component responsible for document reranking operations.",
        "size": 355,
        "parent-class": "RerankingController",
        "function_name": "__init__"
    },
    {
        "id": "beb78b26-7527-4921-aa87-386e3b7f2d78",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 14,
        "end_line": 17,
        "content": "async def rerank_documents(\n        self, request: RerankingRequest\n    ) -> RerankingResponse:\n        return await self.reranking_usecase.execute(request)\n\nAsynchronous method in RerankingController class that receives a RerankingRequest, calls the execute method of the reranking_usecase dependency, and returns a RerankingResponse. Acts as an API endpoint controller for document reranking functionality, connecting the HTTP layer to the underlying business logic.",
        "size": 468,
        "parent-class": "RerankingController",
        "function_name": "rerank_documents"
    },
    {
        "id": "1d36effc-6350-4616-9875-799fbe3c0f19",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.index_upsert_usecase import IndexUpsertUseCase\n\nImport statements for a FastAPI controller that handles index upsert operations. Imports the Depends function from fastapi for dependency injection and the IndexUpsertUseCase from the application's usecase layer, establishing the controller's dependency on the business logic implementation.",
        "size": 385,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b70f0a31-f032-4778-8e6e-3bb1e9981fc6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self, index_upsert_usecase=Depends(IndexUpsertUseCase)):\n        self.index_upsert_usecase = index_upsert_usecase\n\nConstructor for the IndexUpsertController class that uses FastAPI's dependency injection pattern to initialize the controller with an IndexUpsertUseCase dependency. This establishes the controller-usecase relationship in a clean architecture implementation for handling index upsert operations.",
        "size": 422,
        "parent-class": "IndexUpsertController",
        "function_name": "__init__"
    },
    {
        "id": "2551e0e1-f96d-4b2e-ba14-837cbff406d4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 10,
        "end_line": 12,
        "content": "async def index_upsert(self, request):\n\n        return await self.index_upsert_usecase.index_upsert(request)\n\nController method for handling index upsert operations that delegates the request to the IndexUpsertUseCase. Part of the FastAPI dependency injection pattern that processes document indexing requests in an asynchronous context.",
        "size": 337,
        "parent-class": "IndexUpsertController",
        "function_name": "index_upsert"
    },
    {
        "id": "f02f3f94-77f8-44e5-b868-1f9334bcd559",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.usecases.query_usecase import QueryUseCase\n\nImport statements for the QueryController class, importing FastAPI's Dependency Injection system, the request schema model for queries, and the QueryUseCase that contains the business logic for handling queries.",
        "size": 357,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d72604e7-cf67-47fa-9b21-a70a8f88a0d6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: QueryUseCase = Depends()):\n        self.query_usecase = usecase\n\nConstructor for QueryController class injecting QueryUseCase dependency through FastAPI's dependency injection system, storing it as an instance attribute for later use in the make_query method.",
        "size": 287,
        "parent-class": "QueryController",
        "function_name": "__init__"
    },
    {
        "id": "fc03e2e0-6112-40a5-9289-e2dc3e801284",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def make_query(self, request: QueryEndPointRequest):\n        return await self.query_usecase.execute(request)\n\nController method that handles API query requests by passing the request data to the query use case for processing. Acts as an intermediary between the FastAPI endpoint and the application business logic, following a clean architecture pattern.",
        "size": 361,
        "parent-class": "QueryController",
        "function_name": "make_query"
    },
    {
        "id": "60307474-3d61-4e66-a73b-cbab6168e456",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.config_usecase import ConfigUsecase\n\nImports for ConfigurationController class, bringing in FastAPI's Depends for dependency injection and the ConfigUsecase module that provides configuration retrieval functionality.",
        "size": 262,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f0d6234d-3738-44a6-a55f-2e20ae252bf8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, usecase: ConfigUsecase = Depends()):\n        self.query_usecase = usecase\n\nConstructor method for ConfigurationController class that injects a ConfigUsecase dependency, storing it as query_usecase for configuration retrieval operations.",
        "size": 255,
        "parent-class": "ConfigurationController",
        "function_name": "__init__"
    },
    {
        "id": "15d87bca-ce6b-497e-946d-7025e82768bd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "async def get_config(self):\n        return await self.query_usecase.get_config()\n\nController method in ConfigurationController that asynchronously fetches configuration data by delegating to the get_config method of the injected ConfigUsecase instance. Implements a clean architecture pattern with dependency injection for retrieving application configuration.",
        "size": 360,
        "parent-class": "ConfigurationController",
        "function_name": "get_config"
    },
    {
        "id": "fdc0db55-91d5-45cd-8c26-b07159150f0a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.usecases.random_query_usecase import RandomQueryUseCase\nfrom app.models.schemas.random_query_schema import RandomQueryRequest\n\nImport statements for a FastAPI controller that handles random queries, importing the Depends function from FastAPI, the RandomQueryUseCase class from the application's usecase layer, and the RandomQueryRequest schema model for request validation.",
        "size": 411,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9fdc2b84-6fc2-4207-8f21-0af37d1a3e58",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 8,
        "end_line": 9,
        "content": "def __init__(self, random_query_usecase: RandomQueryUseCase = Depends()):\n        self.random_query_usecase = random_query_usecase\n\nConstructor method for the RandomQueryController class that uses dependency injection to receive a RandomQueryUseCase instance and assign it to an instance variable. Part of a FastAPI controller pattern for handling random query operations.",
        "size": 372,
        "parent-class": "RandomQueryController",
        "function_name": "__init__"
    },
    {
        "id": "b3b5f0b9-e1a4-4e41-bb2e-f61d6952eba0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "async def random_query(self, request: RandomQueryRequest):\n        return await self.random_query_usecase.random_query(request)\n\nController method for random query functionality that receives a RandomQueryRequest and delegates processing to the random_query_usecase service. Part of the FastAPI application's controller layer implementing the request handler for random query operations.",
        "size": 387,
        "parent-class": "RandomQueryController",
        "function_name": "random_query"
    },
    {
        "id": "7062c649-3eba-4447-bc91-4c564b95d02f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.random_question_usecase import RandomQuestionUseCase\n\nImports for the RandomQuestionController, including FastAPI's Depends for dependency injection and the RandomQuestionUseCase that provides the core functionality for generating random questions from files.",
        "size": 305,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ce2b24ac-03e0-494f-943d-e2dae15b2778",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 8,
        "end_line": 9,
        "content": "def __init__(self, random_question_usecase: RandomQuestionUseCase = Depends()):\n        self.random_question_usecase = random_question_usecase\n\nController constructor for RandomQuestionController that injects RandomQuestionUseCase dependency using FastAPI's dependency injection system. Sets up the controller with access to the usecase implementation for retrieving random questions.",
        "size": 384,
        "parent-class": "RandomQuestionController",
        "function_name": "__init__"
    },
    {
        "id": "f626678b-f9a9-4de5-8b66-66333e7ab13c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "async def random_question(self, file_name: str):\n        return await self.random_question_usecase.random_question(file_name)\n\nController method that handles random question retrieval operations, delegates to the RandomQuestionUseCase with the provided file name parameter, and returns the result asynchronously. Part of the FastAPI dependency injection pattern in the RandomQuestionController class.",
        "size": 400,
        "parent-class": "RandomQuestionController",
        "function_name": "random_question"
    },
    {
        "id": "c5ed7060-e732-4773-9e1b-82c4f2ba26cb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.repositories.index_repository import IndexRepository\n\nImport statements for the ConfigUsecase class, including FastAPI's Depends for dependency injection and IndexRepository from the app's repository layer.",
        "size": 243,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "870b278e-71d7-4806-b646-1b77cfc78c48",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, index_repository: IndexRepository = Depends()):\n        self.index_repository = index_repository\n\nConstructor method for the ConfigUsecase class that initializes the index_repository dependency through FastAPI's dependency injection system. This establishes the repository connection needed for configuration retrieval operations in the get_config method.",
        "size": 374,
        "parent-class": "ConfigUsecase",
        "function_name": "__init__"
    },
    {
        "id": "dab66d31-2eb6-452b-bfa1-8289c5065607",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 9,
        "end_line": 13,
        "content": "async def get_config(self):\n        response = await self.index_repository.fetch_user_previous_configurations()\n        if response is None:\n            return {\"message\": \"No configurations found\"}\n        return response\n\nMethod within the ConfigUsecase class that asynchronously retrieves user configurations by calling the fetch_user_previous_configurations method from the index_repository. Returns the fetched configurations or a message indicating no configurations were found.",
        "size": 484,
        "parent-class": "ConfigUsecase",
        "function_name": "get_config"
    },
    {
        "id": "36c38766-2f69-4d63-ab96-776cf5b9bd9a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import os\nimport json\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom fastapi import Depends, HTTPException\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.repositories.index_repository import IndexRepository\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.reranking_service import RerankerService\nfrom app.utils.logging_util import loggers\n\nImport statements and dependencies for the RerankingUseCase class that handles document reranking operations. Includes standard libraries for I/O and concurrency (os, json, asyncio, ThreadPoolExecutor), FastAPI components, custom schemas for request/response handling, repository and service layer dependencies for index access, evaluation metrics calculation, and reranking functionality, and logging utilities.",
        "size": 866,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "e3efbe1a-129a-4b53-83c9-93ab74908675",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 18,
        "end_line": 24,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        reranker_service: RerankerService = Depends(),\n    ):\n        self.reranker_service = reranker_service\n        self.index_repository = index_repository\n\n\nConstructor for the RerankingUseCase class that initializes dependencies for document reranking operations. Injects IndexRepository and RerankerService components through FastAPI's dependency injection system to support retrieval and reranking functionality in the search pipeline.\n",
        "size": 527,
        "parent-class": "RerankingUseCase",
        "function_name": "__init__"
    },
    {
        "id": "c919e9de-9e42-498d-ad7b-50f028b61fee",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 26,
        "end_line": 90,
        "content": "async def execute(self, request: RerankingRequest) -> RerankingResponse:\n        \"\"\"\n        Execute the reranking use case by processing queries and documents \n        from the saved first_stage_retrieval.json file.\n\n        Args:\n            request: RerankingRequest containing model_name and top_n\n\n        Returns:\n            RerankingResponse with evaluation metrics\n        \"\"\"\n        try:\n            model_name = request.model_name\n            top_n = request.top_n\n            top_k=request.top_k\n\n            if top_n > top_k:\n                raise HTTPException(\n                    status_code=400, \n                    detail=f\"Invalid request: top_n ({top_n}) cannot be greater than top_k ({top_k}).\"\n                )\n\n            # Load first stage retrieval results\n            first_stage_file_path = \"results/first_stage_retrieval.json\"\n            if not os.path.exists(first_stage_file_path):\n                raise HTTPException(\n                    status_code=404, \n                    detail=\"First stage retrieval results not found. Run query_usecase first.\"\n                )\n                \n            with open(first_stage_file_path, \"r\") as f:\n                questions_data = json.load(f)\n                \n            # Process each question in parallel\n            tasks = [\n                self._process_question(question, model_name, top_n)\n                for question in questions_data\n            ]\n            \n            processed_questions = await asyncio.gather(*tasks)\n            \n            # Extract questions and evaluation metrics\n            questions, evaluation_metrics_list = zip(*processed_questions)\n            \n            # Calculate average metrics\n            with ThreadPoolExecutor() as executor:\n                average_evaluation_metrics = executor.submit(\n                    self.average_metrics,\n                    evaluation_metrics_list,\n                    top_n\n                ).result()\n                \n            # Save results\n            os.makedirs(\"results\", exist_ok=True)\n            with open(\"results/second_stage_retrieval.json\", \"w\") as f:\n                json.dump(list(questions), f, indent=4)\n                \n            with open(\"results/second_stage_evaluation.json\", \"w\") as f:\n                json.dump(average_evaluation_metrics, f, indent=4)\n                \n            return RerankingResponse(evaluation_metrics=average_evaluation_metrics)\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking execution: {str(e)}\", exc_info=True)\n            raise HTTPException(status_code=500, detail=str(e))\n\nMain method of the RerankingUseCase class that orchestrates document reranking. Processes a batch of queries against first-stage retrieval results, applying reranking algorithms with specified models, evaluating performance metrics, and saving results. Handles validation of input parameters, parallel processing of questions, metric calculation, and error handling. Relies on helper methods for reranking individual questions and calculating evaluation metrics.",
        "size": 3096,
        "parent-class": "RerankingUseCase",
        "function_name": "execute"
    },
    {
        "id": "55ba1c14-2f9c-47c2-80dc-09ba03f4b92c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 92,
        "end_line": 113,
        "content": "async def _process_question(self, question, model_name, top_n):\n        \"\"\"Process a single question with reranking.\"\"\"\n        try:\n            query = question[\"question\"]\n            documents = question[\"relevant_docs\"]\n            ground_truth_chunk_ids = question[\"ground_truth_chunk_ids\"]\n            \n            reranked_docs = await self._rerank_documents(model_name, query, documents, top_n)\n            \n            # Update the question with reranked documents\n            question[\"reranked_docs\"] = reranked_docs\n            \n            evaluation_metrics = self._calculate_evaluation_metrics(\n                reranked_docs, ground_truth_chunk_ids, top_n\n            )\n            \n            return question, evaluation_metrics\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error processing question '{query}': {str(e)}\", exc_info=True)\n            question[\"error\"] = str(e)\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nHelper method in the RerankingUseCase class that processes individual questions for document reranking. Extracts query and documents from a question object, calls the reranking function, updates the question with reranked documents, calculates evaluation metrics against ground truth, and returns both the updated question and metrics. Part of a parallel processing approach for handling multiple questions during reranking operations. Includes error handling with logging and HTTP exception raising.\n",
        "size": 1495,
        "parent-class": "RerankingUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "9e97c40e-aa2a-45d0-91dd-f524860f1898",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 115,
        "end_line": 217,
        "content": "async def _rerank_documents(self, model_name, query, documents, top_n):\n        \"\"\"Rerank documents using the specified reranker.\"\"\"\n\n        try:\n            pinecone_models = [\n                \"cohere-rerank-3.5\",\n                \"bge-reranker-v2-m3\",\n                \"pinecone-rerank-v0\",\n            ]\n            cohere_models = [\n                \"rerank-v3.5\",\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n            ]\n            jina_models = [\"jina-reranker-v2-base-multilingual\"]\n            voyage_models=[\"rerank-lite-1\",\"rerank-1\",\"rerank-2\"]\n            \n            # Extract text from documents for non-Pinecone rerankers\n            docs_text = [doc[\"text\"] for doc in documents]\n            # Format documents for Pinecone reranker\n            pinecone_docs = [{\"text\": doc[\"text\"]} for doc in documents]\n            \n            results = []\n            \n            # Determine which reranker to use based on the model name\n            if model_name.lower() in pinecone_models:\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model_name, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    # Find the original document to preserve the id\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            elif model_name.lower() in cohere_models:\n                reranking_result = await self.reranker_service.cohere_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n                        \n            elif model_name.lower() in jina_models:\n                reranking_result = await self.reranker_service.jina_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n\n            elif model_name.lower() in voyage_models:\n                reranking_result = await self.reranker_service.voyage_rerank(\n                    model_name,query,docs_text,top_n\n                )\n                for result in reranking_result.get(\"data\",[]):\n                    idx=result.get(\"index\",0)\n                    if 0<=idx <len(documents):\n                        results.append({\n                            \"id\":documents[idx][\"id\"],\n                            \"text\":documents[idx][\"text\"],\n                            \"score\":result.get(\"relevance_score\",0.0)\n                        })\n                        \n            else:\n                # Default to Pinecone\n                model = \"bge-reranker-v2-m3\"\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            return results\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate method within RerankingUseCase class that handles document reranking with multiple model providers. Dynamically selects appropriate reranker (Pinecone, Cohere, Jina, or Voyage) based on the requested model name, formats documents according to provider requirements, processes reranking results into a standardized format preserving document IDs and scores, and handles response parsing for each provider's unique API structure. Implements fallback to a default Pinecone model when encountering unrecognized model names.",
        "size": 5168,
        "parent-class": "RerankingUseCase",
        "function_name": "_rerank_documents"
    },
    {
        "id": "88f2dd5c-1d4e-4898-8358-f0433da75bab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 219,
        "end_line": 260,
        "content": "def _calculate_evaluation_metrics(self, retrieved_docs, ground_truth_ids, top_n):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n        return {\n            \"precision_at_k\": EvaluationService.precision_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"recall_at_k\": EvaluationService.recall_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids, \n                k=top_n\n            ),\n            \"bpref\": EvaluationService.bpref(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids\n            ),\n            \"mrr\": EvaluationService.reciprocal_rank(\n            retrieved_docs=retrieved_docs,\n            ground_truth=ground_truth_ids\n            ),\n            \"map\": EvaluationService.mean_average_precision(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n\n            ),\n        }\n\nPrivate method within RerankingUseCase that calculates multiple information retrieval evaluation metrics, including precision, recall, F1-score, hit rate, NDCG, BPREF, MRR, and MAP. Takes reranked document results, ground truth document IDs, and top_n parameter as inputs. Used during document reranking evaluation to assess retrieval quality against known relevant documents. Called by the _process_question method to evaluate individual query results before aggregating metrics across all questions.",
        "size": 2213,
        "parent-class": "RerankingUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "da38b379-0d95-4d48-a1c9-8e4e7def1de0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 262,
        "end_line": 314,
        "content": "def average_metrics(self, metrics_list, top_n):\n        \"\"\"Calculate average metrics across all questions.\"\"\"\n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_n + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n    \n        avg_dict = sum_dict.copy()\n        \n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    for sub_key, sub_value in value.items():\n                        if sub_key in sum_dict.get(key, {}):\n                            sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] if count_dict[key] > 0 else 0.0\n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key] if count_dict[key] > 0 else 0.0\n        \n        return avg_dict\n\n\nMethod in RerankingUseCase class that calculates average evaluation metrics across multiple reranking results. Processes various information retrieval metrics (precision, recall, F1-score, hit rate, NDCG, BPREF, MRR, MAP) by aggregating values across all questions at different k values. Handles both scalar metrics and nested dictionary metrics, computing the mean values. Used by the execute method to generate final evaluation metrics for reranking operations. Important for evaluating search effectiveness in retrieving relevant documents.\n",
        "size": 2465,
        "parent-class": "RerankingUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "466160a7-32e2-4d1a-bebf-2591e77caedd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 1,
        "end_line": 16,
        "content": "import os\nimport time\nimport json\nimport asyncio\nfrom typing import List\nfrom typing import List\nfrom fastapi import Depends, HTTPException\nfrom concurrent.futures import ThreadPoolExecutor\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.repositories.index_repository import IndexRepository\nfrom app.repositories.query_repository import QueryRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.pinecone_service import PineconeService\nfrom app.models.domain.queryembed import QueryEmbeddings\nfrom app.utils.logging_util import loggers\n\nImport statements and dependencies for a query evaluation service that performs vector search operations. The module imports essential components for embedding generation, vector search, data access, and evaluation metrics calculation. This setup supports a system that retrieves and evaluates document chunks using various embedding models and query processing techniques through a FastAPI-based API.",
        "size": 1061,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f927a5d6-6000-4b23-8f9e-560dcfbfb32b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 23,
        "end_line": 70,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        query_repository: QueryRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(),\n    ):\n        self.index_repository = index_repository\n        self.query_repository = query_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        self.semaphore = asyncio.Semaphore(50)\n        self.embedding_batch = 90\n        self.embedding_batch = 90\n\nConstructor method for the QueryUseCase class that initializes dependencies and configurations for text embedding operations. Establishes repository connections, service integrations, and defines mappings between embedding models and their providers (Pinecone, Cohere, Jina, Voyage). Maintains a comprehensive dictionary of supported embedding dimensions for each model. Sets up concurrency control with a semaphore and defines embedding batch size for processing multiple queries efficiently.",
        "size": 2583,
        "parent-class": "QueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "de696ab6-cbb4-4dff-9217-aab447288c07",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 72,
        "end_line": 145,
        "content": "async def execute(self, request_data: QueryEndPointRequest):\n        \"\"\"\n        Main execution function for processing query endpoint requests.\n        Breaks down the request handling into smaller, focused functions.\n        \"\"\"\n        \n        total_chunks = await self.index_repository.fetch_total_chunks(request_data.file_name)\n        if total_chunks < request_data.top_k:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Top K value cannot be greater than the total number of chunks: {total_chunks}\",\n            )\n        \n        try:\n            model = self.embeddings_provider_mapping[request_data.embedding_model]\n        except KeyError:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Invalid embedding model. Please provide a valid model.\",\n            )\n            \n        if request_data.dimension not in self.model_to_dimensions[request_data.embedding_model]:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Invalid dimension. Please provide a valid dimension for embedding model: {request_data.embedding_model}\",\n            )\n            \n        namespace_name, host = await self._get_namespace_and_host(request_data)\n        questions_with_ground_turth_chunks = await self.index_repository.fetch_questions(request_data.file_name)\n        \n        batches = [questions_with_ground_turth_chunks[i:min(i + self.embedding_batch, len(questions_with_ground_turth_chunks))]\n            for i in range(0, len(questions_with_ground_turth_chunks), self.embedding_batch)\n        ]\n        \n        embedding_tasks = [self._generate_batch_embeddings(batch, request_data) for batch in batches]\n        embeddings = await asyncio.gather(*embedding_tasks, return_exceptions=True)\n        \n        dense_embeddings = []\n        for x in embeddings:\n            dense_embeddings.extend(x)\n\n        loggers['evaluation'].info(f\"Total number of questions: {len(questions_with_ground_turth_chunks)}\")\n        loggers['evaluation'].info(f\"Total number of dense embeddings: {len(dense_embeddings)}\")\n\n        \n        s = time.time()\n        tasks = [self._process_question(embedding, question, namespace_name, host, request_data) for question, embedding in zip(questions_with_ground_turth_chunks, dense_embeddings)]\n        processed_questions = await asyncio.gather(*tasks)\n        \n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices: {e-s}\")\n        if processed_questions:\n            loggers['evaluation'].info(f\"processed_questions: {len(processed_questions)}\")\n        \n        questions, evaluation_metrics_list = zip(*processed_questions)\n\n        s = time.time()\n        with ThreadPoolExecutor() as executor:\n            average_evaluation_metrics = executor.submit(\n                self.average_metrics,\n                evaluation_metrics_list,\n                request_data.top_k,\n            ).result()\n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices (Average): {e-s}\")\n\n        os.makedirs(\"results\", exist_ok=True)\n        with open(\"results/first_stage_retrieval.json\", \"w\") as f:\n            json.dump(list(questions), f, indent=4)\n        \n        with open(\"results/first_stage_evaluation.json\", \"w\") as f:\n            json.dump(average_evaluation_metrics, f, indent=4)\n            \n        return {\"questions\": questions, \"evaluation_result\" : average_evaluation_metrics}\n\nMain orchestration method in QueryUseCase class implementing evaluation workflow for retrieval systems. Validates request parameters, batches questions, generates embeddings, performs search operations, computes evaluation metrics (precision, recall, NDCG, MRR), and aggregates results. Handles parallel processing through asyncio tasks while enforcing validation checks for embedding models, dimensions, and retrieval parameters. Creates JSON output files with detailed retrieval results and aggregated evaluation metrics.",
        "size": 4054,
        "parent-class": "QueryUseCase",
        "function_name": "execute"
    },
    {
        "id": "55df6897-0de2-4e07-afed-d8c6b7745bb5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 147,
        "end_line": 156,
        "content": "async def _generate_batch_embeddings(self, questions: List[dict], request_data: QueryEndPointRequest):\n        \n        questions = [question[\"question\"] for question in questions]\n        loggers['evaluation'].info(f'Generating embeddings for {len(questions)} questions.')\n        dense_embeddings = await self._generate_dense_embedding(request_data, questions)\n            \n        if not dense_embeddings:\n            raise HTTPException(status_code=500, detail=\"Error generating dense embedding.\")\n            \n        return dense_embeddings\n\n\nBatch embedding generation method in QueryUseCase class that processes a list of questions for embedding. It extracts question text from a list of question objects, logs the operation, calls the dense embedding generation method, validates results, and raises an exception if embedding generation fails. This method supports the document retrieval evaluation system by preparing question embeddings for vector search operations.\n",
        "size": 978,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_batch_embeddings"
    },
    {
        "id": "65ef0395-04b4-43d2-b9c4-a71d180f9dbc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 159,
        "end_line": 203,
        "content": "async def _process_question(self, dense_embedding: list, question: dict, namespace_name: str, host:str, request_data: QueryEndPointRequest):\n        \n        async with self.semaphore:\n            \n            results = None\n            if request_data.is_hybrid:\n                results = await self._perform_hybrid_search(\n                    request_data, namespace_name, host, dense_embedding, question['question']\n                )\n            else:\n                results = await self._perform_regular_search(\n                    request_data, namespace_name, host, dense_embedding\n                )\n                \n            if not results:\n                loggers['evaluation'].info(\"No results found.\")\n                \n            relevant_docs_ids = []\n            relevant_docs = []\n            for result in results[\"matches\"]:\n                relevant_docs_ids.append(result[\"id\"])\n                relevant_docs.append(\n                    {\"id\": result[\"id\"], \"text\": result[\"metadata\"][\"text\"]}\n                )\n            \n            question['relevant_docs'] = relevant_docs\n            \n            ground_truth_chunk_ids = question['ground_truth_chunk_ids']\n            \n            if not relevant_docs_ids:\n                return {\n                    \"relevant_docs\": {},\n                    \"error\": \"No relevant documents found.\",\n                }\n\n            else:\n                with ThreadPoolExecutor() as executor:\n                    evaluation_metrics = executor.submit(\n                        self._calculate_evaluation_metrics,\n                        relevant_docs,\n                        ground_truth_chunk_ids,\n                        request_data.top_k\n                    ).result()\n                    \n            return question, evaluation_metrics\n\n\nAsynchronous method in QueryUseCase class that processes an individual question during semantic search evaluation. The method performs either hybrid or regular vector search based on query parameters, extracts matching documents, associates them with the question, and calculates evaluation metrics by comparing retrieved documents against ground truth. Uses semaphores for concurrency control and a ThreadPoolExecutor for metric calculation. Returns both the enriched question with search results and corresponding evaluation metrics for performance assessment.\n",
        "size": 2368,
        "parent-class": "QueryUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "7707ea27-921d-4359-b022-37062ceef4a6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 206,
        "end_line": 229,
        "content": "async def _get_namespace_and_host(self, request_data: QueryEndPointRequest):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{request_data.similarity_metric}-{request_data.dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    request_data.embedding_model,\n                    request_data.file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers['evaluation'].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nA helper method within the QueryUseCase class that retrieves the namespace and host information needed for vector search operations. It constructs an index_name from similarity metric and dimension parameters, then queries the index repository with this name along with the embedding model and file name. The method handles error cases by logging failures and raising appropriate HTTP exceptions. This function is called during the query execution process to obtain connection details for the vector database before performing searches.\n",
        "size": 1519,
        "parent-class": "QueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "b03563ce-deca-4732-a64f-e45c27481783",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 231,
        "end_line": 304,
        "content": "async def _generate_dense_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate dense embedding for the query using the appropriate provider.\"\"\"\n\n        try:\n            s = time.perf_counter()\n            existing_embeddings = []\n            for question in questions:\n                already_embeddings = await self.query_repository.retrieve_question_embeddings(\n                    request_data.file_name,\n                    request_data.embedding_model,\n                    request_data.dimension,\n                    question,\n                )\n                e = time.perf_counter()\n                if already_embeddings:\n                    loggers['evaluation'].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n                    loggers['evaluation'].info(\"Embeddings already present in the database.\")  \n                    existing_embeddings.append(already_embeddings)\n            \n            loggers['evaluation'].info(f'Existing embeddings: {len(existing_embeddings)}')\n            if existing_embeddings and len(existing_embeddings) == len(questions):\n                return existing_embeddings\n\n            embedding_provider = None\n            for key, value in self.embeddings_provider_mapping.items():\n                if key == request_data.embedding_model:\n                    embedding_provider = value\n\n            embeddings = None\n            if embedding_provider == \"pinecone\":\n                embeddings =  await self._generate_pinecone_embedding(request_data, questions)\n                        \n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by pinecone.')\n                \n            elif embedding_provider == \"cohere\":\n                embeddings = await self._generate_cohere_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by cohere.')\n                \n            elif embedding_provider == \"jina\":\n                embeddings = await self._generate_jina_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by jina.')\n        \n            elif embedding_provider == \"voyage\":\n                embeddings = await self._generate_voyage_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by voyage.')\n                \n            for question, embedding in zip(questions, embeddings):\n                    query_embeddings = QueryEmbeddings(\n                        filename=request_data.file_name,\n                        embedding_model = request_data.embedding_model,\n                        dimension=request_data.dimension,\n                    )\n                    query_embeddings.add_question(question, embedding)\n                    result = await self.query_repository.insert_or_update_embeddings(query_embeddings)\n                    if result is None:\n                        loggers['evaluation'].error(\"Error inserting embeddings in motor\")\n                \n            if not len(embeddings) == len(questions):\n                loggers['main'].error(\"Error generating embeddings by pinecone\")\n                loggers[\"embedding\"].error(\"Error generating embeddings for questions: {questions}\")\n                \n            for question, embedding in zip(questions, embeddings):\n                self.validate_embedding(question, embedding, request_data.dimension)\n            \n            return embeddings\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error generating embedding: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nCore method in QueryUseCase class that generates dense embeddings for search queries. First checks if embeddings already exist in MongoDB, returning cached results if available. Otherwise, determines the appropriate embedding provider (Pinecone, Cohere, Jina, or Voyage) based on the requested model, generates new embeddings through provider-specific methods, stores them in the database, validates the embedding dimensions and quality, and returns the resulting vector representations. Handles caching, error logging, and exception handling for the embedding generation process that's critical for the evaluation system's vector search functionality.\n",
        "size": 4474,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_dense_embedding"
    },
    {
        "id": "e3770ca2-5494-48ca-b820-4770803bc3cc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 306,
        "end_line": 319,
        "content": "async def _generate_pinecone_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Pinecone.\"\"\"\n    \n        pinecone_input = [{\"text\": question} for question in questions]\n        embeddings = await self.embedding_service.pinecone_dense_embeddings(\n            inputs=pinecone_input,\n            embedding_model=request_data.embedding_model,\n            dimension=request_data.dimension,\n            input_type=\"query\",\n        )\n        \n        return embeddings\n\n\nHelper method within the QueryUseCase class that generates vector embeddings using Pinecone for a list of questions. It formats the input in Pinecone's required structure, calls the embedding service to create dense embeddings with specified model and dimension, and returns the resulting embeddings to be used in vector searches. This method is one of several embedding generation methods in the class, alongside implementations for Cohere, Jina, and Voyage providers, and is called by the _generate_dense_embedding parent method which handles caching and validation.\n",
        "size": 1109,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_pinecone_embedding"
    },
    {
        "id": "15d2047a-b4f9-4a84-9a69-afb0453806ac",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 321,
        "end_line": 331,
        "content": "async def _generate_cohere_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Cohere.\"\"\"\n        embeddings = await self.embedding_service.cohere_dense_embeddings(\n            texts=questions,\n            model_name=request_data.embedding_model,\n            input_type=\"search_query\",\n        )\n    \n        return embeddings\n\nFunction in QueryUseCase class that generates embeddings using Cohere's embedding models. It takes query request data and a list of questions, calls the embedding service with appropriate parameters (setting input_type to \"search_query\"), and returns the dense vector embeddings. Part of the embedding generation pipeline that supports multiple embedding providers (Cohere, Pinecone, Jina, Voyage) for semantic search and question answering.",
        "size": 843,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_cohere_embedding"
    },
    {
        "id": "d0c9ccb7-4add-427b-b7c1-6dc8d273f6fc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 333,
        "end_line": 345,
        "content": "async def _generate_jina_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Jina.\"\"\"\n\n        embeddings = await self.embedding_service.jina_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"retrieval.query\",\n        )\n        \n        return embeddings\n\nMethod in QueryUseCase class that generates vector embeddings using Jina AI for text queries. Part of a vector search system that supports multiple embedding providers (Pinecone, Cohere, Jina, Voyage). The method processes query strings, calls the embedding service with appropriate parameters, and returns vector representations for semantic search applications.",
        "size": 814,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_jina_embedding"
    },
    {
        "id": "beb4d35a-631b-43ef-8df4-268f92e65106",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 347,
        "end_line": 357,
        "content": "async def _generate_voyage_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        embeddings = await self.embedding_service.voyageai_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"query\",\n        )\n\n        return embeddings\n\n\nMethod within the QueryUseCase class that generates embeddings using Voyage AI models. It calls the voyageai_dense_embeddings method from the embedding_service, passing model name, dimension, input questions, and specifying \"query\" as input type. Part of the system that processes queries for vector search operations, specifically handling Voyage AI embedding generation alongside other providers like Pinecone, Cohere, and Jina.\n",
        "size": 824,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_voyage_embedding"
    },
    {
        "id": "83af0643-92c2-4182-b4ef-3f32e989c340",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 359,
        "end_line": 381,
        "content": "async def _perform_hybrid_search(\n        self, request_data, namespace_name, host, dense_embedding, question\n    ):\n        \"\"\"Perform hybrid search using both dense and sparse embeddings.\"\"\"\n\n        try:\n            sparse_embedding = self.embedding_service.pinecone_sparse_embeddings(\n                inputs=[question]\n            )\n\n            return await self.pinecone_service.pinecone_hybrid_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                alpha=request_data.alpha,\n                query_vector_embeds=dense_embedding,\n                query_sparse_embeds=sparse_embedding[0],\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing hybrid search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nA private method within the QueryUseCase class that performs hybrid vector search by combining dense and sparse embeddings. It generates sparse embeddings from the question text, then calls the pinecone_hybrid_query method with both embedding types to conduct a retrieval that balances semantic similarity and keyword matching. The method handles proper error logging and exception propagation, supporting the main query evaluation pipeline that measures search quality metrics.\n",
        "size": 1424,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_hybrid_search"
    },
    {
        "id": "33e93dbb-425f-4160-8a1f-e29772812bca",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 383,
        "end_line": 399,
        "content": "async def _perform_regular_search(\n        self, request_data, namespace_name, host, dense_embedding\n    ):\n        \"\"\"Perform regular dense vector search.\"\"\"\n\n        try:\n            return await self.pinecone_service.pinecone_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                vector=dense_embedding,\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing regular search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nA method within the QueryUseCase class that executes a standard vector search operation in Pinecone without hybrid capabilities. It takes search parameters including the namespace, host, and dense vector embedding, then calls the pinecone_service to perform the vector similarity search with the specified top_k results. The method handles errors by logging them and raising appropriate HTTP exceptions. This is contrasted with the _perform_hybrid_search method which combines both dense and sparse embeddings.",
        "size": 1171,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_regular_search"
    },
    {
        "id": "b4b440c8-97e1-4ce2-bc4b-86c6c7915c56",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 401,
        "end_line": 404,
        "content": "async def _get_ground_truth(self, query):\n        \"\"\"Fetch ground truth data for the query.\"\"\"\n\n        return await self.index_repository.fetch_ground_truth(query=query)\n\nMethod in QueryUseCase class that retrieves ground truth data for a given query from the index repository. Part of an evaluation system for vector search that compares search results against known correct answers. Used within the search evaluation pipeline alongside other methods that handle embedding generation, search execution, and metric calculation.",
        "size": 528,
        "parent-class": "QueryUseCase",
        "function_name": "_get_ground_truth"
    },
    {
        "id": "2434db1c-3ff9-42fc-9f1a-73fdda8b6ef8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 406,
        "end_line": 450,
        "content": "def _calculate_evaluation_metrics(self, relevant_docs, ground_truth_ids, top_k):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n\n        try:\n            return {\n                \"precision_at_k\": EvaluationService.precision_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"recall_at_k\": EvaluationService.recall_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids, k=top_k\n                ),\n                \"bpref\": EvaluationService.bpref(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids\n                ),\n                \"mrr\": EvaluationService.reciprocal_rank(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids\n                ),\n                \"map\": EvaluationService.mean_average_precision(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k\n                ),\n            }\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error calculating evaluation metrics: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in QueryUseCase class that calculates multiple information retrieval evaluation metrics for search results. Takes retrieved documents, ground truth document IDs, and top-k value to compute precision@k, recall@k, f1-score@k, hit rate@k, NDCG@k, BPREF, MRR, and MAP using the EvaluationService. Used during the evaluation process for document retrieval performance measurement within a vector search system that supports multiple embedding models and hybrid search capabilities.",
        "size": 2499,
        "parent-class": "QueryUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "fcddde00-71fb-4a2a-aa2f-5aa13c530c2a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 452,
        "end_line": 504,
        "content": "def average_metrics(self, metrics_list, top_k):\n    \n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_k + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n        \n        avg_dict = sum_dict.copy()\n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    \n                    for sub_key, sub_value in value.items():\n                        sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    \n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] \n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key]\n        \n        return avg_dict\n\n\nMethod in QueryUseCase class that calculates average evaluation metrics across multiple search results. Processes metrics like precision, recall, F1-score, hit rate, NDCG, BPREF, MRR and MAP at different k values. Handles hierarchical metric structures by summing values and computing averages, supporting both scalar metrics and nested metrics with k-specific values. Used during query evaluation to aggregate performance statistics across multiple questions for final reporting in the search evaluation system.\n",
        "size": 2286,
        "parent-class": "QueryUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "08e3d50a-5999-4f88-b93d-37e3970ee1ff",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 506,
        "end_line": 515,
        "content": "def validate_embedding(self, question: str, embedding: list, expected_dim: int):\n        \"\"\"Check if embedding is valid; otherwise, log failure.\"\"\"\n        if embedding is None or not isinstance(embedding, list):\n            loggers[\"embedding\"].error(f\"Invalid embedding for question: {question}\")\n\n        elif len(embedding) != expected_dim:\n            loggers[\"embedding\"].error(f\"Invalid embedding dimension for question: {question}\")\n    \n        elif any(np.isnan(embedding)) or any(np.isinf(embedding)):\n            loggers[\"embedding\"].error(f\"Invalid embedding values for question: {question}\")\n\nValidation method within QueryUseCase class that performs quality control checks on generated embeddings. Ensures embeddings are properly formatted lists of the expected dimension and contain valid numerical values (no NaN or infinite values). Used after embedding generation to maintain data integrity before vector search operations. Part of the query processing pipeline that performs vector similarity searches for document retrieval.",
        "size": 1045,
        "parent-class": "QueryUseCase",
        "function_name": "validate_embedding"
    },
    {
        "id": "77cb1dd6-1f47-4d40-92de-965d5144b73a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 1,
        "end_line": 11,
        "content": "import asyncio\nimport json\nimport os\nfrom uuid import uuid4\nfrom fastapi import UploadFile, HTTPException, status\nimport aiofiles\nfrom app.config.settings import settings\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\nfrom app.utils.llm_utils import LLMUtils\nfrom app.utils.logging_util import loggers\n\nImport statements for the FileUploadUseCase module which handles JSON file processing. Includes asyncio for asynchronous operations, file handling utilities, database repositories for ground truth and raw data, and custom utilities for logging and LLM interactions. The module is built for FastAPI application with specific error handling capabilities.",
        "size": 716,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "2fe52ccb-0b6e-495f-b57d-78a2b1b64ff0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 14,
        "end_line": 17,
        "content": "def __init__(self):\n        self.raw_data_repo = RawDataRepo()\n        self.gt_data_repo = GTDataRepo()\n        self.llm_utils = LLMUtils()\n\nConstructor initializing repositories and utilities for the FileUploadUseCase class. Creates instances of RawDataRepo for storing raw document data, GTDataRepo for ground truth data management, and LLMUtils for language model operations used in file processing workflows.",
        "size": 412,
        "parent-class": "FileUploadUseCase",
        "function_name": "__init__"
    },
    {
        "id": "5e3cb82e-ad4d-4125-a652-75b27894370d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 19,
        "end_line": 25,
        "content": "async def store_file_locally(self, file: UploadFile):\n        os.makedirs(settings.UPLOAD_DIR, exist_ok=True)\n        file_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n        async with aiofiles.open(file_path, \"wb\") as f:\n            while chunk := await file.read(2 * 1024 * 1024):  # Read in 2MB chunks\n                await f.write(chunk)\n        return file_path\n\nMethod in FileUploadUseCase that handles asynchronous file storage operations. Creates the upload directory if it doesn't exist, saves uploaded files to the configured path using chunked reading (2MB at a time) to efficiently handle large files, and returns the file path. Part of the document processing pipeline for the data enrichment system.",
        "size": 740,
        "parent-class": "FileUploadUseCase",
        "function_name": "store_file_locally"
    },
    {
        "id": "9be02339-5f14-4fa9-9b3a-ee5893e61d34",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 27,
        "end_line": 39,
        "content": "async def process_and_enrich_json(self, file_path: str):\n        async with aiofiles.open(file_path, \"r\") as f:\n            content = await f.read()\n            data = json.loads(content)\n        if not isinstance(data, list):\n            raise ValueError(\"JSON data must be a list\")\n        enriched_data = []\n        for item in data:\n            item[\"_id\"] = str(uuid4())\n            enriched_data.append(item)\n        async with aiofiles.open(file_path, \"w\") as f:\n            await f.write(json.dumps(enriched_data))\n        return enriched_data\n\nMethod within FileUploadUseCase that asynchronously reads a JSON file, validates it's a list, enriches each item with a unique UUID identifier, overwrites the original file with the enriched data, and returns the enriched dataset. Part of the document processing pipeline for handling uploaded files in a FastAPI application.",
        "size": 878,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_and_enrich_json"
    },
    {
        "id": "61bc5cf8-bb54-4b9b-8adf-6dfeda21224f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 41,
        "end_line": 73,
        "content": "async def process_multi_chunk(self, data: dict):\n\n        loggers['main'].info(f\"length of data before : {len(data)}\")\n        chunks = [item for item in data[\"chunks\"] if item.get(\"text\", \"\").strip()]\n        loggers['main'].info(f\"length of data after : {len(chunks)}\")\n\n        chunk_data_for_llm = [\n            {\"text\": chunk[\"text\"], \"_id\": chunk[\"_id\"]} for chunk in data[\"chunks\"]\n        ]\n\n        response_json = await self.llm_utils.generate_multi_chunk_question(\n            {\"chunks\": chunk_data_for_llm, \"file_type\": data[\"file_type\"]}\n        )\n        # loggers['main'].info(f\"response_json from generate multi : {response_json}\")\n\n        if isinstance(response_json, str):\n            try:\n                response = json.loads(response_json)\n            except Exception as e:\n                raise ValueError(str(e))\n        else:\n            response = response_json\n\n        final_results = []\n        for question_item in response:\n            relevant_ids = question_item[\"relevant_ids\"]\n            relevant_chunks = [chunk for chunk in data[\"chunks\"] if str(chunk[\"_id\"]) in relevant_ids]\n            \n            final_results.append({\n                \"question\": question_item[\"question\"],\n                \"chunks\": relevant_chunks\n            })\n        return final_results\n\nMethod in FileUploadUseCase that processes a collection of text chunks to generate multi-chunk questions. Filters empty chunks, formats data for LLM processing, calls generate_multi_chunk_question from LLMUtils, handles JSON parsing of the response, and creates a structured dataset by pairing generated questions with their relevant text chunks. Used within the file upload workflow for processing uploaded JSON data and creating training datasets for question-answering systems.",
        "size": 1786,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_multi_chunk"
    },
    {
        "id": "d63b06dd-02b0-41a9-ad27-ffe3f8c00aef",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 75,
        "end_line": 92,
        "content": "async def generate_multi_chunk_queries(self, data):\n        dataset = []\n        tasks = []\n        for i in range(\n            0,\n            min(len(data[\"chunks_with_metadata\"]), settings.NO_OF_CHUNKS_AT_A_TIME*settings.MULTI_CHUNK_QUERIES_COUNT),\n            settings.NO_OF_CHUNKS_AT_A_TIME\n        ):\n\n            selected_items = data[\"chunks_with_metadata\"][i:i+settings.NO_OF_CHUNKS_AT_A_TIME]\n            task = self.process_multi_chunk({\"chunks\": selected_items, \"file_type\": data[\"file_type\"]})\n            tasks.append(task)\n        \n        results = await asyncio.gather(*tasks)\n        for result in results:\n            dataset.extend(result)\n        loggers['main'].info(f\"length of results in generate multi : {len(results)}\")\n        return dataset\n\nMethod in FileUploadUseCase class that creates and executes multiple concurrent tasks for processing text chunks in batches. Divides input data into smaller batches based on configuration settings, processes each batch asynchronously using process_multi_chunk to generate relevant questions, and then combines all results into a single dataset. Uses asyncio.gather for parallel execution to improve performance when handling large datasets during file upload processing.",
        "size": 1239,
        "parent-class": "FileUploadUseCase",
        "function_name": "generate_multi_chunk_queries"
    },
    {
        "id": "bf8b02ca-f800-4445-a052-2ff105686d2c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 94,
        "end_line": 171,
        "content": "async def execute(self, request_data):\n        try:\n\n            # File Store\n            file = request_data.get(\"input_data\")\n            file_name = request_data.get(\"file_name\")\n            file_type = request_data.get(\"file_type\")\n\n            if not isinstance(file_name, str):\n                raise ValueError(\"File name must be a string\")\n            _, file_extension = os.path.splitext(file_name)\n            if file_extension.lower() != \".json\":\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file is not in .json format\")\n\n            file_path = await self.store_file_locally(file)\n\n            existing_gt_data = await self.gt_data_repo.is_exist(file_name, file_type)\n            \n            if existing_gt_data:\n                doc = await self.raw_data_repo.is_exist(file_name, file_type)\n                doc = doc[\"data\"][0]\n                file_schema = {key: type(value).__name__ for key, value in doc.items() if key != \"_id\"}\n                if \"text\" not in file_schema.keys():\n                    raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n                \n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_gt_data.get(\"data\", []), default=str))\n                \n                existing_raw_data = await self.raw_data_repo.is_exist(file_name, file_type)\n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_raw_data.get(\"data\", []), default=str))\n                return {\"data\": \"File already processed\", \"file_schema\": json.dumps(file_schema)}\n            \n            enriched_data = await self.process_and_enrich_json(file_path)\n\n            loggers['main'].info(f\"length of data before : {len(enriched_data)}\")\n            enriched_data = [item for item in enriched_data if item.get(\"text\", \"\").strip()]\n            loggers['main'].info(f\"length of data after : {len(enriched_data)}\")\n\n            file_schema = {key: type(value).__name__ for key, value in enriched_data[0].items() if key != \"_id\"}\n            if \"text\" not in list(file_schema.keys()):\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n            \n            # Generate Queries\n            multi_chunk_dataset = await self.generate_multi_chunk_queries(\n                {\"chunks_with_metadata\": enriched_data, \"file_type\": file_type}\n            )\n            loggers[\"main\"].info(f\"length of multi chunk dataset : {len(multi_chunk_dataset)}\")\n            raw_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": enriched_data\n            }\n            await self.raw_data_repo.insert_documents(raw_data_document)\n\n            gt_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": [\n                    item.copy() for item in multi_chunk_dataset\n                ]\n            }\n            # loggers[\"main\"].info(f\"gt_data_document{gt_data_document}\")\n            try:\n                await self.gt_data_repo.insert_documents(gt_data_document)\n            except Exception as e:\n                loggers['main'].error(f\"documents were not inserted in mongodb , length of gt: {len(gt_data_document.get('data', []))}\")\n\n            dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n            async with aiofiles.open(dataset_path, \"w\") as f:\n                await f.write(json.dumps(multi_chunk_dataset))\n\n            return {\"data\": \"File processed and dataset generated successfully\", \"file_schema\": json.dumps(file_schema)}\n        except Exception as e:\n            loggers['main'].error(f\"file upload usecase outermost code breaks : {str(e)}\")\n            raise Exception(str(e))\n\nMain execution method of FileUploadUseCase that handles JSON file processing workflow. Validates and stores uploaded files, checks for existing files in repositories, extracts and validates schemas requiring a \"text\" field, filters and enriches data, generates multi-chunk queries, and stores processed data in both raw and ground truth repositories. Handles exceptions with detailed logging and returns processing status with file schema information. Implements idempotent behavior for previously processed files.",
        "size": 4667,
        "parent-class": "FileUploadUseCase",
        "function_name": "execute"
    },
    {
        "id": "195eba65-2900-4f4c-827c-072eb0da2175",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi import Depends, HTTPException, status\nfrom app.models.domain.indexupsert import IndexUpsert, Namespace\nfrom app.repositories.index_upsert_repository import IndexUpsertRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.utils.logging_util import loggers\nimport time\n\nImport statements for the IndexUpsertUseCase class that handles vector embedding generation and upsert operations to Pinecone. Defines dependencies on repositories and services for database operations, embedding generation across multiple providers (Pinecone, Cohere, Jina, Voyage), and vector database interactions. Includes utilities for asynchronous operations, logging, and time tracking.",
        "size": 835,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "95a1b051-c89c-4e49-8056-e5eed32ec178",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 17,
        "end_line": 49,
        "content": "def __init__(\n        self,\n        index_upsert_repository=Depends(IndexUpsertRepository),\n        pinecone_service=Depends(PineconeService),\n        embedding_service=Depends(EmbeddingService),\n    ):\n        self.index_upsert_repository = index_upsert_repository\n        self.pinecone_service = pinecone_service\n        self.embedding_service = embedding_service\n        self.file_path = \"uploads/raw_dataset.json\"\n        self.chunk_size = 90\n        self.semaphore = asyncio.Semaphore(3)\n        self.upsert_batch_size = 50\n        self.model_provider = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"jina-clip-v2\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n\nConstructor for IndexUpsertUseCase class initializing dependencies, configuration parameters, and embedding model mappings. Sets up repository connections, service dependencies, file paths, processing parameters like chunk size and batch size, and defines a comprehensive dictionary mapping embedding models to their respective providers (pinecone, cohere, jina, voyage). Establishes a semaphore for concurrent processing control with a limit of 3 concurrent operations.",
        "size": 1840,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "__init__"
    },
    {
        "id": "be2e9788-3701-4bc7-8e2e-409587260151",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 51,
        "end_line": 76,
        "content": "async def process_chunk(self, chunk, provider, embed_model, dimension=None):\n        async with self.semaphore:\n            try:\n                if provider == \"pinecone\":\n                    return (\n                        await self.embedding_service.pinecone_dense_embeddings(\n                            chunk, embed_model, dimension=dimension\n                        )\n                    )\n                elif provider == \"cohere\":\n                    return await self.embedding_service.cohere_dense_embeddings(\n                        embed_model, chunk\n                    )\n                elif provider == \"jina\":\n                    return await self.embedding_service.jina_dense_embeddings(\n                        embed_model, dimension, chunk, \"retrieval.passage\"\n                    )\n                elif provider == \"voyage\":\n                    return await self.embedding_service.voyageai_dense_embeddings(\n                        embed_model, dimension, chunk\n                    )\n            except Exception as e:\n                loggers[\"main\"].error(\n                    f\"Error processing chunk with {provider} provider: {str(e)}\"\n                )\n                raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method within IndexUpsertUseCase that processes batches of text chunks by routing them to the appropriate embedding service based on provider type (pinecone, cohere, jina, or voyage). Uses a semaphore for concurrency control during embedding generation and handles provider-specific API calls with error logging and exception handling. Supports vector database indexing operations with rate limiting.",
        "size": 1660,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "process_chunk"
    },
    {
        "id": "b8f4ec8f-c2ec-434e-8596-c5a81a7f5971",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 78,
        "end_line": 112,
        "content": "async def _get_embeddings(self, data, embed_model, dimension):\n        try:\n            all_embeddings = []\n            embedding_provider = self.model_provider.get(embed_model)\n\n            if embedding_provider == \"pinecone\":\n                inputs = [{\"text\": item[\"text\"]} for item in data]\n            elif embedding_provider == \"cohere\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"jina\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"voyage\":\n                inputs = [item.get(\"text\", item.get(\"code\")) for item in data]\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            chunks = [\n                inputs[i : i + self.chunk_size]\n                for i in range(0, len(inputs), self.chunk_size)\n            ]\n            tasks = [\n                self.process_chunk(\n                    chunk, embedding_provider, embed_model, dimension\n                )\n                for chunk in chunks\n            ]\n            chunk_results = await asyncio.gather(*tasks)\n\n            for embeddings in chunk_results:\n                all_embeddings.extend(embeddings)\n\n            return all_embeddings\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate method in IndexUpsertUseCase class that generates embeddings for text data by determining the appropriate provider (pinecone, cohere, jina, or voyage) based on the model name, dividing inputs into smaller chunks for processing, running embedding generation asynchronously with semaphore control, and combining results into a single collection. The method formats input data according to provider requirements, handles errors with logging, and supports different embedding models across multiple providers.",
        "size": 1979,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_get_embeddings"
    },
    {
        "id": "5a1380cc-f73a-4b89-afc5-889c6471e09b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 114,
        "end_line": 122,
        "content": "async def _upsert_batch(self, index_host, batch, namespace_name):\n        \"\"\"Helper function to upsert a single batch of vectors\"\"\"\n        try:\n            return await self.pinecone_service.upsert_vectors(\n                index_host, batch, namespace_name\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error upserting batch: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nHelper method in IndexUpsertUseCase class that handles the upserting of a single batch of vectors to Pinecone. Takes index_host, batch of vectors, and namespace_name as parameters, calls the pinecone_service to perform the actual vector upsert operation, and implements error handling with logging and HTTP exception raising. This method is used by the _prepare_and_upsert method as part of the vector database batch processing workflow.",
        "size": 875,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_upsert_batch"
    },
    {
        "id": "9c730c07-0ede-44a1-ad5a-dfc158294844",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 124,
        "end_line": 167,
        "content": "async def _prepare_and_upsert(\n        self, data, embed_model, dimension, index_host, namespace_name\n    ):\n        try:\n            all_embeddings = await self._get_embeddings(\n                data, embed_model, dimension\n            )\n\n            text_list = [item[\"text\"] for item in data]\n            sparse_embeds = self.embedding_service.pinecone_sparse_embeddings(\n                text_list\n            )\n            final_upsert_format = await self.pinecone_service.upsert_format(\n                data, all_embeddings, sparse_embeds\n            )\n\n            batches = [\n                final_upsert_format[i : i + self.upsert_batch_size]\n                for i in range(0, len(final_upsert_format), self.upsert_batch_size)\n            ]\n\n            loggers[\"main\"].info(f\"Upserting {len(final_upsert_format)} vectors in {len(batches)} batches\")\n\n            upsert_tasks = [\n                self._upsert_batch(index_host, batch, namespace_name)\n                for batch in batches\n            ]\n            \n            # Gather results from all batches\n            batch_results = await asyncio.gather(*upsert_tasks)\n            \n            # Combine results\n            total_upserted = sum(result.get(\"upserted_count\", 0) for result in batch_results)\n            time.sleep(15)\n            return {\n                \"upserted_count\": total_upserted,\n                \"batches_processed\": len(batches),\n                \"batch_results\": batch_results\n            }\n\n    \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in preparing and upserting vectors : {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate method in IndexUpsertUseCase class that processes document data into vector embeddings and upserts them to Pinecone. Handles generating both dense and sparse embeddings, formats data for Pinecone, divides vectors into batches for efficient processing, and performs parallel upsert operations using asyncio. Returns statistics about the upsert operation including counts of vectors processed and batches completed. Core vector embedding preparation and database insertion functionality for the vector search system.",
        "size": 2192,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_prepare_and_upsert"
    },
    {
        "id": "cb7f3bcc-bf25-4dbf-961d-bbac7da5204d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 169,
        "end_line": 196,
        "content": "async def _save_in_db(\n        self,\n        file_name,\n        embed_model,\n        index_name,\n        index_host,\n        dimension,\n        similarity_metric,\n    ):\n        namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n        namespace = Namespace(\n            name=namespace_name, filename=file_name, embedding_model=embed_model\n        )\n\n        index_upsert = IndexUpsert(\n            index_name=index_name,\n            index_host=index_host,\n            dimension=dimension,\n            similarity_metric=similarity_metric,\n        )\n\n        index_upsert.add_namespace(namespace)\n        return (\n            await self.index_upsert_repository.add_index_upsert_details(\n                index_upsert\n            ),\n        )\n\nHelper method in IndexUpsertUseCase that persists vector index metadata to the database. Creates a namespace object with a formatted name pattern, constructs an IndexUpsert object with index parameters, associates the namespace with the index, and saves the relationship using the repository. Used during the vector embedding and upsert process to track index configurations and namespaces for retrieval operations.",
        "size": 1163,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_save_in_db"
    },
    {
        "id": "b1a8d4df-100c-448b-a5d3-a11c87a6fb18",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 198,
        "end_line": 300,
        "content": "async def index_upsert(self, request):\n        try:\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            embed_model = request.embed_model\n\n            already_upserted = (\n                await self.index_upsert_repository.find_matching_index_upsert(\n                    dimension, similarity_metric, file_name, embed_model\n                )\n            )\n\n            if already_upserted:\n                return {\n                    \"message\": \"such dimension, similarity metric, filename and embed_model configuration already exists, move on to query\"\n                }\n\n            with open(self.file_path, \"r\") as file:\n                data = json.load(file)\n\n            loggers[\"main\"].info(f\"length of data before : {len(data)}\")\n            data = [item for item in data if item.get(\"text\", \"\").strip()]\n            loggers[\"main\"].info(f\"length of data after : {len(data)}\")\n\n\n\n            already_index = (\n                await self.index_upsert_repository.find_matching_index(\n                    dimension, similarity_metric\n                )\n            )\n\n            if not already_index:\n                index_json = await self.pinecone_service.list_pinecone_indexes()\n                index_list = index_json.get(\"indexes\")\n                index_names = [index[\"name\"] for index in index_json[\"indexes\"]]\n                if(len(index_list) >= 5):\n                    loggers[\"main\"].error(f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n                    raise HTTPException(status_code= status.HTTP_403_FORBIDDEN, detail = f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n\n                loggers[\"main\"].info(f\"already index {already_index}\")\n                loggers[\"main\"].info(f\"index list {index_json}\")\n\n\n                index_name = f\"{similarity_metric}-{dimension}\"\n                response = await self.pinecone_service.create_index(\n                    index_name, dimension, similarity_metric\n                )\n                index_host = response.get(\"host\")\n\n                namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n                upsert_result = await self._prepare_and_upsert(\n                    data, embed_model, dimension, index_host, namespace_name\n                )\n\n                db_result = await self._save_in_db(\n                    file_name,\n                    embed_model,\n                    index_name,\n                    index_host,\n                    dimension,\n                    similarity_metric,\n                )\n\n                return {\n                    \"upsert_result\": upsert_result,\n                    \"database_result\": db_result,\n                }\n\n            index_name = already_index.get(\"index_name\")\n            index_host = already_index.get(\"index_host\")\n\n            index_json = await self.pinecone_service.list_pinecone_indexes()\n            index_list = index_json.get(\"indexes\")\n            loggers[\"main\"].info(f\"length of index list : {len(index_list)}\")\n\n            loggers[\"main\"].info(f\"already index outside if{already_index}\")\n            loggers[\"main\"].info(f\"index list outside if {index_list}\")\n\n            namespace_name = f\"{file_name}-{embed_model}-namespace\"\n            upsert_result = await self._prepare_and_upsert(\n                data, embed_model, dimension, index_host, namespace_name\n            )\n\n            db_result = await self._save_in_db(\n                file_name,\n                embed_model,\n                index_name,\n                index_host,\n                dimension,\n                similarity_metric,\n            )\n\n            return {\n                \"upsert_result\": upsert_result,\n                \"database_result\": db_result,\n            }\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in index upsert {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nMain method in IndexUpsertUseCase class that orchestrates vector database indexing process. Accepts configuration parameters (dimension, similarity_metric, file_name, embed_model) and checks if requested configuration already exists. Loads JSON data from file, filters empty entries, and either creates a new Pinecone index (if matching configuration doesn't exist) or uses an existing one. Enforces Pinecone index limit of 5. Generates namespace name from file and model names, processes data through _prepare_and_upsert method for embedding generation and vector insertion, saves index metadata to database via _save_in_db, and returns results containing upsert statistics and database operation outcome. Includes logging and error handling.\n",
        "size": 4832,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "index_upsert"
    },
    {
        "id": "ec273295-682b-451e-abe4-95e7f8cf99d8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.repositories.index_repository import IndexRepository\nfrom app.utils.logging_util import loggers\n\nImport statements and dependency setup for a FastAPI use case that integrates embedding generation and vector search capabilities using Pinecone. Imports FastAPI components for dependency injection and exception handling, along with service classes for embeddings, Pinecone operations, index repository access, and logging functionality.",
        "size": 612,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9b1ff181-20f0-4467-ae15-1e3873e7eb27",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 10,
        "end_line": 52,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(), \n    ):\n        self.index_repository = index_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n\n\nConstructor for RandomQueryUseCase class that initializes dependencies for vector search operations. Maps embedding models to their respective providers (pinecone, cohere, jina, voyage) and defines supported dimension configurations for each model. Used for random query execution in a FastAPI application with Pinecone vector database integration.\n",
        "size": 2222,
        "parent-class": "RandomQueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "1c0f8fa1-60a7-4880-9d00-894bb45eb931",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 55,
        "end_line": 78,
        "content": "async def _get_namespace_and_host(self, similarity_metric, dimension, embedding_model, file_name):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{similarity_metric}-{dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    embedding_model,\n                    file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers[\"main\"].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nA private helper method in the RandomQueryUseCase class that resolves namespace and host information for Pinecone vector index operations. The method constructs an index name from similarity metric and dimension parameters, then retrieves the corresponding namespace and host from an index repository. Includes error handling for missing namespaces or general exceptions, logging appropriate errors and raising HTTP exceptions with appropriate status codes. This method supports the vector search functionality by providing connection details for the correct Pinecone index.",
        "size": 1513,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "58b98884-252e-4efc-a6c1-a511fe392bb6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 81,
        "end_line": 119,
        "content": "async def _get_query_embeddings(self, query, embed_model, dimension):\n        try:\n            embedding_provider = self.embeddings_provider_mapping.get(embed_model)\n            if embedding_provider == \"pinecone\":\n\n                pinecone_input = [{\"text\": query}]\n                embeddings =  await self.embedding_service.pinecone_dense_embeddings(\n                    pinecone_input, embed_model, dimension=dimension,input_type=\"query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"cohere\":\n                cohere_input = [query]\n                embeddings = await self.embedding_service.cohere_dense_embeddings(\n                    cohere_input, embed_model, input_type=\"search_query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"jina\":\n                jina_input = [query]\n                embeddings = await self.embedding_service.jina_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = jina_input, input_type = \"retrieval.query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"voyage\":\n                voyage_input = [query]\n                embeddings = await self.embedding_service.voyageai_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = voyage_input, input_type = \"query\"\n                )\n                return embeddings[0]\n\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate helper method within RandomQueryUseCase that generates vector embeddings for a search query using different embedding providers. Routes requests to appropriate embedding services (Pinecone, Cohere, Jina, or Voyage) based on model selection from embeddings_provider_mapping. Handles dimension specification and proper input formatting for each provider. Used by the random_query method to prepare query vectors for similarity search operations.",
        "size": 2255,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_query_embeddings"
    },
    {
        "id": "8d31becf-d9b3-437f-8cd0-d831addb5279",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 122,
        "end_line": 166,
        "content": "async def random_query(self, request):\n        try:\n            query = request.query\n            embed_model = request.embedding_model\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            top_k = request.top_k\n            include_metadata = request.include_metadata\n            namespace, host = await self._get_namespace_and_host(similarity_metric, dimension, embed_model,file_name)\n        \n           \n            query_dense_vector = await self._get_query_embeddings(query, embed_model, dimension)\n            \n            if request.is_hybrid:\n                query_sparse_vector = self.embedding_service.pinecone_sparse_embeddings([query])\n                query_sparse_vector = query_sparse_vector[0]\n                alpha = request.alpha\n                loggers[\"main\"].info(\"sparse embeddings generated in random query use case\")\n                pinecone_response = await self.pinecone_service.pinecone_hybrid_query(\n                    host, namespace, top_k, alpha, query_dense_vector, query_sparse_vector, include_metadata\n                )\n            else:\n                pinecone_response = await self.pinecone_service.pinecone_query(\n                    host, namespace, top_k, query_dense_vector, include_metadata\n                )\n            \n            matches = pinecone_response.get(\"matches\", [])\n            final_responses = []\n            for match in matches:\n                score = match.get(\"score\", None)\n                id = match.get(\"id\", None)\n                text = match.get(\"metadata\", None).get(\"text\", None)\n                metadata = {key: value for key, value in match.get(\"metadata\").items() if key != \"text\"}\n                final_responses.append({\n                    \"id\": id,\n                    \"score\": score,\n                    \"text\": text,\n                    \"metadata\": metadata\n                })\n            return final_responses\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in random_query_usecase: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\n\nMain query execution method in RandomQueryUseCase that performs vector similarity search using Pinecone. Extracts query parameters, generates embeddings through appropriate model, executes either standard or hybrid vector search based on request configuration, processes match results, and returns formatted response with scores, text, and metadata. Handles namespace retrieval, embedding generation, error handling, and supports multiple embedding models with different dimensions.\n",
        "size": 2693,
        "parent-class": "RandomQueryUseCase",
        "function_name": "random_query"
    },
    {
        "id": "1c1f51f7-8c69-41ed-8f98-7651a88593fc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\n\nImport statements for the RandomQuestionUseCase class, including FastAPI dependencies, custom repository interfaces for ground truth data (GTDataRepo) and raw data (RawDataRepo) access, and HTTP exception handling components.",
        "size": 385,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d0d7c282-796f-4f60-ab49-db35b11181d7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 9,
        "end_line": 15,
        "content": "def __init__(\n        self, \n        gt_data_repo: GTDataRepo = Depends(),\n        raw_data_repo: RawDataRepo = Depends(),\n    ):\n        self.gt_data_repo = gt_data_repo\n        self.raw_data_repo = raw_data_repo\n\nConstructor for RandomQuestionUseCase class that injects dependencies for ground truth data repository and raw data repository using FastAPI's dependency injection system. Sets up repositories needed for retrieving random questions with their associated text chunks.",
        "size": 481,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "__init__"
    },
    {
        "id": "f746b51d-98d1-4bfc-8f4c-dff43cc56742",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 17,
        "end_line": 28,
        "content": "async def random_question(self, file_name):\n        try:\n            question_with_groundtruth, ids = await self.gt_data_repo.get_random_question(file_name)\n           \n            text_content = await self.raw_data_repo.fetch_texts_by_ids(file_name,ids)\n            \n            for i in range(len(ids)):\n                question_with_groundtruth[\"chunks\"][i][\"text\"] = text_content[i]\n               \n            return question_with_groundtruth\n        except Exception as e:\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\nMethod that retrieves a random question with its ground truth from a repository, fetches corresponding text content from a raw data repository using document IDs, populates the question's chunks with text content, and returns the complete question object. Handles exceptions by raising HTTP 500 errors. Part of RandomQuestionUseCase class that depends on GTDataRepo and RawDataRepo repositories.",
        "size": 973,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "random_question"
    },
    {
        "id": "bec0fb30-f117-425f-87ae-d97b0efc3c20",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict\nimport httpx\nfrom fastapi import HTTPException\nfrom pinecone import Pinecone\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\n\nPython import statements for a Pinecone vector database service module, including asynchronous HTTP client libraries (httpx, asyncio), data handling utilities, FastAPI components for error handling, and application configuration modules. These imports support vector database operations for embedding storage and retrieval.",
        "size": 583,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "88d41ffb-e004-4496-8900-94873f831cb4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 16,
        "end_line": 31,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.api_version = settings.PINECONE_API_VERSION\n        self.index_url = settings.PINECONE_CREATE_INDEX_URL\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.upsert_url = settings.PINECONE_UPSERT_URL\n        self.query_url = settings.PINECONE_QUERY_URL\n        self.list_index_url = settings.PINECONE_LIST_INDEXES_URL\n        self.semaphore = asyncio.Semaphore(10)\n        self.pc = Pinecone(api_key=settings.PINECONE_API_KEY)\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nConstructor for the PineconeService class that initializes configuration for vector database operations. Sets up API keys, endpoints for index management, vector operations, connection pool controls with a semaphore, creates a Pinecone client instance, and configures HTTP timeout settings for network operations. This forms the foundation for all vector database interactions in the service.",
        "size": 1272,
        "parent-class": "PineconeService",
        "function_name": "__init__"
    },
    {
        "id": "5a14c696-0d6c-4323-9ee9-ee1f02818d67",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 33,
        "end_line": 53,
        "content": "async def list_pinecone_indexes(self):\n        url = self.list_index_url\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url, headers=headers)\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n\n            loggers[\"main\"].error(f\"Error creating index: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the PineconeService class that retrieves a list of all indexes from Pinecone's vector database. Makes an HTTP GET request with appropriate authentication headers, handles error cases by logging and raising appropriate HTTP exceptions, and returns the JSON response from Pinecone's API. Part of a larger service that manages vector database operations for semantic search functionality.",
        "size": 1192,
        "parent-class": "PineconeService",
        "function_name": "list_pinecone_indexes"
    },
    {
        "id": "1dd113f6-fdd8-4706-83ee-58af238b8c02",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 55,
        "end_line": 118,
        "content": "async def create_index(\n        self, index_name: str, dimension: int, metric: str\n    ) -> Dict[str, Any]:\n        if self.pc.has_index(index_name) == False:\n            index_data = {\n                \"name\": index_name,\n                \"dimension\": dimension,\n                \"metric\": metric,\n                \"spec\": {\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}},\n            }\n\n            headers = {\n                \"Accept\": \"application/json\",\n                \"Content-Type\": \"application/json\",\n                \"Api-Key\": self.pinecone_api_key,\n                \"X-Pinecone-API-Version\": self.api_version,\n            }\n\n            try:\n                async with httpx.AsyncClient() as client:\n                    response = await client.post(\n                        self.index_url, headers=headers, json=index_data\n                    )\n                    response.raise_for_status()\n\n                    retry_count = 0\n                    max_retries = 30\n                    while retry_count < max_retries:\n                        status = (\n                            self.pc.describe_index(index_name)\n                            .get(\"status\")\n                            .get(\"state\")\n                        )\n                        loggers[\"main\"].info(f\"Index status: {status}\")\n\n                        if status == \"Ready\":\n                            loggers[\"main\"].info(f\"Index {index_name} is ready\")\n                            break\n\n                        retry_count += 1\n                        time.sleep(2)\n\n                    if retry_count > max_retries:\n                        raise HTTPException(\n                            status_code=500, detail=\"Index creation timed out\"\n                        )\n\n                    loggers[\"main\"].info(\"Index Created\")\n                    return response.json()\n\n            except httpx.HTTPStatusError as e:\n                parsed_response = json.loads(response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\n                    \"message\", \"Unknown error occurred\"\n                )\n                loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            except Exception as e:\n                loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        else:\n            loggers[\"main\"].info(\"index already created\")\n            return {\"host\": self.pc.describe_index(index_name).get(\"host\")}\n\nAsynchronous method in the PineconeService class that creates a new serverless Pinecone vector index with specified parameters. Performs index creation via API request, polls for index readiness with a retry mechanism, handles various error conditions, and returns index information. If the index already exists, returns the host information without recreating it. Includes detailed error handling for HTTP and general exceptions, with appropriate logging and status code responses.",
        "size": 3094,
        "parent-class": "PineconeService",
        "function_name": "create_index"
    },
    {
        "id": "5aa36de5-59ec-4fda-8b52-6343c9134a0e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 120,
        "end_line": 138,
        "content": "async def upsert_format(\n        self, chunks: list, vector_embeddings: list, sparse_embeddings: list\n    ):\n        results = []\n        for i in range(len(chunks)):\n            metadata = {key: value for key, value in chunks[i].items() if key != \"_id\"}\n\n            metadata[\"created_at\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            result = {\n                \"id\": chunks[i][\"_id\"],\n                \"values\": vector_embeddings[i],\n                \"metadata\": metadata,\n                \"sparse_values\": {\n                    \"indices\": sparse_embeddings[i][\"indices\"],\n                    \"values\": sparse_embeddings[i][\"values\"],\n                },\n            }\n            results.append(result)\n        return results\n\nMethod in PineconeService class that formats document chunks with their vector and sparse embeddings for Pinecone upsert operations. Transforms input data into the required Pinecone vector format by extracting metadata from chunks, adding timestamps, combining with vector embeddings, and structuring sparse vector components (indices and values) for hybrid search functionality.",
        "size": 1119,
        "parent-class": "PineconeService",
        "function_name": "upsert_format"
    },
    {
        "id": "488ed445-dfb7-4fbc-a71c-0b5de443df38",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 140,
        "end_line": 169,
        "content": "async def upsert_vectors(self, index_host, input, namespace):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        url = self.upsert_url.format(index_host)\n\n        payload = {\"vectors\": input, \"namespace\": namespace}\n        try:\n            async with httpx.AsyncClient(timeout= self.timeout) as client:\n                response = await client.post(\n                    url=url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors http status error : {str(e)} - {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)    \n        \n        except httpx.HTTPError as e:    \n            loggers[\"main\"].error(f\"Error in upsert vectors http error : {str(e)}\")\n            raise HTTPException(status_code=400, detail=str(e))\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors : {str(e)} \")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in PineconeService class that uploads vector embeddings to Pinecone. Takes an index host URL, vector input data, and namespace parameter. Constructs appropriate headers with API authentication, builds the request payload, and handles the HTTP POST operation with timeout settings. Implements comprehensive error handling for different HTTP error types, logging specific error messages and raising appropriate FastAPI exceptions with status codes. Part of the vector database interaction functionality used for storing embeddings in Pinecone's vector database.",
        "size": 1829,
        "parent-class": "PineconeService",
        "function_name": "upsert_vectors"
    },
    {
        "id": "4edcaab8-fee0-4c5c-8c16-2045863dd426",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 171,
        "end_line": 181,
        "content": "def hybrid_scale(self, dense, sparse, alpha: float):\n\n        if alpha < 0 or alpha > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        # scale sparse and dense vectors to create hybrid search vecs\n        hsparse = {\n            \"indices\": sparse[\"indices\"],\n            \"values\": [v * (1 - alpha) for v in sparse[\"values\"]],\n        }\n        hdense = [v * alpha for v in dense]\n        return hdense, hsparse\n\nVector scaling method in Pinecone service that balances dense and sparse embeddings for hybrid search using a weighting factor alpha. It validates alpha is between 0-1, then scales sparse vector values by (1-alpha) and dense vector values by alpha, preparing optimized vector representations for hybrid search queries in Pinecone.",
        "size": 766,
        "parent-class": "PineconeService",
        "function_name": "hybrid_scale"
    },
    {
        "id": "96f96528-4dc2-4dae-a40e-18e1c02d246b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 183,
        "end_line": 247,
        "content": "async def pinecone_hybrid_query(\n        self,\n        index_host,\n        namespace,\n        top_k,\n        alpha: int,\n        query_vector_embeds: list,\n        query_sparse_embeds: dict,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        if query_vector_embeds is None or query_sparse_embeds is None:\n            time.sleep(2)\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        hdense, hsparse = self.hybrid_scale(\n            query_vector_embeds, query_sparse_embeds, alpha\n        )\n\n        payload = {\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n            \"vector\": hdense, \n            \"sparseVector\": {\n                \"indices\": hsparse.get(\n                    \"indices\"\n                ),  \n                \"values\": hsparse.get(\n                    \"values\"\n                ),  \n            },\n            \"topK\": top_k,\n            \"namespace\": namespace,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone hybrid query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error performing hybrid query: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in PineconeService class that executes hybrid search queries against a Pinecone vector database by combining dense and sparse vectors. Takes parameters for index host, namespace, results count, alpha weighting factor, query embeddings, metadata inclusion flag, and optional filters. Scales vectors using the hybrid_scale method, constructs the query payload, makes an asynchronous HTTP request to Pinecone's API, logs query usage, and handles various error conditions with appropriate exception handling and status codes.",
        "size": 2877,
        "parent-class": "PineconeService",
        "function_name": "pinecone_hybrid_query"
    },
    {
        "id": "100e0995-8725-4be3-8380-1b88cfa91d15",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 249,
        "end_line": 297,
        "content": "async def pinecone_query(\n        self,\n        index_host: str,\n        namespace: str,\n        top_k: int,\n        vector: list,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        payload = {\n            \"namespace\": namespace,\n            \"vector\": vector,\n            # \"filter\": filter_dict,\n            \"topK\": top_k,\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone Normal query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the PineconeService class for performing standard vector queries against a Pinecone vector database. The method handles formatting the query payload with dense vector embeddings, namespace specification, and optional filtering. It manages API authentication, processes responses including read usage metrics, and implements comprehensive error handling for HTTP and general exceptions. Unlike the hybrid_query method, this function uses only dense vectors without sparse vector components.",
        "size": 2328,
        "parent-class": "PineconeService",
        "function_name": "pinecone_query"
    },
    {
        "id": "dfa08a30-a1ed-4619-b348-342c97234fb9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nimport pickle\nimport httpx\nfrom fastapi import HTTPException, status\nfrom pinecone_text.sparse import BM25Encoder\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\n\nImport statements section for an embedding service module that handles text embedding operations with various providers (Pinecone, Cohere, Jina, TogetherAI, VoyageAI). Imports essential libraries and components for API interactions, logging, serialization, and exception handling. Sets up the foundation for the EmbeddingService class that follows.",
        "size": 574,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c384425a-bf3b-4a46-934a-225d3023cce4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 18,
        "end_line": 38,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.pinecone_embedding_url = settings.PINECONE_EMBED_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.togetherai_api_key = settings.TOGETHERAI_API_KEY\n        self.voyageai_api_key = settings.VOYAGEAI_API_KEY\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.togetherai_base_url = settings.TOGETHERAI_BASE_URL\n        self.voyageai_base_url = settings.VOYAGEAI_BASE_URL\n        self.EMBED_SUFFIX = \"embed\"\n        self.JINA_EMBED_SUFFIX = \"embeddings\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=300.0,    # Time to read the response\n                        write=300.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nInitialization method for the EmbeddingService class that configures API endpoints, authentication keys, and connection parameters for multiple embedding providers including Pinecone, Cohere, Jina, TogetherAI, and VoyageAI. Sets up HTTP request timeout parameters for reliable API communication when generating vector embeddings.",
        "size": 1480,
        "parent-class": "EmbeddingService",
        "function_name": "__init__"
    },
    {
        "id": "5fe678c2-8381-46ea-90c8-68e277a7db01",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 40,
        "end_line": 84,
        "content": "async def pinecone_dense_embeddings(\n        self,\n        inputs: list,\n        embedding_model: str = \"llama-text-embed-v2\",\n        input_type: str = \"passage\",\n        truncate: str = \"END\",\n        dimension: int = 1024,\n    ):\n        payload = {\n            \"model\": embedding_model,\n            \"parameters\": {\n                \"input_type\": input_type,\n                \"truncate\": truncate,\n                # \"dimension\": dimension,\n            },\n            \"inputs\": inputs,\n        }\n\n        if embedding_model != \"multilingual-e5-large\":\n            payload[\"parameters\"][\"dimension\"] = dimension \n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n        }\n\n        url = self.dense_embed_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"embeddings generated\")\n                response = response.json()\n                loggers[\"pinecone\"].info(f\"pinecone hosted embedding model tokens usage: {response['usage']}\")\n                list_result = [item[\"values\"] for item in response[\"data\"]]\n                return list_result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=f\"{str(e)}-{e.response.text}\")\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the EmbeddingService class that generates dense vector embeddings using Pinecone's embedding service. Takes text inputs and optional parameters for embedding model configuration, sends the request to Pinecone's API, processes the response to extract embedding vectors, handles errors, and logs token usage. Special handling exists for the multilingual-e5-large model which doesn't accept dimension parameters. Part of a larger embedding service that supports multiple embedding providers including Pinecone, Cohere, Jina, TogetherAI, and VoyageAI.",
        "size": 2385,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_dense_embeddings"
    },
    {
        "id": "ddc67ed5-493f-449d-b5bf-dbe2cdf8a149",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 86,
        "end_line": 93,
        "content": "def pinecone_sparse_embeddings(self, inputs):\n        try:\n            sparse_vector = bm25.encode_documents(inputs)\n            return sparse_vector\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating sparse embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod within the EmbeddingService class that generates sparse vector embeddings using a BM25 encoder. Takes text inputs, encodes them using a pre-loaded BM25 encoder instance, and returns sparse vectors that represent the text content. Includes error handling that logs failures and raises appropriate HTTP exceptions. This function complements the dense embedding methods in the service, providing an alternative representation format for text search and retrieval.",
        "size": 795,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_sparse_embeddings"
    },
    {
        "id": "24b6f4b3-b524-4efd-9cf1-4e1d39fb7817",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 95,
        "end_line": 137,
        "content": "async def cohere_dense_embeddings(\n        self,\n        model_name: str,\n        texts: list[str],\n        input_type: str = \"search_document\",\n    ):\n\n        url = f\"{self.cohere_base_url}/{self.EMBED_SUFFIX}\"\n\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.cohere_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"texts\": texts,\n            \"input_type\": input_type,\n            \"embedding_types\": [\"float\"],\n        }\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout,verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                # return response.json()\n                response = response.json()\n                loggers[\"cohere\"].info(f\"cohere hosted embedding model tokens usage: { response.get('meta', {}).get('billed_units', {})}\")\n                result = response[\"embeddings\"][\"float\"]\n                return result\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}-{e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense cohere embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the EmbeddingService class for generating dense vector embeddings using Cohere's API. Takes a model name, list of texts, and input type parameter, then constructs and sends a request to Cohere's embedding endpoint. Uses httpx for async HTTP requests with configured timeout settings. Returns float embeddings after processing the response and logs token usage metrics. Implements comprehensive error handling for HTTP status errors, request failures, and general exceptions with appropriate logging and HTTP exceptions.",
        "size": 2303,
        "parent-class": "EmbeddingService",
        "function_name": "cohere_dense_embeddings"
    },
    {
        "id": "02bac1b3-c8da-4aa7-a1c5-ef61a2ae17f0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 139,
        "end_line": 187,
        "content": "async def jina_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n\n        url = f\"{self.jina_base_url}/{self.JINA_EMBED_SUFFIX}\"\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"embedding_type\": \"float\",\n            \"input\": inputs,\n        }\n\n        if model_name == \"jina-embeddings-v3\":\n            data[\"task\"] = input_type\n            data[\"late_chunking\"] = False\n            data['dimensions'] = dimension\n        elif model_name == \"jina-embeddings-v2-base-code\":\n            data[\"normalized\"] = True\n        else:\n            data[\"normalized\"] = True\n            data['dimensions'] = dimension\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout, verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"jina\"].info(f\"jina hosted embedding model tokens usage: {response.get('usage', {})}\")\n                result = [item[\"embedding\"] for item in response[\"data\"]]\n                return result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.content} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}, {e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502,  # Bad Gateway (Failed to connect)\n                detail= f\"Failed to connect to API httpx Request error : {str(e)}\",\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense jina embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nMethod in EmbeddingService class that generates dense vector embeddings using Jina AI's API. Accepts model name, dimension, input texts, and input type parameters. Constructs API request with appropriate headers and payload, handling model-specific configurations for different Jina embedding models. Makes asynchronous HTTP request to Jina's embeddings endpoint, processes the response, logs token usage, and returns extracted embeddings. Implements comprehensive error handling for HTTP status errors, request failures, and unexpected exceptions with appropriate logging and HTTPException raising.\n",
        "size": 2671,
        "parent-class": "EmbeddingService",
        "function_name": "jina_dense_embeddings"
    },
    {
        "id": "c1e0cbe4-bda3-4bfd-b093-5be582f07dcd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 189,
        "end_line": 219,
        "content": "async def togetherai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n        url = f\"{self.togetherai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        headers = {\n            \"accept\": \"application/json\",\n            \"authorization\": f\"Bearer {self.togetherai_api_key}\",\n            \"content-type\": \"application/json\"\n        }\n        payload = {\n            \"model\": model_name,\n            \"input\": inputs\n        }\n\n        try:\n            async with httpx.AsyncClient(verify = False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error:{str(e)} {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx : {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in togetherai_dense_embedding: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured : {str(e)}\")\n\nAsynchronous method in EmbeddingService class that generates dense vector embeddings using TogetherAI's API. Takes model name, dimension, text inputs, and input type parameters. Constructs API request with proper headers and payload, handles HTTP communication with error logging, and returns JSON response with embedding data. Part of a larger service that supports multiple embedding providers including Pinecone, Cohere, Jina, and VoyageAI.",
        "size": 1974,
        "parent-class": "EmbeddingService",
        "function_name": "togetherai_dense_embeddings"
    },
    {
        "id": "811857e8-7b0c-40ed-be0c-09538d3a2436",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 223,
        "end_line": 263,
        "content": "async def voyageai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list, input_type: str = \"document\"\n    ):\n        url = f\"{self.voyageai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.voyageai_api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        data = {\n            \"input\": inputs,\n            \"model\": model_name,\n            \"input_type\": input_type,\n            \"output_dimension\": dimension\n        }\n\n        try:\n\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"voyage\"].info(f\"Embedding model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                embedding_list = [item[\"embedding\"] for item in response[\"data\"]]\n                return embedding_list\n            \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {e.response.text}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error occurred in httpx status error  : {str(e)} - {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx voyage dense embed: {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in voyageai_dense_embedding: {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured in voyageai_dense_embedding: {str(e)}, \")\n\nMethod in the EmbeddingService class that generates dense vector embeddings using VoyageAI's API. Accepts model name, dimension size, input texts, and input type parameters. Makes an asynchronous HTTP request to the VoyageAI embeddings endpoint, processes the response to extract embeddings, logs token usage, and handles various error conditions with appropriate exception handling. Part of a larger embedding service that supports multiple embedding providers including Pinecone, Cohere, Jina, and TogetherAI.",
        "size": 2745,
        "parent-class": "EmbeddingService",
        "function_name": "voyageai_dense_embeddings"
    },
    {
        "id": "aa4d1089-7257-4f58-ba71-f38849b563e7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import math\nimport logging\nfrom typing import Dict, List\nfrom app.utils.logging_util import loggers\n\nImport statements for the EvaluationService class that handles information retrieval metrics. Imports the math module for mathematical calculations, logging for error handling, typing for type annotations, and custom loggers from app.utils.logging_util that are used throughout the evaluation metrics implementation.",
        "size": 417,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "4c41cad7-9d3d-4f0f-bb84-a9c578a7d6af",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 10,
        "end_line": 45,
        "content": "def _discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Discounted Cumulative Gain (DCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            retrieved_texts = [doc[\"id\"] for doc in retrieved_docs[:k]]\n            relevance_scores = [\n                1 if doc in ground_truth else 0 for doc in retrieved_texts\n            ]\n\n            if not relevance_scores:\n                return 0.0\n\n            dcg_at_k = relevance_scores[0] if relevance_scores else 0\n            for i in range(1, len(relevance_scores)):\n                dcg_at_k += relevance_scores[i] / math.log2(i + 1)\n\n            return dcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nPrivate method in EvaluationService class that calculates Discounted Cumulative Gain (DCG) at a specified rank k. Accepts retrieved documents and ground truth items, validates input types, extracts document IDs, assigns binary relevance scores (1 for matches, 0 otherwise), and applies the DCG formula with logarithmic discounting for rank positions. Used as a component in normalized DCG calculations for information retrieval evaluation metrics.",
        "size": 1739,
        "parent-class": "EvaluationService",
        "function_name": "_discounted_cumulative_gain_at_k"
    },
    {
        "id": "4e29e650-0fde-45a9-bbe2-650f5d2262b7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 48,
        "end_line": 78,
        "content": "def _ideal_discounted_cumulative_gain_at_k(\n        ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Ideal Discounted Cumulative Gain (IDCG) @ K.\n        \"\"\"\n        try:\n            if not isinstance(ground_truth, list) or not isinstance(k, int):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ideal_relevance_scores = [1] * min(len(ground_truth), k)\n\n            if not ideal_relevance_scores:\n                return 0.0\n\n            idcg_at_k = (\n                ideal_relevance_scores[0] if ideal_relevance_scores else 0\n            )\n            for i in range(1, len(ideal_relevance_scores)):\n                idcg_at_k += ideal_relevance_scores[i] / math.log2(i + 1)\n\n            return idcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in ideal_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nPrivate helper method in the EvaluationService class that calculates the Ideal Discounted Cumulative Gain (IDCG) at position K for information retrieval evaluation. This method creates an ideal ranking scenario where all relevant documents appear first, assigning them relevance scores of 1, then applies the DCG formula to this ideal ordering. IDCG serves as the normalization factor for NDCG calculations, representing the maximum possible DCG score. Used by the normalized_discounted_cumulative_gain_at_k method for ranking quality assessment in search results.",
        "size": 1671,
        "parent-class": "EvaluationService",
        "function_name": "_ideal_discounted_cumulative_gain_at_k"
    },
    {
        "id": "044b315d-9659-464c-8a50-1e9cd1c2798e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 81,
        "end_line": 119,
        "content": "def normalized_discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Normalized Discounted Cumulative Gain (NDCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ndcg_at_k = {}\n            for i in range(k):\n                dcg_at_i = EvaluationService._discounted_cumulative_gain_at_k(\n                    retrieved_docs, ground_truth, i + 1\n                )\n                idcg_at_i = (\n                    EvaluationService._ideal_discounted_cumulative_gain_at_k(\n                        ground_truth, i + 1\n                    )\n                )\n                ndcg_at_i = dcg_at_i / idcg_at_i if idcg_at_i > 0 else 0.0\n\n                ndcg_at_k[f\"NDCG@{i+1}\"] = ndcg_at_i\n\n            loggers['evaluation'].info(f\"NDCG Result: {ndcg_at_k}\")\n            return ndcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in normalized_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in EvaluationService class implementing Normalized Discounted Cumulative Gain (NDCG) calculation for information retrieval evaluation. Validates input types, computes DCG and IDCG values for each position up to k using helper methods, normalizes results, and returns a dictionary of NDCG scores at each position. Includes input validation, error handling, and logging functionality. Part of a search evaluation metrics suite alongside precision, recall, F1-score, and other relevance metrics.",
        "size": 1981,
        "parent-class": "EvaluationService",
        "function_name": "normalized_discounted_cumulative_gain_at_k"
    },
    {
        "id": "df35b04d-714e-4a91-869c-626ddee489ba",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 122,
        "end_line": 153,
        "content": "def bpref(retrieved_docs: List[Dict], ground_truth: List[str]) -> float:\n        \"\"\"\n        Computes BPREF (Binary Preference).\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            relevant_docs = set(ground_truth)\n            irrelevant_count = 0\n            total_relevant = len(relevant_docs)\n            bpref_score = 0.0\n\n            if total_relevant == 0:\n                return 0.0\n\n            for doc in retrieved_docs:\n                if doc[\"id\"] in relevant_docs:\n                    bpref_score += 1 - (min(irrelevant_count, total_relevant) / total_relevant)\n                else:\n                    irrelevant_count += 1\n\n            loggers['evaluation'].info(f\"BPREF Result: {bpref_score / total_relevant}\")\n            return bpref_score / total_relevant\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in bpref: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in the EvaluationService class that calculates the Binary Preference (BPREF) metric for search quality evaluation. Takes retrieved documents and ground truth documents as inputs, computes how well the retrieval system ranks relevant documents before irrelevant ones, and returns a normalized score between 0 and 1. Includes error handling for input validation and logs results to an evaluation logger. Part of a comprehensive retrieval evaluation framework alongside other metrics like precision, recall, F1-score, and NDCG.",
        "size": 1691,
        "parent-class": "EvaluationService",
        "function_name": "bpref"
    },
    {
        "id": "46646e0f-da37-442c-a7cd-3bd2c0d978e0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 156,
        "end_line": 201,
        "content": "def precision_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Precision@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Precision@k' to precision scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            precision_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision_results[f\"Precision@{k}\"] = (\n                    round(matches / float(k), 2) if k > 0 else 0.0\n                )\n            loggers['evaluation'].info(f\"Precision Result: {precision_results}\")\n            return precision_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in precision_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method for calculating precision@k in the EvaluationService class, used in information retrieval evaluation. Measures the proportion of relevant documents among retrieved documents at different cutoff points. Handles input validation, computes precision for all k values up to max_k, and returns a dictionary of precision scores. Part of a comprehensive evaluation toolkit including other metrics like recall, F1, NDCG, and MRR for assessing search quality.",
        "size": 2269,
        "parent-class": "EvaluationService",
        "function_name": "precision_at_k"
    },
    {
        "id": "70e6fdca-84d0-49e5-a202-a664e4f3d2f0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 204,
        "end_line": 251,
        "content": "def recall_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Recall@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Recall@k' to recall scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            recall_results = {}\n\n            if len(ground_truth) == 0:\n                return {f\"Recall@{k}\": 0.0 for k in range(1, max_k + 1)}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                matches = len(ground_truth_ids.intersection(retrieved_at_k))\n                recall_results[f\"Recall@{k}\"] = round(\n                    matches / float(len(ground_truth)), 2\n                )\n            loggers['evaluation'].info(f\"Recall Results: {recall_results}\")\n            return recall_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in recall_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method within the EvaluationService class that calculates recall metrics for information retrieval evaluation. Calculates recall at different k values (1 to max_k) by determining the proportion of relevant documents retrieved from the total relevant documents. The method handles validation, processes document IDs, calculates recall scores for each k threshold, and returns a dictionary with results. Part of a comprehensive evaluation framework alongside other metrics like precision, F1-score, and NDCG for assessing retrieval performance.",
        "size": 2436,
        "parent-class": "EvaluationService",
        "function_name": "recall_at_k"
    },
    {
        "id": "c4c2dbef-8b28-475b-8e93-775d4974d152",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 254,
        "end_line": 314,
        "content": "def f1_score_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes F1-Score@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'F1-Score@k' to F1 scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            f1_score_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n\n                # Calculate precision\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision = matches / float(k) if k > 0 else 0.0\n\n                # Calculate recall\n                recall = (\n                    matches / float(len(ground_truth))\n                    if ground_truth\n                    else 0.0\n                )\n\n                # Calculate F1 score\n                f1 = 0.0\n                if precision + recall > 0:\n                    f1 = 2 * (precision * recall) / (precision + recall)\n\n                f1_score_results[f\"F1-Score@{k}\"] = round(f1, 2)\n\n            loggers['evaluation'].info(f\"F1-Score Results: {f1_score_results}\")\n            return f1_score_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in f1_score_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in EvaluationService class calculating F1-Score@K metrics for information retrieval evaluation. Combines precision and recall into a harmonic mean for each k value from 1 to max_k. Handles input validation, edge cases, and logs results. Part of a comprehensive evaluation framework alongside precision, recall, NDCG, reciprocal rank, and other retrieval metrics.",
        "size": 2577,
        "parent-class": "EvaluationService",
        "function_name": "f1_score_at_k"
    },
    {
        "id": "67e2b423-ce10-4b85-b9c2-59547edd4edb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 317,
        "end_line": 365,
        "content": "def hit_rate_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Hit Rate@K for all k values from 1 to max_k.\n        (Binary outcome: 1 if at least one relevant document is in top-K, 0 otherwise)\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Hit_Rate@k' to binary hit values for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            hit_rate_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                hit = (\n                    1.0\n                    if len(ground_truth_ids.intersection(retrieved_at_k)) > 0\n                    else 0.0\n                )\n                hit_rate_results[f\"Hit_Rate@{k}\"] = hit\n\n            loggers[\"evaluation\"].info(f\"Hit Rate Results: {hit_rate_results}\")\n            return hit_rate_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in hit_rate_at_k: {e}\")\n            return {}\n\nStatic method in EvaluationService class calculating hit rate metrics for information retrieval evaluation. Assesses whether at least one relevant document appears in top-k results for each k value. Takes retrieved documents and ground truth lists, validates inputs, calculates binary hit values (1 if any relevant document exists in top-k results, 0 otherwise), and returns results dictionary with hit rates for different k values. Includes input validation, error handling, and logging functionality.",
        "size": 2374,
        "parent-class": "EvaluationService",
        "function_name": "hit_rate_at_k"
    },
    {
        "id": "781d015d-163d-4e9d-9737-55f175b7bc4b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 368,
        "end_line": 401,
        "content": "def reciprocal_rank(\n        retrieved_docs: List[Dict], ground_truth: List[str]\n    ) -> float:\n        \"\"\"\n        Computes Mean Reciprocal Rank (MRR).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n\n        Returns:\n            MRR score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            reciprocal_rank = 0.0\n            ground_truth_set = set(ground_truth)\n\n            for rank, doc in enumerate(retrieved_docs, start=1):\n                if doc[\"id\"] in ground_truth_set:\n                    reciprocal_rank = 1.0 / rank\n                    break\n\n            return reciprocal_rank\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_reciprocal_rank: {e}\")\n            return 0.0\n\nStatic method in EvaluationService class that calculates Reciprocal Rank (RR), returning the inverse of the position of the first relevant document in search results. The method validates input types, converts ground truth to a set for efficient lookup, iterates through retrieved documents until finding the first match, and returns 1/rank for that position. Part of a comprehensive information retrieval evaluation framework including metrics like precision, recall, F1-score, NDCG, and MAP.",
        "size": 1587,
        "parent-class": "EvaluationService",
        "function_name": "reciprocal_rank"
    },
    {
        "id": "bf697a24-b26a-45a5-b006-08b3a8049a7c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 404,
        "end_line": 452,
        "content": "def mean_average_precision(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> float:\n        \"\"\"\n        Computes Mean Average Precision (MAP).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            MAP score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_set = set(ground_truth)\n            average_precision = 0.0\n            relevant_count = 0\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_docs[:k]\n                matches = sum(\n                    1 for doc in retrieved_at_k if doc[\"id\"] in ground_truth_set\n                )\n                precision_at_k = matches / float(k) if k > 0 else 0.0\n\n                if retrieved_at_k[-1][\"id\"] in ground_truth_set:\n                    average_precision += precision_at_k\n                    relevant_count += 1\n\n            return average_precision / relevant_count if relevant_count > 0 else 0.0\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_average_precision: {e}\")\n            return 0.0\n\nStatic method in EvaluationService class that calculates Mean Average Precision (MAP), a common information retrieval evaluation metric. Measures the quality of search results by averaging precision values at positions where relevant documents are found. Handles input validation, processes retrieved documents against ground truth, and calculates precision at each relevant position. Part of a comprehensive evaluation framework that includes other metrics like NDCG, precision/recall, F1-score, and reciprocal rank. Includes error handling and logging functionality.",
        "size": 2353,
        "parent-class": "EvaluationService",
        "function_name": "mean_average_precision"
    },
    {
        "id": "2a2595bf-4ee5-4760-9a54-fa30de50573f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nfrom fastapi import HTTPException\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\n\nImport statements for the RerankerService class, including HTTP client (httpx), JSON handling, FastAPI exception handling, application settings, and logging utilities needed for the reranking functionality that interfaces with external APIs like Pinecone, Cohere, Jina, and VoyageAI.",
        "size": 427,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "4e0bf1f4-ea54-43a8-a54d-36ff8d4a57e3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 11,
        "end_line": 27,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.voyage_api_key=settings.VOYAGEAI_API_KEY\n        self.pinecone_rerank_url = settings.PINECONE_RERANK_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.voyage_base_url=settings.VOYAGEAI_BASE_URL\n        self.RERANK_SUFFIX = \"rerank\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nRerankerService initialization method that configures API keys, base URLs, and connection parameters for multiple reranking services including Pinecone, Cohere, Jina, and VoyageAI. Sets up HTTP timeout settings for asynchronous API requests used in document reranking operations.",
        "size": 1191,
        "parent-class": "RerankerService",
        "function_name": "__init__"
    },
    {
        "id": "86c08224-7136-4204-9352-1b6702df14b1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 29,
        "end_line": 70,
        "content": "async def pinecone_reranker(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n            \"Api-Key\": self.pinecone_api_key,\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"return_documents\": True,\n            \"top_n\": top_n,\n            \"documents\": documents,\n            \"parameters\": {\n                \"truncate\": \"END\",\n            },\n        }\n\n        url = self.pinecone_rerank_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done\")\n                loggers[\"pinecone\"].info(f\"Reranking model hosted by Pinecone tokens usage : {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            parsed_response = json.loads(response.content.decode(\"utf-8\"))\n            error_message = parsed_response.get(\"error\", {}).get(\n                \"message\", \"Unknown error occurred\"\n            )\n            loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n            raise HTTPException(status_code=400, detail=error_message)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in RerankerService class that performs reranking of search results using Pinecone's API. Takes a model name, query string, list of documents, and top_n parameter to determine how many results to return. Constructs appropriate headers and payload for the Pinecone reranking endpoint, sends the request, logs token usage, and handles HTTP errors with appropriate exception handling. Part of a larger service that supports multiple reranking providers including Cohere, Jina, and Voyage.",
        "size": 2149,
        "parent-class": "RerankerService",
        "function_name": "pinecone_reranker"
    },
    {
        "id": "6ecc4967-0f9f-4eb8-8d71-a0375b1ed2b3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 72,
        "end_line": 114,
        "content": "async def cohere_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        rerank_url = f\"{self.cohere_base_url}/{self.RERANK_SUFFIX}\"\n\n        headers = {\n            \"content-type\": \"application/json\",\n            \"accept\": \"application/json\",\n            \"Authorization\": f\"bearer {self.cohere_api_key}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url,\n                    headers=headers,\n                    json=payload,\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by cohere\")\n                loggers[\"cohere\"].info(f\"Reranking model hosted by Cohere tokens usage : {response.json().get('meta',{}).get('billed_units', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in cohere {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in RerankerService class that handles document reranking using Cohere's API. Takes a model name, query, list of documents, and number of results to return. Constructs the API request with proper authentication headers, sends the request to Cohere's rerank endpoint, logs token usage, and handles various error conditions with appropriate HTTP exceptions. Part of a service that offers multiple reranking providers including Pinecone, Cohere, Jina, and Voyage.",
        "size": 2256,
        "parent-class": "RerankerService",
        "function_name": "cohere_rerank"
    },
    {
        "id": "0032bd19-50a9-4677-a627-3a264ed2ec76",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 116,
        "end_line": 155,
        "content": "async def jina_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.jina_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by jina\")\n                loggers[\"jina\"].info(f\"Reranking model hosted by Jina tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in jina {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in RerankerService class that implements reranking functionality using Jina API. Takes query string, document list, model name, and top_n parameter to reorder search results based on relevance. Makes HTTP POST request to Jina's rerank endpoint with appropriate authentication headers, handles API responses and errors, logs token usage metrics, and implements comprehensive error handling for HTTP, connection, and general exceptions.",
        "size": 2154,
        "parent-class": "RerankerService",
        "function_name": "jina_rerank"
    },
    {
        "id": "25eb8609-a977-4af1-96ca-f51fa7379641",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 158,
        "end_line": 196,
        "content": "async def voyage_rerank(\n            self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        headers = {\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.voyage_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_k\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.voyage_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by voyage\")\n                loggers[\"voyage\"].info(f\"Reranking model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail = f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in Voyage {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in RerankerService class that interfaces with VoyageAI's reranking API. Sends a query and document list for relevance reranking, configures request headers and payload, handles HTTP communication with timeout settings, logs token usage metrics, and implements comprehensive error handling with specific HTTP exceptions for different failure scenarios.",
        "size": 2106,
        "parent-class": "RerankerService",
        "function_name": "voyage_rerank"
    }
]