[
    {
        "id": "925ffc9b-d8ab-4e58-934e-0eca3a23ac7c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nimport asyncio\nimport streamlit as st\nfrom typing import Dict, Tuple, List, Optional\nImport statements at the beginning of a Streamlit application using Python libraries for JSON handling, HTTP requests, asynchronous operations, and Streamlit UI.\n",
        "size": 272,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "fd4893e4-3381-47fa-b9aa-56218183c234",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 11,
        "end_line": 47,
        "content": "def initialize():\n        \"\"\"Initialize all session state variables\"\"\"\n        if \"pipeline_states\" not in st.session_state:\n            st.session_state.pipeline_states = {\n                \"1\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                },\n                \"2\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                }\n            }\n        \n        if \"file_uploaded\" not in st.session_state:\n            st.session_state.file_uploaded = False\n        \n        if \"file_name\" not in st.session_state:\n            st.session_state.file_name = \"\"\nThis code snippet is part of the `SessionState` class, which initializes Streamlit session state variables to manage the state of two pipelines (\"1\" and \"2\") involved in a search and reranking process.  It sets initial values for flags indicating whether search and reranking have been performed, stores results, and tracks file upload status.\n",
        "size": 1854,
        "parent-class": "SessionState",
        "function_name": "initialize"
    },
    {
        "id": "37709078-b318-4002-ad4d-cc87f19d6de6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 50,
        "end_line": 53,
        "content": "def reset_search_result(pipeline_id: str):\n        \"\"\"Reset search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = {}\nThis function, part of the `SessionState` class, resets the search results and `search_performed` flag for a given pipeline ID in Streamlit's session state.\n",
        "size": 418,
        "parent-class": "SessionState",
        "function_name": "reset_search_result"
    },
    {
        "id": "9786a2e7-d106-4010-9fc6-568c87caedfe",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 56,
        "end_line": 59,
        "content": "def reset_reranking_result(pipeline_id: str):\n        \"\"\"Reset reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = {}\nThis code snippet is part of the `SessionState` class, which manages the application's session state.  Specifically, it defines a method to reset reranking results for a given pipeline ID.\n",
        "size": 462,
        "parent-class": "SessionState",
        "function_name": "reset_reranking_result"
    },
    {
        "id": "4e374948-bbb1-4eb3-b344-6d16d86fff09",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 62,
        "end_line": 65,
        "content": "def set_search_performed(pipeline_id: str, top_k: int):\n        \"\"\"Mark search as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = True\n        st.session_state.pipeline_states[pipeline_id][\"top_k\"] = top_k\nThis function, part of the `SessionState` class, updates the session state to indicate that a search has been performed for a given pipeline and stores the `top_k` value.\n",
        "size": 442,
        "parent-class": "SessionState",
        "function_name": "set_search_performed"
    },
    {
        "id": "3ecc4cef-7baa-47e3-b6b6-db8be135aeed",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 68,
        "end_line": 70,
        "content": "def set_reranking_performed(pipeline_id: str):\n        \"\"\"Mark reranking as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = True\nThis function is part of the `SessionState` class, which manages the application's session state, specifically updating the status of reranking for a given pipeline.\n",
        "size": 363,
        "parent-class": "SessionState",
        "function_name": "set_reranking_performed"
    },
    {
        "id": "26828536-d709-40ad-8d9f-5a84045eefa1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 73,
        "end_line": 75,
        "content": "def set_index_created(pipeline_id: str):\n        \"\"\"Mark index as created for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"index_created\"] = True\nThis function is part of the `SessionState` class, which manages the application's session state, specifically updating the `index_created` flag for a given pipeline ID after index creation.\n",
        "size": 370,
        "parent-class": "SessionState",
        "function_name": "set_index_created"
    },
    {
        "id": "e1f1db9b-46a2-414f-85d3-391766f7c8df",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 78,
        "end_line": 80,
        "content": "def store_search_results(pipeline_id: str, results: Dict):\n        \"\"\"Store search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = results\nThis code snippet is part of the `SessionState` class, which manages the application's session state.  Specifically, this method stores search results in the session state for a given pipeline ID.\n",
        "size": 397,
        "parent-class": "SessionState",
        "function_name": "store_search_results"
    },
    {
        "id": "a90a0c12-dac9-4342-a945-d87c7db0b236",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 83,
        "end_line": 85,
        "content": "def store_reranking_results(pipeline_id: str, results: Dict):\n        \"\"\"Store reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = results\nThis code snippet is part of the `SessionState` class, which manages the application's session state, specifically storing reranking results for individual pipelines within a Streamlit application.\n",
        "size": 407,
        "parent-class": "SessionState",
        "function_name": "store_reranking_results"
    },
    {
        "id": "653edc7e-1d1d-496d-9c62-205f69f6ac38",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 88,
        "end_line": 89,
        "content": "def store_random_question(pipeline_id: str, generated_question: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_question\"] = generated_question\nThis function, part of the `SessionState` class, stores a randomly generated question in the Streamlit session state for a given pipeline ID.\n",
        "size": 307,
        "parent-class": "SessionState",
        "function_name": "store_random_question"
    },
    {
        "id": "7c6eb549-c212-475b-8707-949001c4b396",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 92,
        "end_line": 94,
        "content": "def store_random_question_answer(pipeline_id: str, query: str, results: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_query\"] = query\n        st.session_state.pipeline_states[pipeline_id][\"random_question_results\"] = results\nThis code snippet is part of the `SessionState` class, which manages the Streamlit application's session state.  Specifically, this method stores the user's query and the results of a random question answering task within the session state for a given pipeline ID.\n",
        "size": 513,
        "parent-class": "SessionState",
        "function_name": "store_random_question_answer"
    },
    {
        "id": "a91a12af-054f-4da2-b07c-e23b052350d8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 100,
        "end_line": 116,
        "content": "def get_embedding_models() -> List[str]:\n        \"\"\"Get list of available embedding models\"\"\"\n        return [\n            \"\",\n            \"llama-text-embed-v2\",\n            \"multilingual-e5-large\",\n            \"embed-english-v3.0\",\n            \"embed-multilingual-v3.0\",\n            \"embed-english-light-v3.0\",\n            \"embed-multilingual-light-v3.0\",\n            \"embed-english-v2.0\",\n            \"embed-english-light-v2.0\",\n            \"embed-multilingual-v2.0\",\n            \"jina-embeddings-v3\",\n            \"jina-clip-v2\",\n            \"voyage-3-large\"\n        ]\nThis code snippet defines a function `get_embedding_models` within the `ModelRegistry` class, which returns a list of available embedding models for use in a vector database.\n",
        "size": 746,
        "parent-class": "ModelRegistry",
        "function_name": "get_embedding_models"
    },
    {
        "id": "8a955d51-3939-4d42-bb9b-205472bd26e6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 119,
        "end_line": 124,
        "content": "def get_code_embedding_models() -> List[str]:\n        return [\n            \"\",\n            \"jina-embeddings-v2-base-code\",\n            \"voyage-code-3\",\n        ]\nThis code snippet defines a function within the `ModelRegistry` class that returns a list of available code embedding models.\n",
        "size": 288,
        "parent-class": "ModelRegistry",
        "function_name": "get_code_embedding_models"
    },
    {
        "id": "b0cc0d34-73de-4df4-823e-611e7469b12c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 126,
        "end_line": 139,
        "content": "def get_reranking_models() -> List[str]:\n        \"\"\"Get list of available reranking models\"\"\"\n        return [\n            \"\",\n            \"pinecone-rerank-v0\",\n            \"bge-reranker-v2-m3\",\n            \"rerank-v3.5\",\n            \"rerank-english-v3.0\",\n            \"rerank-multilingual-v3.0\",\n            \"jina-reranker-v2-base-multilingual\",\n            \"rereank-lite-1\",\n            \"rerank-2\",\n            \"rerank-1\"\n        ]\nDefinition of `get_reranking_models` function within the `ModelRegistry` class, listing available reranking models.\n",
        "size": 550,
        "parent-class": "ModelRegistry",
        "function_name": "get_reranking_models"
    },
    {
        "id": "70c001fb-32e5-4276-b7f2-ce7edb002f38",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 142,
        "end_line": 158,
        "content": "def get_dimensions(dense_embedding_model: str) -> List[int]:\n        \"\"\"Get available dimensions for a specific embedding model\"\"\"\n        model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        return model_to_dimensions.get(dense_embedding_model, [])\nThis code snippet is part of the `ModelRegistry` class, defining a method `get_dimensions` that retrieves available dimensions for different dense embedding models.  It uses a dictionary mapping model names to lists of their supported dimensions.\n",
        "size": 1104,
        "parent-class": "ModelRegistry",
        "function_name": "get_dimensions"
    },
    {
        "id": "faa243a5-4af4-4816-8f74-44f71cfcae12",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 164,
        "end_line": 180,
        "content": "def display_results_tabs(pipeline_id: str):\n        \"\"\"Display results in tabbed interface\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        tab1, tab2 = st.tabs([\"Search Results\", \"Reranking Results\"])\n        \n        with tab1:\n            if pipeline_state[\"search_performed\"]:\n                UIComponents.display_search_results(pipeline_state[\"search_results\"], pipeline_id)\n            else:\n                st.info(\"Run a search to see results here.\")\n        \n        with tab2:\n            if pipeline_state[\"reranking_performed\"]:\n                UIComponents.display_reranking_results(pipeline_state[\"reranking_results\"], pipeline_id)\n            else:\n                st.info(\"Run reranking to see results here.\")\nThis code snippet is part of the `UIComponents` class, defining a method to display search and reranking results in Streamlit using tabs.  It accesses and displays data stored in the application's session state.\n",
        "size": 980,
        "parent-class": "UIComponents",
        "function_name": "display_results_tabs"
    },
    {
        "id": "f6754c48-ce18-4450-9a94-04dbaaaafa3f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 183,
        "end_line": 196,
        "content": "def display_search_results(results: Dict, pipeline_id: str):\n        \"\"\"Display search results\"\"\"\n        if not results:\n            st.info(\"No search results available.\")\n            return\n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Search metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_search_{pipeline_id}\"\n        )\n        st.json(results, expanded = False)\nThis code snippet is part of the `UIComponents` class, defining a method to display and download search results within a Streamlit application.  It's used to present search evaluation metrics from a RAG pipeline.\n",
        "size": 779,
        "parent-class": "UIComponents",
        "function_name": "display_search_results"
    },
    {
        "id": "6e2d37c1-853b-47bc-be9b-d09511ac2bc1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 200,
        "end_line": 215,
        "content": "def display_reranking_results(results: Dict, pipeline_id: str):\n        \"\"\"Display reranking results\"\"\"\n        if not results:\n            st.info(\"No reranking results available.\")\n            return\n        \n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Rerank metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_reranking_{pipeline_id}\"\n        )\n        \n        st.json(results, expanded = False)\nThis code snippet is part of the `UIComponents` class, which defines helper functions for displaying UI elements in a Streamlit application.  Specifically, this function displays reranking results from a search pipeline, providing a download button for the results and a JSON representation.\n",
        "size": 888,
        "parent-class": "UIComponents",
        "function_name": "display_reranking_results"
    },
    {
        "id": "739ae130-5a03-4a2f-b412-23a3549dc785",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 218,
        "end_line": 245,
        "content": "def display_random_question(pipeline_id: str):\n\n        if st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"]:\n            results = st.session_state.pipeline_states[pipeline_id][\"random_question\"]\n            question = results[\"question\"]\n\n            if len(results) > 0:\n                st.markdown(f\"### Random Question: \\n> {question}\")\n\n                for i, res in enumerate(results[\"chunks\"]):\n\n                    col1, col2 = st.columns([1, 1])\n                    with col1:\n                        st.markdown(f\"**Ground Truth Chunk {i+1}**\")\n                    with col2:\n                        st.markdown(f\"**ID:** {res['_id']}\")\n                # Create expander for each chunk\n                    with st.expander(\"Ground Truth\", expanded=False):\n                        \n                        # Display the text with wrapping\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"gt_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\nThis code snippet is a function within the `UIComponents` class, responsible for displaying a randomly generated question and its associated ground truth chunks from the session state in a Streamlit application.  It's part of a larger application for comparing RAG pipelines.\n",
        "size": 1520,
        "parent-class": "UIComponents",
        "function_name": "display_random_question"
    },
    {
        "id": "b5590a26-86cf-4074-9f65-2b0992931c2e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 248,
        "end_line": 276,
        "content": "def display_random_question_answer(pipeline_id: str):\n        \n        if st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"]:\n            response = st.session_state.pipeline_states[pipeline_id][\"random_question_results\"]\n            query = st.session_state.pipeline_states[pipeline_id][\"random_query\"]\n            \n            # Container for the results to improve layout\n            if len(response) > 0:\n                st.markdown(\"### Search Results\")\n                st.markdown(f\"**Query:** \\n> {query}\")\n\n                for i, res in enumerate(response):\n                    # Create expander for each chunk\n                    score_indicator = \"\ud83d\udfe9\" if res['score'] > 0.8 else \"\ud83d\udfe7\" if res['score'] > 0.5 else \"\ud83d\udfe5\"\n                    col1, col2 = st.columns([4, 1])\n                    with col1:\n                        st.markdown(f\"**Relevant chunk {i+1}** || **ID:** {res['id']}\")\n                    with col2:\n                        st.markdown(f\"{score_indicator} **Score:** {res['score']:.4f}\")\n\n                    with st.expander(\"**Chunk**\",expanded=False):\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"chunk_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\n        \nThis function `display_random_question_answer` is part of the `UIComponents` class, which handles the display of results in a Streamlit application.  It specifically displays the results of a random question answered by querying a vector database.\n",
        "size": 1741,
        "parent-class": "UIComponents",
        "function_name": "display_random_question_answer"
    },
    {
        "id": "0e0855b7-2838-4140-aa15-07d39b4a013b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 287,
        "end_line": 297,
        "content": " fetch_user_previous_configurations():\n        \"\"\"Fetch user's previous configurations\"\"\"\n        async with httpx.AsyncClient() as client:\n            try:\n                response = await client.get(\n                    f\"{APIClient.BASE_URL}/get-configurations\",\n                    timeout=APIClient.TIMEOUT,\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n    \n   \nThis code snippet defines a static method `fetch_user_previous_configurations` within the `APIClient` class, which uses `httpx` to make a GET request to retrieve user's previously saved configurations from a backend service.\n",
        "size": 771,
        "parent-class": ":\n    \"\"\"",
        "function_name": "r_previous_configurations():\n     "
    },
    {
        "id": "9f7aa7c6-045b-4a73-a927-b7b72cb1c88d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 300,
        "end_line": 315,
        "content": " upload_file(data):\n        \"\"\"Upload a file to the backend service\"\"\"\n        \n        files = {\"file\": data['uploaded_file']}\n        form_data = {\"file_type\" : data[\"file_type\"]}\n\n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/upload-files\",\n                    files=files,\n                    data=form_data\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n        \nThis code snippet defines the `upload_file` static method within the `APIClient` class, responsible for uploading files to a backend service using the `httpx` library.\n",
        "size": 850,
        "parent-class": ":\n    \"\"\"",
        "function_name": "le(data):\n "
    },
    {
        "id": "61f9a33a-3d99-4033-98dc-7603741ddd1c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 318,
        "end_line": 335,
        "content": " create_index(file_name: str, embed_model: str, similarity_metric: str, dimension: int) -> Tuple[bool, str]:\n        \"\"\"Create an index and upsert dataset\"\"\"\n        payload = {\n            \"file_name\": file_name,\n            \"embed_model\": embed_model,\n            \"similarity_metric\": similarity_metric,\n            \"dimension\": dimension,\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/index-upsert\",\n                    json=payload,\n                )\n                return response.status_code == 200, response.json()[\"error\"] if response.status_code != 200 else \"\"\n            except Exception as e:\n                return False, str(e)\n        \nThis code snippet is part of the `APIClient` class, defining a static method `create_index` that sends a POST request to a backend service to create a vector index and upsert data.  It handles potential errors during the API call.\n",
        "size": 1039,
        "parent-class": ":\n    \"\"\"",
        "function_name": "dex(file_nam"
    },
    {
        "id": "f5435af3-fa28-446c-a734-955f656d0822",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 338,
        "end_line": 366,
        "content": " perform_search(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform a search query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/query\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_result\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \nThis code snippet defines the `perform_search` method within the `APIClient` class, which handles making API calls to a backend service to execute a search query and return evaluation results.  It uses `httpx` for asynchronous HTTP requests.\n",
        "size": 1478,
        "parent-class": ":\n    \"\"\"",
        "function_name": "earch(is_hybri"
    },
    {
        "id": "59baff42-d1a4-4b14-aa70-404acb6e1618",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 369,
        "end_line": 390,
        "content": " perform_reranking(model_name: str, top_n: int, top_k: int) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform reranking\"\"\"\n        payload = {\n            \"model_name\": model_name,\n            \"top_n\": top_n,\n            \"top_k\": top_k\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/rerank\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_metrics\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \nThis code snippet defines the `perform_reranking` method within the `APIClient` class, which handles making API calls to a backend service for reranking search results using a specified model and parameters.\n",
        "size": 1076,
        "parent-class": ":\n    \"\"\"",
        "function_name": "eranking(model_na"
    },
    {
        "id": "cf0cf7fb-8c35-4d76-a24a-5ade595f32ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 393,
        "end_line": 411,
        "content": " random_question(file_name: str) -> Tuple[bool, Dict, str]:\n        \"\"\"Generate a random question\"\"\"\n        payload = {\n            \"file_name\": file_name\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-question\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \nThis code snippet defines the `random_question` method within the `APIClient` class, which is responsible for making API calls to a backend service to generate a random question based on a given file.  It's part of a larger Streamlit application for comparing RAG pipelines.\n",
        "size": 1017,
        "parent-class": ":\n    \"\"\"",
        "function_name": "estion(file_nam"
    },
    {
        "id": "df512a4b-78af-400d-b05c-3039cb5a7742",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 414,
        "end_line": 442,
        "content": " random_query(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, query: str, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None):\n        \"\"\"Perform a random query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n            \"query\": query,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-query\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \nThis code snippet defines the `random_query` method within the `APIClient` class, responsible for sending a user-specified query to a backend service for retrieval and returning the results.  It's part of a larger Streamlit application for comparing different RAG pipelines.\n",
        "size": 1472,
        "parent-class": ":\n    \"\"\"",
        "function_name": "ery(is_hybri"
    },
    {
        "id": "a3477392-f486-479b-826c-0f22d6f63b6d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 448,
        "end_line": 500,
        "content": " index_creation_section(pipeline_id: str, is_hybrid: bool) -> bool:\n        \"\"\"Handle index creation section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = \"\"\n        if st.session_state.get(f'file_type', None) == \"Code\":\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_code_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        else:\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        \n        dimensions = ModelRegistry.get_dimensions(dense_embedding_model)\n        dense_dimension = st.selectbox(\n            \"Enter Dimension of the Dense Model:\",\n            dimensions,\n            key=f\"dense_dimension_{pipeline_id}\",\n        )\n        \n        if not dense_embedding_model or not dense_dimension:\n            st.warning(\"Please select the required models and dimensions.\")\n            return False\n        \n        similarity_metric = \"dotproduct\"\n        if not is_hybrid:\n            similarity_metric = st.selectbox(\n                \"Enter Similarity Metric:\",\n                [\"dotproduct\", \"cosine\", \"euclidean\"],\n                key=f\"similarity_metric_{pipeline_id}\",\n            )\n        else:\n            st.warning(\"By default, dot product similarity is used for the hybrid search.\")\n        \n        if st.button(\"Create Index and Upsert Dataset\", key=f\"create_index_{pipeline_id}\"):\n            with st.spinner(\"Creating index and upserting dataset...\"):\n                success, error_msg = await APIClient.create_index(\n                    file_name, dense_embedding_model, similarity_metric, dense_dimension\n                )\n                \n                if success:\n                    st.success(\"Index created and dataset upserted successfully!\")\n                    SessionState.set_index_created(pipeline_id)\n                else:\n                    st.error(f\"Index creation and dataset upsert failed: {error_msg}\")\n        \n        return pipeline_state[\"index_created\"]\n    \n   \nThis chunk is a method within the `PipelineManager` class that handles the UI for index creation, allowing users to select embedding models, dimensions, and similarity metrics before creating and upserting a dataset.\n",
        "size": 2575,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ation_section(pipeline"
    },
    {
        "id": "a0a7f9da-91d7-4649-aaad-2994afd6ff74",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 503,
        "end_line": 554,
        "content": " search_section(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Handle search section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.number_input(\"Enter the value for top_k:\", min_value=1, value=\"min\", step=1, key=f\"top_k_{pipeline_id}\")\n        \n        alpha = None\n        if is_hybrid:\n            alpha = st.slider(\n                \"Select alpha value (between 0 and 1):\",\n                min_value=0.0,\n                max_value=1.0,\n                step=0.1,\n                value=0.5,\n                key=f\"alpha_{pipeline_id}\",\n            )\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get First Stage Evaluation Metrics\",\n                key=f\"perform_search_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing search...\"):\n                    success, results, error_msg = await APIClient.perform_search(\n                        is_hybrid=is_hybrid,\n                        file_name=file_name,\n                        embedding_model=dense_embedding_model,\n                        dimension=dense_dimension,\n                        top_k=top_k,\n                        similarity_metric=similarity_metric,\n                        alpha=alpha,\n                    )\n                    \n                    if success:\n                        st.success(\"Search performed successfully!\")\n                        SessionState.store_search_results(pipeline_id, results)\n                        SessionState.set_search_performed(pipeline_id, top_k)\n                    else:\n                        st.error(f\"First stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_similarity_{pipeline_id}\",\n            ):\n                SessionState.reset_search_result(pipeline_id)\n    \n   \nThis chunk defines the `search_section` method within the `PipelineManager` class.  This method handles the user interface for performing a search, including input parameters, API calls, and result display within a Streamlit application.\n",
        "size": 2518,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ction(pipeline"
    },
    {
        "id": "bfb2a710-ebd8-4306-9f97-a76e445fe5f3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 557,
        "end_line": 605,
        "content": " reranking_section(pipeline_id: str):\n        \"\"\"Handle reranking section of the UI\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        if not pipeline_state[\"search_performed\"] or not pipeline_state[\"search_results\"]:\n            return\n        \n        reranking_model = st.selectbox(\n            \"Select Reranking Model:\",\n            ModelRegistry.get_reranking_models(),\n            key=f\"reranking_model_{pipeline_id}\",\n        )\n        \n        top_n = st.number_input(\"Enter the value for top_n:\", min_value=1, value=\"min\", step=1, key=f\"top_n_{pipeline_id}\")\n        \n        if pipeline_state[\"top_k\"] < top_n:\n            st.warning(\"The value of top_n should be less than or equal to the value of top_k.\")\n            return\n        \n        if not reranking_model or not top_n:\n            st.warning(\"Please select the reranking model and enter the top_n value.\")\n            return\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get Reranking Evaluation Metrics\",\n                key=f\"perform_reranking_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing reranking...\"):\n                    success, results, error_msg = await APIClient.perform_reranking(\n                        model_name=reranking_model,\n                        top_n=top_n,\n                        top_k=pipeline_state[\"top_k\"],\n                    )\n                    \n                    if success:\n                        st.success(\"Reranking performed successfully!\")\n                        SessionState.store_reranking_results(pipeline_id, results)\n                        SessionState.set_reranking_performed(pipeline_id)\n                    else:\n                        st.error(f\"Second stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_reranked_{pipeline_id}\",\n            ):\n                SessionState.reset_reranking_result(pipeline_id)\n        \nThis code chunk defines the `reranking_section` method within the `PipelineManager` class.  This method handles the user interface for reranking search results in a Streamlit application, allowing users to select a reranking model, specify parameters, and trigger the reranking process.\n",
        "size": 2369,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "_section(pipeline"
    },
    {
        "id": "c1d4e548-7bda-4f73-bb0e-c7478887e21e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 608,
        "end_line": 627,
        "content": " random_question_section(pipeline_id: str):\n        if \"file_name\" in st.session_state:\n            file_name = st.session_state.file_name\n            \n            if st.button(\n                \"Get random question\",\n                key=f\"generate_random_question_{pipeline_id}\",\n            ):\n                with st.spinner(\"processing random question...\"):\n                    success, response, error_msg = await APIClient.random_question(file_name)\n                    \n                    if success:\n                        st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"] = True\n                        SessionState.store_random_question(pipeline_id = pipeline_id, generated_question = response)\n\n                    else:\n                        st.error(f\"Random question generation failed: {error_msg}\")\n\n        else:\n            st.warning(\"No file selected. Please upload a file first.\")\n        \nThis chunk defines a function `random_question_section` within the `PipelineManager` class, responsible for the UI element that generates a random question from uploaded data and displays it using Streamlit.\n",
        "size": 1146,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "estion_section(pipeline"
    },
    {
        "id": "00a53db3-598a-4ba0-ae0a-6fb4a90daed5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 630,
        "end_line": 670,
        "content": " random_query_section(pipeline_id: str):\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.session_state.get(f\"top_k_{pipeline_id}\", 0)\n        is_hybrid = st.session_state.get(f\"hybrid_search_{pipeline_id}\", \"No\") == \"Yes\"\n        alpha = st.session_state.get(f\"alpha_{pipeline_id}\", None)\n            \n        query = st.text_input(\"Enter the query for random search:\", key=f\"query_{pipeline_id}\")\n        \n        if not query:\n            st.warning(\"Please enter a query for random search.\")\n            return\n        \n        if st.button(\n            \"Search custom query\", \n            key=f\"search_custom_query_{pipeline_id}\"\n        ):\n            with st.spinner(\"Performing search...\"):\n                success, response, error_msg = await APIClient.random_query(\n                    is_hybrid=is_hybrid,\n                    file_name=file_name,\n                    embedding_model=dense_embedding_model,\n                    dimension=dense_dimension,\n                    top_k=top_k,\n                    query=query,\n                    similarity_metric=similarity_metric,\n                    alpha=alpha,\n                )\n                \n                if success:\n                    st.success(\"Search performed successfully!\")\n                    st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"] = True\n                    SessionState.store_random_question_answer(pipeline_id = pipeline_id, query=query, results = response)\n                        \n                else:\n                    st.error(f\"Error performing search: {error_msg}\")\n    \n   \nThis code chunk defines a Streamlit UI function `random_query_section` within a larger application for comparing RAG pipelines.  It handles user input for a custom query, performs a search using the `APIClient`, and updates the session state with the results.\n",
        "size": 2251,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ery_section(pipeline"
    },
    {
        "id": "b1692c14-0345-4371-8fdf-ea00f3440609",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 673,
        "end_line": 691,
        "content": " run_pipeline(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Run a complete RAG pipeline\"\"\"\n\n        index_ready = await PipelineManager.index_creation_section(pipeline_id, is_hybrid)\n        \n        if index_ready:\n            \n            await PipelineManager.search_section(pipeline_id, is_hybrid)\n            \n            await PipelineManager.reranking_section(pipeline_id)\n            \n            await PipelineManager.random_question_section(pipeline_id)\n            UIComponents.display_random_question(pipeline_id=pipeline_id)\n            \n            await PipelineManager.random_query_section(pipeline_id)\n            UIComponents.display_random_question_answer(pipeline_id=pipeline_id)\n        \n        st.subheader(\"Results\")\n        UIComponents.display_results_tabs(pipeline_id)\n        \nThis chunk defines the `run_pipeline` function within the `PipelineManager` class, which orchestrates the execution of a complete Retrieval Augmented Generation (RAG) pipeline in a Streamlit application.  It handles index creation, search, reranking, random question generation, and displays the results.\n",
        "size": 1111,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ine(pipeline"
    },
    {
        "id": "40d83880-e78c-4404-9358-91635d733d45",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 693,
        "end_line": 721,
        "content": " handle_file_upload():\n    \"\"\"Handle file upload\"\"\"\n    file_type = st.radio(\"Select File Type:\", [\"Text\", \"Code\"])\n    if \"file_type\" not in st.session_state:\n        st.session_state.file_type = file_type\n    st.session_state.file_type = file_type\n\n\n    uploaded_file = st.file_uploader(\"Upload a file:\", type=[\"json\"])\n    \n    if uploaded_file and not st.session_state.file_uploaded:\n        with st.spinner(\"Uploading file...\"):\n            data = {\"uploaded_file\": uploaded_file, \"file_type\": file_type}\n            success, response, error_msg = await APIClient.upload_file(data)\n\n            if success:\n                success_message = response.json()[\"detail\"]\n                st.success(f\"Success Message: {success_message}\")\n\n                st.session_state.file_uploaded = True\n                st.session_state.file_name = uploaded_file.name\n\n                st.write(\"Here is the schema of the uploaded file:\")\n                st.json(response.json()[\"data\"][\"file_schema\"])\n            else:\n                st.error(f\"Upload failed: {error_msg}\")\n\n    \n    return st.session_state.file_uploaded\n\nasync d\nThis chunk defines an asynchronous function `handle_file_upload()` responsible for handling file uploads in a Streamlit application, using `st.file_uploader` and making API calls via `APIClient.upload_file` to process the uploaded JSON file.  It updates session state to reflect upload success and file details.\n",
        "size": 1434,
        "parent-class": null,
        "function_name": "le_upload():\n    \""
    },
    {
        "id": "7ba3dbdb-5cbb-4fb0-98ad-4aaa9a7d706c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 723,
        "end_line": 788,
        "content": " main():\n    \"\"\"Main application entry point\"\"\"\n    \n    SessionState.initialize()\n    \n    st.set_page_config(\n        page_title=\"RAG Pipeline Comparison Tool | Pinecone\",\n        layout=\"wide\",\n        page_icon=\"\ud83e\uddca\",\n    )\n    \n    st.title(\"RetrieveWise\")\n    st.divider()\n    st.markdown(\n        \"\"\"\n        Compare and Evaluate different Information Retrieval Pipelines, Configure two retrieval pipelines side by side \n        with different settings, embedding models, rerankers. Once set compare key performance metrics like precision, recall\n        NDCG, MRR, F1 etc \n    \"\"\"\n    )\n    \n    success, response, error_msg = await APIClient.fetch_user_previous_configurations()\n    \n    if success:\n        data = response.json().get(\"data\", None)\n        if isinstance(data, dict) and \"message\" in data:\n            st.info(data[\"message\"])\n        else:\n            st.write(\"Here are your previous configurations:\")\n            st.json(response.json()[\"data\"], expanded = False)\n    else:\n        st.error(f\"Failed to fetch previous configurations: {error_msg}\")\n    \n    file_uploaded = await handle_file_upload()\n    \n    if not file_uploaded:\n        st.warning(\"Please upload the JSON files for the pipelines to compare.\")\n        return\n\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.header(\"Pipeline 1\")\n        hybrid_search_1 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_1\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"1\", \n            is_hybrid=(hybrid_search_1 == \"Yes\")\n        )\n        \n    with col2:\n        st.header(\"Pipeline 2\")\n        hybrid_search_2 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_2\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"2\", \n            is_hybrid=(hybrid_search_2 == \"Yes\")\n        )\n        \nif\nMain function of Streamlit application; initializes session state, configures page, handles file upload, and runs two parallel RAG pipelines.\n",
        "size": 2157,
        "parent-class": null,
        "function_name": "   \""
    },
    {
        "id": "2e087837-7e3f-420e-951e-316eaf297160",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom app.apis import file_upload, index_upsert_route, query, reranking_router, configuration_route, random_question_route, random_query_route\nfrom app.config.database import db_helper\nImport statements and FastAPI app initialization.\n",
        "size": 305,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "e01e35ef-328e-4754-ae9b-cd0064af4f07",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 10,
        "end_line": 14,
        "content": "async def lifespan(app: FastAPI):\n    await db_helper.connect()\n    db = await db_helper.get_db()\n    yield\n    await db_helper.disconnect()\nFastAPI application lifespan management using asynccontextmanager to handle database connection.\n",
        "size": 238,
        "parent-class": null,
        "function_name": "lifespan"
    },
    {
        "id": "d2dc1b73-d400-4f91-9cb3-12eb83bf91a7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 30,
        "end_line": 31,
        "content": "async def root():\n    return {\"message\": \"Welcome to the RAG Playground\"}\nFastAPI application's root endpoint definition.\n",
        "size": 122,
        "parent-class": null,
        "function_name": "root"
    },
    {
        "id": "8027f119-e3ea-4082-bd22-351595ff96a6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.query_controller import QueryController\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nImport statements for FastAPI-based query endpoint.\n",
        "size": 322,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "0e1d4ebc-d0de-48e2-a930-4803d843a7c9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 12,
        "end_line": 26,
        "content": "async def make_query(\n    request: QueryEndPointRequest, query_controller: QueryController = Depends()\n):\n\n    response_data = await query_controller.make_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Query execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\nFastAPI route handler for POST /query endpoint, handling query execution and returning JSON response.\n",
        "size": 517,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "59fd33d2-25ce-475b-9cde-78710baa7a95",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.models.schemas.random_query_schema import RandomQueryRequest\nfrom app.controllers.random_query_controller import RandomQueryController\nImport statements for FastAPI-based random query endpoint.\n",
        "size": 347,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c9522178-89ab-4f34-8215-5a545252e44a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 13,
        "end_line": 28,
        "content": "async def random_query(\n    request: RandomQueryRequest,\n    random_query_controller: RandomQueryController = Depends(),\n):\n\n    response = await random_query_controller.random_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Query Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\nFastAPI route handler for a POST request to `/random-query`, using dependency injection and returning a JSONResponse.\n",
        "size": 588,
        "parent-class": null,
        "function_name": "random_query"
    },
    {
        "id": "bf701b87-8442-495c-a9f3-6d50c438f3c1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.random_question_controller import RandomQuestionController\nImport statements for FastAPI, Pydantic, and custom modules used in the random question API endpoint.\n",
        "size": 357,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c3afc1ad-ad5b-406f-a20b-2f27f570653d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 16,
        "end_line": 31,
        "content": "async def random_question(\n    request: RQRequest,\n    random_question_controller: RandomQuestionController=Depends(),\n):\n\n    response = await random_question_controller.random_question(request.file_name)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Question Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\nFastAPI route handler for generating a random question using a provided filename, leveraging a controller and error handling.\n",
        "size": 613,
        "parent-class": null,
        "function_name": "random_question"
    },
    {
        "id": "5dbeb431-35e3-4135-af19-6ffc464a4f15",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Body, Depends,status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.reranking_controller import RerankingController\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest\n)\nImport statements for FastAPI-based reranking API endpoint.\n",
        "size": 351,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "26bbbf6f-f9f4-4253-8b50-1f503453e6a0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 15,
        "end_line": 31,
        "content": "async def rerank_documents(\n    request: RerankingRequest = Body(...),\n    controller: RerankingController = Depends(),\n):\n    \n    response_data = await controller.rerank_documents(request)\n    response = response_data.model_dump()\n\n    return JSONResponse(\n        content={\n            \"data\": response,\n            \"statuscode\": 200,\n            \"detail\": \"Rerank execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\nFastAPI endpoint `/rerank` POST method handler function using RerankingController to rerank documents and return JSON response.\n",
        "size": 602,
        "parent-class": null,
        "function_name": "rerank_documents"
    },
    {
        "id": "6c462e69-6064-436a-b230-7efa2386a03f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.index_upsert_controller import IndexUpsertController\nfrom app.models.schemas.index_upsert_schema import IndexUpsertRequest\nImport statements for FastAPI-based index upsert endpoint.\n",
        "size": 347,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "4a88fb61-79e1-446b-89e9-28b02ec6aca2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 13,
        "end_line": 30,
        "content": "async def index_upsert(\n    request: IndexUpsertRequest,\n    index_upsert_controller: IndexUpsertController = Depends(\n        IndexUpsertController\n    ),\n):\n    \n    response = await index_upsert_controller.index_upsert(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"host\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Upserted Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\nFastAPI route handler for `/index-upsert` endpoint using dependency injection.\n",
        "size": 570,
        "parent-class": null,
        "function_name": "index_upsert"
    },
    {
        "id": "f69f574c-a514-45c3-a9fa-e7c8deab1dc2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, UploadFile, File, status, Form\nfrom fastapi.responses import JSONResponse\nfrom app.controllers.file_upload_controller import FileUploadController\nfrom app.utils.error_handler import handle_exceptions\nimport logging\nImport statements and logger initialization at the beginning of a FastAPI router file.\n",
        "size": 342,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "05c5d7d2-ce48-4e9f-953e-4e1f98218c45",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 14,
        "end_line": 32,
        "content": "async def upload_files(\n    file_type: str = Form(),\n    file: UploadFile = File(...),\n    file_controller: FileUploadController = Depends(),\n):\n    response_data = await file_controller.upload_files({\n        \"input_data\": file,\n        \"file_name\": file.filename,\n        \"file_type\": file_type\n    })\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": response_data[\"data\"],\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\nFastAPI route handler for file uploads using a custom controller.\n",
        "size": 606,
        "parent-class": null,
        "function_name": "upload_files"
    },
    {
        "id": "e4c321be-c5c4-4b28-90ed-6fee29a5852e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from motor.motor_asyncio import AsyncIOMotorClient\nfrom app.config.settings import settings\nImport statements for MongoDB asynchronous client and application settings.\n",
        "size": 168,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5b0cca1e-8341-4a80-ac9e-8a62ab478a3a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 7,
        "end_line": 13,
        "content": "def __init__(self):\n        self.client = AsyncIOMotorClient(settings.MONGODB_URL)\n        self.db = self.client[settings.DATABASE_NAME]\n        self.raw_data = self.db[\"raw_data\"]\n        self.index_upsert_collection = self.db[\"index_upsert\"]\n        self.gt_data = self.db[\"gt_data\"]\n        self.query_embeddings_collection = self.db[\"query_embeddings\"]\nDBHelper class constructor; initializes MongoDB client and collections.\n",
        "size": 429,
        "parent-class": "DBHelper",
        "function_name": "__init__"
    },
    {
        "id": "af686488-9386-492b-b0e1-7127b55e6192",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 15,
        "end_line": 33,
        "content": "async def connect(self):\n        try:\n            if self.client is None:\n                self.client = AsyncIOMotorClient(\n                    settings.MONGODB_URL,\n                    maxPoolSize=1000,\n                    minPoolSize=50,\n                    maxIdleTimeMS=50000,\n                    connectTimeoutMS=20000,\n                )\n\n                self.db = self.client[settings.DATABASE_NAME]\n                await self.client.admin.command(\"ping\")\n                await self.create_collections()\n\n        except Exception as e:\n            if self.client:\n                await self.disconnect()\n            raise\nThis code snippet defines an asynchronous `connect` method within a MongoDB database helper class.  It establishes a connection to a MongoDB server, pings the server to verify connectivity, and creates necessary collections if they don't exist.  Error handling includes disconnecting if connection fails.\n",
        "size": 933,
        "parent-class": "DBHelper",
        "function_name": "connect"
    },
    {
        "id": "d21d95e7-e5c4-40a1-85c2-a45058e74338",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 35,
        "end_line": 40,
        "content": "async def create_collections(self):\n        required_collections = [\"raw_data\", \"gt_data\"]\n        existing_collections = await self.db.list_collection_names()\n        for collection in required_collections:\n            if collection not in existing_collections:\n                await self.db.create_collection(collection)\nThis function ensures the existence of necessary MongoDB collections (\"raw_data\" and \"gt_data\") within the database, creating them if they don't already exist.\n",
        "size": 483,
        "parent-class": "DBHelper",
        "function_name": "create_collections"
    },
    {
        "id": "2a89b9c9-c43d-4798-bd97-6f239d7ede73",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 42,
        "end_line": 45,
        "content": "async def get_db(self):\n        if self.client is None:\n            await self.connect()\n        return self.db\nMethod to retrieve the MongoDB database connection, connecting if necessary.\n",
        "size": 189,
        "parent-class": "DBHelper",
        "function_name": "get_db"
    },
    {
        "id": "ae0b6336-48e1-453d-aada-8a9e0966c70f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 47,
        "end_line": 51,
        "content": "async def disconnect(self):\n        if self.client:\n            self.client.close()\n            self.client = None\n            self.db = None\nThis code snippet defines an asynchronous method `disconnect` within a MongoDB database helper class, closing the client connection and resetting internal references.\n",
        "size": 309,
        "parent-class": "DBHelper",
        "function_name": "disconnect"
    },
    {
        "id": "53d0e3d9-2f17-444f-96d3-824ceef3238c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/settings.py",
        "file_name": "settings.py",
        "start_line": 1,
        "end_line": 1,
        "content": "from pydantic_settings import BaseSettings\nImport statement for pydantic settings configuration.\n",
        "size": 97,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "6cd9e7b9-4d6e-4cb6-a8cc-590a0031ec9c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import os\nimport json\nimport logging\nfrom datetime import datetime\nImport statements at the beginning of a Python script defining a logging system.\n",
        "size": 148,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9489207b-d9d6-44f6-93e4-eb0d143d9e94",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 8,
        "end_line": 27,
        "content": "def format(self, record):\n        log_entry = {\n            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n            \"levelname\": record.levelname,\n            \"module\": record.module,\n            \"funcName\": record.funcName,\n            \"lineno\": record.lineno\n        }\n\n        message = record.getMessage()\n        try:\n            parsed_message = json.loads(message)\n            log_entry[\"message\"] = json.dumps(parsed_message, indent=4, ensure_ascii=False)\n        except json.JSONDecodeError:\n            log_entry[\"message\"] = message\n        \n        if record.args:\n            log_entry[\"extra\"] = record.args\n            \n        return json.dumps(log_entry, ensure_ascii = False, indent=4)\nDefinition of a custom JSONFormatter class for logging, handling JSON messages and formatting log entries.\n",
        "size": 826,
        "parent-class": "JSONFormatter",
        "function_name": "format"
    },
    {
        "id": "95a64f85-f77a-4ef1-af53-d496741f8755",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 29,
        "end_line": 52,
        "content": "def setup_logger(name: str, log_file: str, log_dir: str = \"struct_logs\", level=logging.INFO) -> logging.Logger:\n    \"\"\"\n    Sets up a logger with a specified name and log file.\n    \n    Args:\n        name (str): The name of the logger.\n        log_file (str): The name of the log file.\n        log_dir (str): Directory where logs will be stored.\n        level (int): Logging level (default: logging.INFO).\n    \n    Returns:\n        logging.Logger: Configured logger instance.\n    \"\"\"\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    handler = logging.FileHandler(log_path)\n    handler.setFormatter(JSONFormatter())\n\n    logger.addHandler(handler)\n    return logger\nFunction definition for `setup_logger`, which configures and returns a logging.Logger instance writing JSON formatted logs to a specified file.\n",
        "size": 917,
        "parent-class": null,
        "function_name": "setup_logger"
    },
    {
        "id": "7ae4d0d4-e3fe-4d69-a559-cf0bfcd22d48",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nfrom typing import Dict, List\nimport httpx\nfrom app.config.settings import Settings\nfrom app.prompts import rag_generation\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Python class definition for LLM interaction.\n",
        "size": 312,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "88b645fb-6347-4118-921f-f59d63df4916",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 11,
        "end_line": 24,
        "content": "def __init__(self):\n        self.settings = Settings()\n        self.rag_generation = rag_generation\n        self.OPENAI_BASE_URL = self.settings.OPENAI_BASE_URL \n        self.model = self.settings.OPENAI_MODEL\n        self.openai_api_key = self.settings.OPENAI_API_KEY\n        self.OPENAI_CHAT_SUFFIX = \"chat/completions\"\n        self.openai_url = f\"{self.OPENAI_BASE_URL}/{self.OPENAI_CHAT_SUFFIX}\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\nConstructor for the LLMUtils class, initializing OpenAI API parameters and HTTP client timeout settings.\n",
        "size": 848,
        "parent-class": "LLMUtils",
        "function_name": "__init__"
    },
    {
        "id": "3d691ff7-ccf1-431e-afef-5df96e953df1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 26,
        "end_line": 53,
        "content": "async def _make_openai_request(\n        self, messages: List[Dict[str, str]], **params\n    ):\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.openai_api_key}\",\n        }\n\n        data = {\"model\": self.model, \"messages\": messages, **params}\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(\n                    self.openai_url, headers=headers, json=data\n                )\n                \n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {e.response.text}\")\n            raise HTTPException(detail = f\"error in openai call httpx error : {str(e)} - {e.response.text}\", status_code = e.response.status_code)\n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\n        except Exception as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\nThis chunk defines a private asynchronous method `_make_openai_request` within the `LLMUtils` class, responsible for making API calls to OpenAI and handling potential HTTP errors.\n",
        "size": 1452,
        "parent-class": "LLMUtils",
        "function_name": "_make_openai_request"
    },
    {
        "id": "74f8ddcf-f8df-4b2a-942f-a5ad02116283",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 55,
        "end_line": 80,
        "content": "async def generate_questions(self, chunk: str):\n        user_msg = f\"Text chunk:\\n{chunk}\"\n\n        response = await self._make_openai_request(\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": self.rag_generation.GENERATE_QUESTIONS_PROMPT,\n                },\n                {\"role\": \"user\", \"content\": user_msg}\n            ],\n            temperature=0.3,\n            max_tokens=512\n        )\n        print(json.dumps(response, indent=4))\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n\n\n        if \"error\" in response:\n            return [\"Could not generate questions - API error\"]\n\n        content = response[\"choices\"][0][\"message\"][\"content\"]\n        return [q.strip() for q in content.split(\"\\n\") if q.strip()]\nThis function uses the OpenAI API to generate questions from a given text chunk.  It's part of a larger class (`LLMUtils`) that handles various interactions with the OpenAI API.\n",
        "size": 1020,
        "parent-class": "LLMUtils",
        "function_name": "generate_questions"
    },
    {
        "id": "3b5ad803-617b-4935-a30e-832bdcfbf963",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 82,
        "end_line": 123,
        "content": "async def generate_multi_chunk_question(self, data: dict):\n        formatted_chunks = \"\\n\\n\".join(\n            f\"Chunk ID: {c['_id']}\\nContent: {c['text']}\" for c in data[\"chunks\"]\n        )\n        if data[\"file_type\"] == 'Text':\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_TXT\n        if data[\"file_type\"] == \"Code\":\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_CODE\n\n        messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": content,\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Text chunks:\\n{formatted_chunks}\"\n                }\n            ]\n        \n        response = await self._make_openai_request(\n            messages=messages,\n            temperature=0.7,\n            max_tokens=1024\n        )\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n        if \"error\" in response:\n            return {\n                \"question\": \"Could not generate question - API error\",\n                \"relevant_ids\": [\n                    data[\"chunks\"][0][\"_id\"], \n                    data[\"chunks\"][1][\"_id\"]\n                ] if len(data[\"chunks\"]) >= 2 else []\n            }\n        loggers[\"main\"].info(f\"response_json from generate multi : {response}\")\n\n        raw_content = response[\"choices\"][0][\"message\"][\"content\"]\n        loggers[\"main\"].info(raw_content)\n        return self._parse_multi_chunk_response(raw_content, data)\nThis chunk defines an asynchronous method `generate_multi_chunk_question` within the `LLMUtils` class, which generates questions from multiple text or code chunks using the OpenAI API.  It handles API errors and parses the response to return a list of questions with associated chunk IDs.\n",
        "size": 1827,
        "parent-class": "LLMUtils",
        "function_name": "generate_multi_chunk_question"
    },
    {
        "id": "f223ee76-da84-425d-b7fc-01c92af4d287",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 125,
        "end_line": 145,
        "content": "def _parse_multi_chunk_response(self, raw_content: str, chunks: List[Dict]):\n        try:\n            questions = json.loads(raw_content)\n            if not isinstance(questions, list):\n                raise ValueError(\"Expected a list of questions\")\n            \n            result_list = []\n            for q in questions:\n                if \"question\" not in q or \"chunk_ids\" not in q:\n                    raise ValueError(\"Missing required fields in question item\")\n                    \n                result_list.append({\n                    \"question\": q[\"question\"].strip(),\n                    \"relevant_ids\": [str(id) for id in q[\"chunk_ids\"]]\n                })\n            return result_list\n        except (json.JSONDecodeError, ValueError):\n            return {\n                \"question\": raw_content.strip(),\n                \"relevant_ids\": [c[\"_id\"] for c in chunks[:2]]\n            }\nThis function parses the OpenAI API response for multi-chunk question generation, handling JSON parsing errors and missing fields gracefully.  It returns a list of dictionaries, each containing a question and relevant chunk IDs, or a fallback dictionary if parsing fails.\n",
        "size": 1174,
        "parent-class": "LLMUtils",
        "function_name": "_parse_multi_chunk_response"
    },
    {
        "id": "25452389-e245-46f5-9a7c-37a4461c2092",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi.responses import JSONResponse\nfrom functools import wraps\nfrom fastapi import status\nImport statements for FastAPI error handling decorator.\n",
        "size": 154,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "6c7793d3-04b1-405d-b4eb-850950fc468d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 5,
        "end_line": 21,
        "content": "def handle_exceptions(func):\n    \"\"\"A decorator to catch exceptions and return a consistent JSON error response.\"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except Exception as e:\n            return JSONResponse(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                content={\n                    \"data\": {},\n                    \"statuscode\": 500,\n                    \"detail\": \"An internal server error occurred.\",\n                    \"error\": str(e),\n                },\n            )\n    return wrapper\nFastAPI decorator function to handle exceptions and return standardized JSON error responses.\n",
        "size": 712,
        "parent-class": null,
        "function_name": "handle_exceptions"
    },
    {
        "id": "43113adb-6b5a-4f32-a940-f78e8b27e40f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Python class definition for a database repository.\n",
        "size": 210,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5d5cf49e-141a-45b0-b020-d0c166edfcab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 6,
        "end_line": 9,
        "content": "def __init__(self):\n        self.ground_truth_collection = db_helper.gt_data\n        self.raw_collection = db_helper.raw_data\n        self.index_info_collection = db_helper.index_upsert_collection\nConstructor for the IndexRepository class, initializing connections to three MongoDB collections: ground truth data, raw data, and index information.\n",
        "size": 347,
        "parent-class": "IndexRepository",
        "function_name": "__init__"
    },
    {
        "id": "63d15758-9e45-462f-93ab-c8d848747301",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 11,
        "end_line": 27,
        "content": "async def fetch_ground_truth(self, query):\n\n        query = {\"question\": query}\n\n        ground_truth_doc = await self.ground_truth_collection.find_one(query)\n\n        ground_truth_ids = []\n        for x in ground_truth_doc[\"chunks\"]:\n            ground_truth_ids.append(x[\"_id\"])\n            \n        ground_truth = []\n        for _id in ground_truth_ids:\n            chunk = await self.raw_collection.find_one({\"_id\": _id})\n\n            ground_truth.append({\"id\": _id, \"chunk\": chunk[\"text_content\"]})\n\n        return ground_truth\nThis function `fetch_ground_truth` in the `IndexRepository` class retrieves ground truth chunks from a database given a question query.  It uses two collections: `ground_truth_collection` and `raw_collection`.\n",
        "size": 743,
        "parent-class": "IndexRepository",
        "function_name": "fetch_ground_truth"
    },
    {
        "id": "9d6bee28-fb15-4c1a-b066-48eeebc30231",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 29,
        "end_line": 56,
        "content": "async def get_namespace_and_host(\n        self, index_name: str, embedding_model: str, filename: str\n    ):\n\n        query = {\n            \"index_name\": index_name,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": filename,\n                    \"details.embedding_model\": embedding_model,\n                }\n            },\n        }\n\n        document = await self.index_info_collection.find_one(query)\n        \n        if document is None:\n            return None, None\n        \n        namespace_name = None\n        namespaces = document[\"namespaces\"]\n        for namespace in namespaces:\n            if namespace['details']['embedding_model'] == embedding_model and namespace['details']['filename'] == filename:\n                namespace_name = namespace[\"name\"]\n\n        host = document[\"index_host\"]\n\n        return namespace_name, host\nThis function retrieves the namespace and host from a MongoDB collection (`index_info_collection`) based on index name, embedding model, and filename.  It handles cases where no matching document is found.\n",
        "size": 1096,
        "parent-class": "IndexRepository",
        "function_name": "get_namespace_and_host"
    },
    {
        "id": "7500f38a-6b44-494b-aec8-9b1d50014ed8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 58,
        "end_line": 84,
        "content": "async def fetch_questions(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.ground_truth_collection.find_one(file_query)\n            \n            if not file_doc:\n                raise HTTPException(status_code=404, detail=\"File not found\")\n            \n            questions_with_ground_truth = []\n\n            data_doc = file_doc[\"data\"]\n\n            for document in data_doc:\n                question = document['question']\n                ground_truth_chunk_ids = [chunk['_id'] for chunk in document['chunks']]\n                questions_with_ground_truth.append({\n                    'question': question,\n                    'ground_truth_chunk_ids': ground_truth_chunk_ids\n                })\n            loggers[\"main\"].info(f\"length of questions with ground truth : {len(questions_with_ground_truth)}\")\n\n            return questions_with_ground_truth\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\nThis function retrieves questions and their corresponding ground truth chunk IDs from a MongoDB collection based on a given filename.  It handles file not found errors and general exceptions.\n",
        "size": 1255,
        "parent-class": "IndexRepository",
        "function_name": "fetch_questions"
    },
    {
        "id": "a19b5a69-023f-4294-b89e-f0acc361de5a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 86,
        "end_line": 96,
        "content": "async def fetch_total_chunks(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.raw_collection.find_one(file_query)\n            \n            return len(file_doc[\"data\"])\n            \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\nThis function retrieves the total number of chunks associated with a given file name from a MongoDB collection.  It's part of an IndexRepository class handling database interactions for an indexing system.\n",
        "size": 584,
        "parent-class": "IndexRepository",
        "function_name": "fetch_total_chunks"
    },
    {
        "id": "c05ddb0e-e74e-4327-88c5-a81af8aa64f4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 98,
        "end_line": 137,
        "content": "async def fetch_user_previous_configurations(self):\n\n        collection_names = await db_helper.db.list_collection_names()\n        if \"index_upsert\" not in collection_names:\n            return {\"message\": \"You have no previous configurations.\"}\n    \n        count = await self.index_info_collection.count_documents({})\n        if count == 0:\n            return {\"message\": \"You have no previous configurations.\"}\n        \n\n\n        try:\n            cursor = self.index_info_collection.find(\n                {}, \n                {\n                    \"index_name\" : 1, \n                    \"dimension\" : 1, \n                    \"similarity_metric\" : 1, \n                    \"namespaces.details.filename\" : 1, \n                    \"namespaces.details.embedding_model\" : 1\n                }\n            )\n            \n            configurations = []\n            async for doc in cursor:\n                configurations.append(\n                    {\n                        \"index_name\" : doc[\"index_name\"],\n                        \"dimension\" : doc[\"dimension\"],\n                        \"similarity_metric\" : doc[\"similarity_metric\"],\n                        \"filename\" : [namespace[\"details\"][\"filename\"] for namespace in doc[\"namespaces\"]],\n                        \"embedding_model\" : [namespace[\"details\"][\"embedding_model\"] for namespace in doc[\"namespaces\"]]\n                    }\n                )\n                \n            return configurations\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Error in fetching previous configurations: {str(e)}\")\nThis function retrieves a user's previous index configurations from a MongoDB database, returning a list of configurations or a message indicating no configurations exist.  It handles potential database errors.\n",
        "size": 1814,
        "parent-class": "IndexRepository",
        "function_name": "fetch_user_previous_configurations"
    },
    {
        "id": "787184cf-6511-42ec-b633-1122299fee02",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers\nImport statements for database interaction, error handling, and logging in a FastAPI application.\n",
        "size": 225,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "68c31f1a-dba7-45f5-81a2-041d899890d8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.raw_data\nConstructor for RawDataRepo class, initializes the MongoDB collection.\n",
        "size": 136,
        "parent-class": "RawDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "a34fb9f2-b4b3-457b-beee-df2b57b352e2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})\nMethod to clear all documents from the MongoDB raw_data collection.\n",
        "size": 148,
        "parent-class": "RawDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "45028dab-a90b-4e6d-bf83-2b82540a750a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 13,
        "end_line": 14,
        "content": "async def insert_documents(self, document: dict):\n        await self.collection.insert_one(document)\nMethod to insert a single document into a MongoDB collection.\n",
        "size": 163,
        "parent-class": "RawDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "4eff8532-fe79-4694-a12d-e049415db0d9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 16,
        "end_line": 21,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)\nMethod to check if a document exists in the raw data collection based on file name and type.\n",
        "size": 303,
        "parent-class": "RawDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "7452a1e8-2b71-48a6-b7db-45d0c9cb8d11",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 23,
        "end_line": 41,
        "content": "async def fetch_texts_by_ids(self,file_name: str, ids: list):\n        try:\n            \n            query = {\"file_name\": file_name}\n            ids_list = []\n            # projection = {\"data.$\": 1}  # Use positional projection to get the matching element\n            document = await self.collection.find_one(query)\n            for doc in document[\"data\"]:\n                if doc[\"_id\"] in ids:\n                    ids_list.append(doc[\"text\"])\n            # print(document)\n            return ids_list\n            # if document and \"data\" in document and document[\"data\"]:\n            #     return document[\"data\"][0][\"text\"]\n            \n\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside fetch_texts_by_ids error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\nThis code snippet defines an asynchronous method `fetch_texts_by_ids` within a `RawDataRepo` class, designed to retrieve text data from a MongoDB collection based on a filename and a list of IDs.  It handles exceptions and raises HTTP errors.\n",
        "size": 1095,
        "parent-class": "RawDataRepo",
        "function_name": "fetch_texts_by_ids"
    },
    {
        "id": "547a8a7f-3a53-48d1-b9df-287663372cf0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.queryembed import QueryEmbeddings\nimport time\nfrom datetime import datetime, timezone\nfrom app.utils.logging_util import loggers\nImport statements for FastAPI, database helper, query embedding model, time functions, and logging utilities used in the QueryRepository class.\n",
        "size": 372,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "58300d52-f138-44d2-9dfb-d760e5f479a5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 13,
        "end_line": 14,
        "content": "def __init__(self):\n        self.collection = db_helper.query_embeddings_collection\nConstructor for the QueryRepository class, initializing the MongoDB collection.\n",
        "size": 164,
        "parent-class": "QueryRepository",
        "function_name": "__init__"
    },
    {
        "id": "8e9df0ac-1ce3-4b58-b02b-8af1fc48c266",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 16,
        "end_line": 57,
        "content": "async def insert_or_update_embeddings(\n        self,\n        query_embeddings: QueryEmbeddings\n    ):\n        \"\"\"\n        Upsert embeddings - either update existing document or create new one\n        \"\"\"\n        try:\n            # Construct the unique identifier for the document\n            filter_query = {\n                \"filename\": query_embeddings.filename,\n                \"embedding_model\": query_embeddings.embedding_model,\n                \"dimension\": query_embeddings.dimension\n            }\n            \n            # Prepare the update operation\n            update_query = {\n                \"$set\": {\n                    \"filename\": query_embeddings.filename,\n                    \"embedding_model\": query_embeddings.embedding_model,\n                    \"dimension\": query_embeddings.dimension,\n                    \"updated_at\": datetime.now(timezone.utc).isoformat()\n                },\n                \"$addToSet\": {\n                    \"questions\": {\n                        \"$each\": query_embeddings.questions\n                    }\n                }\n            }\n            \n            # Perform upsert operation\n            result = await self.collection.update_one(\n                filter_query, \n                update_query, \n                upsert=True\n            )\n            \n            # Return the upserted or updated document's ID\n            return str(result.upserted_id) if result.upserted_id else str(result.modified_count)\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in upserting query embeds: {str(e)}\")\nThis chunk defines a method in the `QueryRepository` class that upserts query embeddings into a MongoDB collection.  It handles both insertion of new documents and updates to existing ones.\n",
        "size": 1791,
        "parent-class": "QueryRepository",
        "function_name": "insert_or_update_embeddings"
    },
    {
        "id": "80bce950-de4f-4156-a459-1b5ec8629261",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 70,
        "end_line": 111,
        "content": "async def retrieve_question_embeddings(\n        self,\n        file_name: str,\n        embed_model: str,\n        dimension: int,\n        question_text: str \n    ):\n        query = {\n            \"filename\": file_name,\n            \"embedding_model\": embed_model,\n            \"dimension\": dimension,\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        projection = {\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        \n        try:\n            s = time.time()\n            document = await self.collection.find_one(query, projection)\n            if document is None:\n                return None\n            \n            matching_questions = document.get('questions', [])\n            if matching_questions:\n                return matching_questions[0].get('embedding')\n            e = time.time()\n            loggers[\"main\"].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n            return None\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in retrieving query embeds in motor : {str(e)}\")\nThis chunk defines an asynchronous method `retrieve_question_embeddings` within the `QueryRepository` class, responsible for retrieving question embeddings from a MongoDB collection based on filename, embedding model, dimension, and question text.\n",
        "size": 1536,
        "parent-class": "QueryRepository",
        "function_name": "retrieve_question_embeddings"
    },
    {
        "id": "55955c75-a250-4a77-989d-c28233fd3beb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.indexupsert import IndexUpsert\nImport statements at the beginning of the IndexUpsertRepository class definition.\n",
        "size": 212,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "dcd16c1b-3b15-4ac0-b86a-0146cf9d55c4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self):\n        self.collection = db_helper.index_upsert_collection\nConstructor for the IndexUpsertRepository class, initializing the MongoDB collection.\n",
        "size": 166,
        "parent-class": "IndexUpsertRepository",
        "function_name": "__init__"
    },
    {
        "id": "0818fc0b-64eb-43c4-ae88-2c6d131c5f1f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 12,
        "end_line": 30,
        "content": "async def find_matching_index_upsert(\n        self,\n        dimension: str,\n        similarity_metric: str,\n        file_name: str,\n        embed_model: str,\n    ):\n        query = {\n            \"dimension\": dimension,\n            \"similarity_metric\": similarity_metric,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": file_name,\n                    \"details.embedding_model\": embed_model,\n                }\n            },\n        }\n        document = await self.collection.find_one(query)\n        return document\nThis function searches a MongoDB collection for an index upsert document matching specified dimension, similarity metric, filename, and embedding model.\n",
        "size": 719,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index_upsert"
    },
    {
        "id": "926b0938-d3dc-4240-a867-4e2d8e67abc7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 32,
        "end_line": 35,
        "content": "async def find_matching_index(self, dimension: str, similarity_metric: str):\n        query = {\"dimension\": dimension, \"similarity_metric\": similarity_metric}\n        document = await self.collection.find_one(query)\n        return document\nThis function retrieves an index document from a MongoDB collection based on dimension and similarity metric.\n",
        "size": 349,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index"
    },
    {
        "id": "e95ebddf-1664-4cbc-8dd9-4fda765af265",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 37,
        "end_line": 83,
        "content": "async def add_index_upsert_details(self, indexupsert: IndexUpsert):\n        try:\n            # Check if an index with same dimension and similarity_metric exists\n            existing_index = await self.collection.find_one(\n                {\n                    \"dimension\": indexupsert.dimension,\n                    \"similarity_metric\": indexupsert.similarity_metric,\n                }\n            )\n\n            if existing_index:\n                # Get the first namespace from the new data\n                new_namespace = indexupsert.namespaces[0]\n\n                # Check if namespace with same name already exists\n                namespace_exists = any(\n                    ns[\"name\"] == new_namespace.name\n                    for ns in existing_index.get(\"namespaces\", [])\n                )\n\n                if namespace_exists:\n                    # Namespace already exists, no need to update\n                    return str(existing_index[\"_id\"])\n\n                # Add new namespace to existing index\n                result = await self.collection.update_one(\n                    {\"_id\": existing_index[\"_id\"]},\n                    {\n                        \"$push\": {\n                            \"namespaces\": {\n                                \"name\": new_namespace.name,\n                                \"details\": {\n                                    \"filename\": new_namespace.details.filename,\n                                    \"embedding_model\": new_namespace.details.embedding_model,\n                                },\n                            }\n                        }\n                    },\n                )\n                return str(existing_index[\"_id\"])\n            else:\n                # Create new index document\n                index_upsert_dict = indexupsert.to_dict()\n                result = await self.collection.insert_one(index_upsert_dict)\n                return str(result.inserted_id)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk defines a method `add_index_upsert_details` within the `IndexUpsertRepository` class.  This method handles adding or updating index details in a MongoDB collection based on existing index and namespace checks.\n",
        "size": 2243,
        "parent-class": "IndexUpsertRepository",
        "function_name": "add_index_upsert_details"
    },
    {
        "id": "2bed588f-16b4-4d50-a0b6-d7523b95899f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from app.config.database import db_helper\nimport random\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Python class definition for a Ground Truth Data Repository.\n",
        "size": 241,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "e2f62f06-87f4-4899-8996-adf6907cdb6e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.gt_data\nConstructor for GTDataRepo class, initializes the MongoDB collection.\n",
        "size": 134,
        "parent-class": "GTDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "e924560f-5ce4-4f77-9ad2-11f974fc9723",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})\nMethod to clear all documents from the MongoDB collection.\n",
        "size": 139,
        "parent-class": "GTDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "d11a8328-dbd5-4bba-9b23-24a6e7e4aec1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 13,
        "end_line": 17,
        "content": "async def insert_documents(self, document: dict):\n        try :\n            await self.collection.insert_one(document)\n        except Exception as e :\n            loggers[\"main\"].info(f\"inside insert documents : {str(e)}\")\nThis chunk defines a method within a MongoDB data repository class that inserts a document into a collection, handling potential exceptions by logging errors.\n",
        "size": 382,
        "parent-class": "GTDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "85c005cc-4089-47d4-b2ea-42ca0bc8e979",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 19,
        "end_line": 24,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)\nThis method checks if a document with a given filename and file type exists in the MongoDB collection.\n",
        "size": 313,
        "parent-class": "GTDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "7b9faa5a-e462-4ff7-9218-7ee91e8e67ed",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 27,
        "end_line": 49,
        "content": "async def get_random_question(self, file_name: str):\n        try:\n            document = await self.collection.find_one({\"file_name\": file_name})\n            if not document:\n                return {\"message\": \"ground truth file not found in database\"}\n            \n            data = document.get(\"data\", [])\n            if not data:\n                return {\"message\": \"no data found in ground truth file\"}\n            \n            total_length = len(data)\n            random_number = random.randint(0, total_length - 1)\n            index = random_number % total_length\n\n            chunks = data[index].get(\"chunks\", [])\n            ids = []\n            for chunk in chunks:\n                ids.append(chunk.get(\"_id\", \"\"))\n            selected_question_gt = data[index]\n            return selected_question_gt, ids\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside get_random_question error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\nThis chunk defines an asynchronous method `get_random_question` within a `GTDataRepo` class that retrieves a random question and its associated IDs from a MongoDB collection based on a given file name.  It handles cases where the file or data is not found and raises a HTTPException for errors.\n",
        "size": 1324,
        "parent-class": "GTDataRepo",
        "function_name": "get_random_question"
    },
    {
        "id": "067e9a0d-8511-4149-9e15-3e44b4123308",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nfrom pydantic.config import ConfigDict\nfrom pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nimport logging\nImport statements at the beginning of a Pydantic-based Python class definition.\n",
        "size": 320,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ed7043ec-460c-4eea-abb3-cbc74307bc61",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 39,
        "end_line": 42,
        "content": "def validate_similarity_metric(cls, value):\n        if value.lower() not in cls.ALLOWED_METRICS:\n            raise ValueError(f\"Invalid similarity_metric '{value}'. Must be one of {cls.ALLOWED_METRICS}.\")\n        return value.lower()  # Normalize to lowercase\nThis code snippet defines a field validator within a Pydantic model to ensure the `similarity_metric` field is one of the allowed values.\n",
        "size": 398,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_similarity_metric"
    },
    {
        "id": "5f839b26-fc56-4394-b864-2527b27e2424",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 47,
        "end_line": 59,
        "content": "def validate_dimension(cls, value, info):\n        # Use info.data to access the context dictionary containing input data\n        embed_model = info.data.get(\"embed_model\")\n\n        if not embed_model:\n            raise ValueError(\"embed_model must be provided before validating dimension.\")\n\n        valid_dimensions = cls.MODEL_TO_DIMENSIONS.get(embed_model)\n\n        if valid_dimensions and value not in valid_dimensions:\n            raise ValueError(f\"Invalid dimension '{value}' for model '{embed_model}'. Must be one of {valid_dimensions}.\")\n\n        return value\nThis code snippet is a Pydantic field validator that checks if the `dimension` parameter is valid for the specified `embed_model` based on a predefined mapping.\n",
        "size": 730,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_dimension"
    },
    {
        "id": "5e4be080-7a97-46c3-a234-35a33408a413",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/file_upload_schema.py",
        "file_name": "file_upload_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Optional\nImport statements for Pydantic BaseModel and typing.\n",
        "size": 119,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "fe0550fb-f491-4f25-9f0e-2ea1bd18977e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/query_schema.py",
        "file_name": "query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Optional, Literal\nfrom pydantic import BaseModel, Field\nImport statements for Pydantic BaseModel and typing modules used in defining a QueryEndPointRequest class.\n",
        "size": 182,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "388d5673-053b-4418-994e-48f1525f82af",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/random_query_schema.py",
        "file_name": "random_query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal, Optional\nImport statements for Pydantic BaseModel, Field, Literal, and Optional.\n",
        "size": 147,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9d5f26e4-e1c8-4dba-b3fd-36f04a9d5a2c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/reranking_schema.py",
        "file_name": "reranking_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Any, Dict\nfrom pydantic import BaseModel\nImport statements for typing and pydantic BaseModel.\n",
        "size": 113,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "7e1352bc-b936-4fab-977d-3a5dda5cb792",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from datetime import datetime\nfrom typing import Any, Dict, List\nfrom bson import ObjectId\nImport statements at the beginning of the Python file.\n",
        "size": 146,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c22d3340-0044-4f6a-b7ce-477d88be24ea",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 8,
        "end_line": 10,
        "content": "def __init__(self, filename: str, embedding_model: str):\n        self.filename = filename\n        self.embedding_model = embedding_model\nConstructor for the NamespaceDetails class, initializing filename and embedding_model attributes.\n",
        "size": 235,
        "parent-class": "NamespaceDetails",
        "function_name": "__init__"
    },
    {
        "id": "5ad93276-a886-4fd7-bc53-88185dc03eb3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 12,
        "end_line": 16,
        "content": "def to_dict(self) -> Dict[str, str]:\n        return {\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n        }\nMethod `to_dict` in `NamespaceDetails` class converts object attributes to a dictionary.\n",
        "size": 245,
        "parent-class": "NamespaceDetails",
        "function_name": "to_dict"
    },
    {
        "id": "e4b2ad1c-ce0c-424d-9847-22dbacd31bd5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 20,
        "end_line": 22,
        "content": "def __init__(self, name: str, filename: str, embedding_model: str):\n        self.name = name\n        self.details = NamespaceDetails(filename, embedding_model)\nConstructor for the `Namespace` class, initializing its name and details using a `NamespaceDetails` object.\n",
        "size": 268,
        "parent-class": "Namespace",
        "function_name": "__init__"
    },
    {
        "id": "79e39ad4-ee36-499d-bb2c-3e5158d9743c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 24,
        "end_line": 25,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\"name\": self.name, \"details\": self.details.to_dict()}\n`to_dict` method for the `Namespace` class, converting a Namespace object to a dictionary.\n",
        "size": 198,
        "parent-class": "Namespace",
        "function_name": "to_dict"
    },
    {
        "id": "746cf384-97f0-4f1f-8966-3bca09db0254",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 29,
        "end_line": 43,
        "content": "def __init__(\n        self,\n        index_name: str,\n        index_host: str,\n        dimension: int,\n        similarity_metric: str,\n    ):\n        self._id = ObjectId()\n        self.index_name = index_name\n        self.index_host = index_host\n        self.dimension = dimension\n        self.similarity_metric = similarity_metric\n        self.created_at = datetime.utcnow()\n        self.updated_at = datetime.utcnow()\n        self.namespaces: List[Namespace] = []\nConstructor for the `IndexUpsert` class, initializing its attributes including index details, timestamps, and an empty list for namespaces.\n",
        "size": 605,
        "parent-class": "IndexUpsert",
        "function_name": "__init__"
    },
    {
        "id": "26b6e87a-af0a-4157-9c52-74eb61109b74",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 45,
        "end_line": 47,
        "content": "def add_namespace(self, namespace: Namespace) -> None:\n        self.namespaces.append(namespace)\n        self.updated_at = datetime.utcnow()\nMethod in `IndexUpsert` class to add a namespace to the list of namespaces and update the timestamp.\n",
        "size": 242,
        "parent-class": "IndexUpsert",
        "function_name": "add_namespace"
    },
    {
        "id": "35c2f47f-952c-4ca1-853c-6f337f8f02e0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 49,
        "end_line": 61,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"_id\": str(self._id),\n            \"index_name\": self.index_name,\n            \"index_host\": self.index_host,\n            \"dimension\": self.dimension,\n            \"similarity_metric\": self.similarity_metric,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n            \"namespaces\": [\n                namespace.to_dict() for namespace in self.namespaces\n            ],\n        }\n`to_dict` method in the `IndexUpsert` class, converting an instance to a dictionary representation.\n",
        "size": 604,
        "parent-class": "IndexUpsert",
        "function_name": "to_dict"
    },
    {
        "id": "84edde59-323e-4167-908e-5199fa4ba07c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 64,
        "end_line": 103,
        "content": "def from_dict(cls, data: Dict[str, Any]) -> \"IndexUpsert\":\n        index = cls(\n            index_name=data[\"index_name\"],\n            index_host=data[\"index_host\"],\n            dimension=data[\"dimension\"],\n            similarity_metric=data[\"similarity_metric\"],\n        )\n\n        # Set ID if it exists\n        if \"_id\" in data:\n            if isinstance(data[\"_id\"], str):\n                index._id = ObjectId(data[\"_id\"])\n            else:\n                index._id = data[\"_id\"]\n\n        # Set dates if they exist\n        if \"created_at\" in data:\n            if isinstance(data[\"created_at\"], str):\n                index.created_at = datetime.fromisoformat(data[\"created_at\"])\n            else:\n                index.created_at = data[\"created_at\"]\n\n        if \"updated_at\" in data:\n            if isinstance(data[\"updated_at\"], str):\n                index.updated_at = datetime.fromisoformat(data[\"updated_at\"])\n            else:\n                index.updated_at = data[\"updated_at\"]\n\n        # Add namespaces if they exist\n        if \"namespaces\" in data:\n            for namespace_data in data[\"namespaces\"]:\n                details = namespace_data[\"details\"]\n                namespace = Namespace(\n                    name=namespace_data[\"name\"],\n                    filename=details[\"filename\"],\n                    embedding_model=details[\"embedding_model\"],\n                )\n                index.namespaces.append(namespace)\n\n        return index\n`from_dict` classmethod for `IndexUpsert` class; reconstructs `IndexUpsert` object from a dictionary.\n",
        "size": 1564,
        "parent-class": "IndexUpsert",
        "function_name": "from_dict"
    },
    {
        "id": "7710abc7-42d7-49e0-a5d6-18ce9df387df",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from typing import List, Union\nimport numpy as np\nfrom bson import ObjectId\nfrom datetime import datetime, timezone\nImport statements at the beginning of a Python class definition.\n",
        "size": 181,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5fe686bc-3e01-42be-a2cf-a2e0d62235d6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 7,
        "end_line": 19,
        "content": "def __init__(self, \n                 filename: str, \n                 embedding_model: str, \n                 dimension: int, \n                 questions: List[dict] = None):\n        \n        self._id = ObjectId()\n        self.filename = filename\n        self.embedding_model = embedding_model\n        self.dimension = dimension\n        self.created_at = datetime.now(timezone.utc).isoformat()\n        self.updated_at = datetime.now(timezone.utc).isoformat()\n        self.questions = questions or []\nConstructor for the QueryEmbeddings class, initializing attributes including ID, filename, embedding model, dimension, timestamps, and an empty list for questions.\n",
        "size": 664,
        "parent-class": "QueryEmbeddings",
        "function_name": "__init__"
    },
    {
        "id": "cadf669d-61d9-4145-b5b9-2a54f435472e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 21,
        "end_line": 35,
        "content": "def add_question(self, question_text: str, embedding: Union[List[float], np.ndarray]):\n        \n        # Ensure embedding is converted to a list\n        if isinstance(embedding, np.ndarray):\n            embedding = embedding.tolist()\n        \n        # Validate embedding dimension\n        if len(embedding) != self.dimension:\n            raise ValueError(f\"Embedding must have {self.dimension} dimensions\")\n        \n        question = {\n            \"question_text\": question_text,\n            \"embedding\": embedding\n        }\n        self.questions.append(question)\nMethod to add a question and its embedding to the QueryEmbeddings object, validating embedding dimensions.\n",
        "size": 675,
        "parent-class": "QueryEmbeddings",
        "function_name": "add_question"
    },
    {
        "id": "664083a5-0a9e-4395-870f-696fca3bd6ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 37,
        "end_line": 47,
        "content": "def to_dict(self) -> dict:\n        \n        return {\n            \"_id\": str(self._id),\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n            \"dimension\": self.dimension,\n            \"questions\": self.questions,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n        }\nMethod to convert QueryEmbeddings object to a dictionary.\n",
        "size": 439,
        "parent-class": "QueryEmbeddings",
        "function_name": "to_dict"
    },
    {
        "id": "28fc3059-898a-4a6a-a329-a69dc5224708",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\nfrom app.usecases.file_upload_usecase import FileUploadUseCase\nimport logging\nImport statements for FastAPI dependencies and the FileUploadUseCase.\n",
        "size": 242,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d4e3393d-3e6a-4d8b-9f8d-26505ce8f5c3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: FileUploadUseCase = Depends()):\n        self.usecase = usecase\nConstructor for FileUploadController, injecting FileUploadUseCase dependency.\n",
        "size": 169,
        "parent-class": "FileUploadController",
        "function_name": "__init__"
    },
    {
        "id": "c3ccf398-068c-4d50-86f1-e78149720bc6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def upload_files(self, request_data: dict):\n        return await self.usecase.execute(request_data)\nFastAPI controller method for file upload, using a use case for business logic.\n",
        "size": 186,
        "parent-class": "FileUploadController",
        "function_name": "upload_files"
    },
    {
        "id": "8392acac-b23a-4c82-9eb1-1f04cf20578b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.usecases.reranking_usecase import RerankingUseCase\nImport statements for FastAPI dependencies and data schemas used in a RerankingController class.\n",
        "size": 282,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f38b915d-3840-4092-8063-a0f11cddb842",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "def __init__(self, reranking_usecase: RerankingUseCase = Depends()):\n        self.reranking_usecase = reranking_usecase\nConstructor for RerankingController, injecting RerankingUseCase dependency.\n",
        "size": 196,
        "parent-class": "RerankingController",
        "function_name": "__init__"
    },
    {
        "id": "9fe84757-bf55-4cdb-b1f7-598f6960c90a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 14,
        "end_line": 17,
        "content": "async def rerank_documents(\n        self, request: RerankingRequest\n    ) -> RerankingResponse:\n        return await self.reranking_usecase.execute(request)\n`rerank_documents` method in `RerankingController` class uses a `RerankingUseCase` to process a `RerankingRequest` and return a `RerankingResponse`.\n",
        "size": 306,
        "parent-class": "RerankingController",
        "function_name": "rerank_documents"
    },
    {
        "id": "ee74b5be-1717-4440-a879-29473f71c365",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.index_upsert_usecase import IndexUpsertUseCase\nImport statements for FastAPI dependency injection and the use case class.\n",
        "size": 168,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "e7d4f02c-f605-47c7-8cdf-b35b3fa21ee5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self, index_upsert_usecase=Depends(IndexUpsertUseCase)):\n        self.index_upsert_usecase = index_upsert_usecase\nConstructor for IndexUpsertController, injecting IndexUpsertUseCase dependency.\n",
        "size": 207,
        "parent-class": "IndexUpsertController",
        "function_name": "__init__"
    },
    {
        "id": "24e90f49-8d73-42e3-b57c-523b049cfe7b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 10,
        "end_line": 12,
        "content": "async def index_upsert(self, request):\n\n        return await self.index_upsert_usecase.index_upsert(request)\nFastAPI controller method for handling index upsert requests.\n",
        "size": 171,
        "parent-class": "IndexUpsertController",
        "function_name": "index_upsert"
    },
    {
        "id": "8c9ee739-ef0c-4650-9fd3-70fa14dea850",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.usecases.query_usecase import QueryUseCase\nImport statements for FastAPI dependencies and data models used in a QueryController class.\n",
        "size": 237,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9ae6b805-84aa-40b1-89bc-50782cc6afba",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: QueryUseCase = Depends()):\n        self.query_usecase = usecase\nConstructor for QueryController, injecting QueryUseCase dependency.\n",
        "size": 160,
        "parent-class": "QueryController",
        "function_name": "__init__"
    },
    {
        "id": "ec6fc6a4-7c3f-4952-b938-8972ed86a97b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def make_query(self, request: QueryEndPointRequest):\n        return await self.query_usecase.execute(request)\nFastAPI controller method handling query requests using a use case.\n",
        "size": 184,
        "parent-class": "QueryController",
        "function_name": "make_query"
    },
    {
        "id": "b9441d79-dfd5-4171-828a-7fe1db846d7c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.config_usecase import ConfigUsecase\nImport statements for FastAPI dependencies and the ConfigUsecase.\n",
        "size": 148,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "dfa7d563-60b1-48b5-99ea-71d3a6ce5aff",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, usecase: ConfigUsecase = Depends()):\n        self.query_usecase = usecase\nConstructor for ConfigurationController, injecting ConfigUsecase dependency.\n",
        "size": 170,
        "parent-class": "ConfigurationController",
        "function_name": "__init__"
    },
    {
        "id": "09f076af-6e1e-4a0a-bb31-546c99a015a2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "async def get_config(self):\n        return await self.query_usecase.get_config()\nFastAPI controller method to retrieve configuration data using a ConfigUsecase.\n",
        "size": 161,
        "parent-class": "ConfigurationController",
        "function_name": "get_config"
    },
    {
        "id": "571240b9-0093-445e-a95b-008c3a8ab009",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.repositories.index_repository import IndexRepository\nImport statements for FastAPI dependencies and the IndexRepository.\n",
        "size": 158,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "3c39dd34-8444-4db9-9848-2368f67ae1aa",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, index_repository: IndexRepository = Depends()):\n        self.index_repository = index_repository\nConstructor for ConfigUsecase class, injecting IndexRepository dependency.\n",
        "size": 191,
        "parent-class": "ConfigUsecase",
        "function_name": "__init__"
    },
    {
        "id": "866b7d2d-fbdb-4e3f-a308-9d39e6ac734e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 9,
        "end_line": 13,
        "content": "async def get_config(self):\n        response = await self.index_repository.fetch_user_previous_configurations()\n        if response is None:\n            return {\"message\": \"No configurations found\"}\n        return response\n`get_config` method in FastAPI's ConfigUsecase class retrieves user configurations from an IndexRepository.\n",
        "size": 331,
        "parent-class": "ConfigUsecase",
        "function_name": "get_config"
    },
    {
        "id": "dc6fe65d-2f4e-4bed-9a21-1436a85daacb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import os\nimport json\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom fastapi import Depends, HTTPException\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.repositories.index_repository import IndexRepository\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.reranking_service import RerankerService\nfrom app.utils.logging_util import loggers\nImport statements and dependencies for the RerankingUseCase class.\n",
        "size": 520,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "dd1877fd-913d-4559-8eb3-112feb270c7d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 18,
        "end_line": 24,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        reranker_service: RerankerService = Depends(),\n    ):\n        self.reranker_service = reranker_service\n        self.index_repository = index_repository\nConstructor for the RerankingUseCase class, injecting dependencies for reranker and index repository.\n",
        "size": 345,
        "parent-class": "RerankingUseCase",
        "function_name": "__init__"
    },
    {
        "id": "e2190357-5741-4e09-a79c-99ad8b5762e8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 26,
        "end_line": 90,
        "content": "async def execute(self, request: RerankingRequest) -> RerankingResponse:\n        \"\"\"\n        Execute the reranking use case by processing queries and documents \n        from the saved first_stage_retrieval.json file.\n\n        Args:\n            request: RerankingRequest containing model_name and top_n\n\n        Returns:\n            RerankingResponse with evaluation metrics\n        \"\"\"\n        try:\n            model_name = request.model_name\n            top_n = request.top_n\n            top_k=request.top_k\n\n            if top_n > top_k:\n                raise HTTPException(\n                    status_code=400, \n                    detail=f\"Invalid request: top_n ({top_n}) cannot be greater than top_k ({top_k}).\"\n                )\n\n            # Load first stage retrieval results\n            first_stage_file_path = \"results/first_stage_retrieval.json\"\n            if not os.path.exists(first_stage_file_path):\n                raise HTTPException(\n                    status_code=404, \n                    detail=\"First stage retrieval results not found. Run query_usecase first.\"\n                )\n                \n            with open(first_stage_file_path, \"r\") as f:\n                questions_data = json.load(f)\n                \n            # Process each question in parallel\n            tasks = [\n                self._process_question(question, model_name, top_n)\n                for question in questions_data\n            ]\n            \n            processed_questions = await asyncio.gather(*tasks)\n            \n            # Extract questions and evaluation metrics\n            questions, evaluation_metrics_list = zip(*processed_questions)\n            \n            # Calculate average metrics\n            with ThreadPoolExecutor() as executor:\n                average_evaluation_metrics = executor.submit(\n                    self.average_metrics,\n                    evaluation_metrics_list,\n                    top_n\n                ).result()\n                \n            # Save results\n            os.makedirs(\"results\", exist_ok=True)\n            with open(\"results/second_stage_retrieval.json\", \"w\") as f:\n                json.dump(list(questions), f, indent=4)\n                \n            with open(\"results/second_stage_evaluation.json\", \"w\") as f:\n                json.dump(average_evaluation_metrics, f, indent=4)\n                \n            return RerankingResponse(evaluation_metrics=average_evaluation_metrics)\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking execution: {str(e)}\", exc_info=True)\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk is the `execute` method of the `RerankingUseCase` class.  It orchestrates the reranking process, handling input validation, loading data, parallel processing of questions, calculating average evaluation metrics, and saving results.\n",
        "size": 2876,
        "parent-class": "RerankingUseCase",
        "function_name": "execute"
    },
    {
        "id": "16fe5094-5069-4341-a4f8-f04db9f2d9e3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 92,
        "end_line": 113,
        "content": "async def _process_question(self, question, model_name, top_n):\n        \"\"\"Process a single question with reranking.\"\"\"\n        try:\n            query = question[\"question\"]\n            documents = question[\"relevant_docs\"]\n            ground_truth_chunk_ids = question[\"ground_truth_chunk_ids\"]\n            \n            reranked_docs = await self._rerank_documents(model_name, query, documents, top_n)\n            \n            # Update the question with reranked documents\n            question[\"reranked_docs\"] = reranked_docs\n            \n            evaluation_metrics = self._calculate_evaluation_metrics(\n                reranked_docs, ground_truth_chunk_ids, top_n\n            )\n            \n            return question, evaluation_metrics\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error processing question '{query}': {str(e)}\", exc_info=True)\n            question[\"error\"] = str(e)\n            raise HTTPException(status_code=500, detail=str(e))\nThis function `_process_question` is an asynchronous helper function within the `RerankingUseCase` class.  It processes a single question from a batch loaded from `first_stage_retrieval.json`, performs reranking using `_rerank_documents`, calculates evaluation metrics using `_calculate_evaluation_metrics`, and returns the updated question and metrics.\n",
        "size": 1346,
        "parent-class": "RerankingUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "b6ae3e07-b06f-4fa4-936c-ae8ce7899987",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 115,
        "end_line": 217,
        "content": "async def _rerank_documents(self, model_name, query, documents, top_n):\n        \"\"\"Rerank documents using the specified reranker.\"\"\"\n\n        try:\n            pinecone_models = [\n                \"cohere-rerank-3.5\",\n                \"bge-reranker-v2-m3\",\n                \"pinecone-rerank-v0\",\n            ]\n            cohere_models = [\n                \"rerank-v3.5\",\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n            ]\n            jina_models = [\"jina-reranker-v2-base-multilingual\"]\n            voyage_models=[\"rerank-lite-1\",\"rerank-1\",\"rerank-2\"]\n            \n            # Extract text from documents for non-Pinecone rerankers\n            docs_text = [doc[\"text\"] for doc in documents]\n            # Format documents for Pinecone reranker\n            pinecone_docs = [{\"text\": doc[\"text\"]} for doc in documents]\n            \n            results = []\n            \n            # Determine which reranker to use based on the model name\n            if model_name.lower() in pinecone_models:\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model_name, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    # Find the original document to preserve the id\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            elif model_name.lower() in cohere_models:\n                reranking_result = await self.reranker_service.cohere_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n                        \n            elif model_name.lower() in jina_models:\n                reranking_result = await self.reranker_service.jina_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n\n            elif model_name.lower() in voyage_models:\n                reranking_result = await self.reranker_service.voyage_rerank(\n                    model_name,query,docs_text,top_n\n                )\n                for result in reranking_result.get(\"data\",[]):\n                    idx=result.get(\"index\",0)\n                    if 0<=idx <len(documents):\n                        results.append({\n                            \"id\":documents[idx][\"id\"],\n                            \"text\":documents[idx][\"text\"],\n                            \"score\":result.get(\"relevance_score\",0.0)\n                        })\n                        \n            else:\n                # Default to Pinecone\n                model = \"bge-reranker-v2-m3\"\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            return results\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\nThis function `_rerank_documents` is an asynchronous method within the `RerankingUseCase` class.  It reranks documents based on a given model and query, handling different reranker types (Pinecone, Cohere, Jina, Voyage).\n",
        "size": 4861,
        "parent-class": "RerankingUseCase",
        "function_name": "_rerank_documents"
    },
    {
        "id": "0f225995-9d6f-401d-a59b-c16956342305",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 219,
        "end_line": 260,
        "content": "def _calculate_evaluation_metrics(self, retrieved_docs, ground_truth_ids, top_n):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n        return {\n            \"precision_at_k\": EvaluationService.precision_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"recall_at_k\": EvaluationService.recall_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids, \n                k=top_n\n            ),\n            \"bpref\": EvaluationService.bpref(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids\n            ),\n            \"mrr\": EvaluationService.reciprocal_rank(\n            retrieved_docs=retrieved_docs,\n            ground_truth=ground_truth_ids\n            ),\n            \"map\": EvaluationService.mean_average_precision(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n\n            ),\n        }\nThis function calculates and returns a dictionary of evaluation metrics (precision, recall, F1-score, hit rate, NDCG, bpref, MRR, MAP) for a reranking model's performance, given retrieved documents and ground truth IDs.  It uses methods from an `EvaluationService` class.\n",
        "size": 1983,
        "parent-class": "RerankingUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "6f5851ea-4741-44df-9db4-09d6586f4edd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 262,
        "end_line": 314,
        "content": "def average_metrics(self, metrics_list, top_n):\n        \"\"\"Calculate average metrics across all questions.\"\"\"\n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_n + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n    \n        avg_dict = sum_dict.copy()\n        \n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    for sub_key, sub_value in value.items():\n                        if sub_key in sum_dict.get(key, {}):\n                            sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] if count_dict[key] > 0 else 0.0\n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key] if count_dict[key] > 0 else 0.0\n        \n        return avg_dict\nThis function calculates the average evaluation metrics (precision, recall, F1-score, hit rate, NDCG, bpref, MRR, MAP) across multiple questions after reranking,  used in the `RerankingUseCase` class to produce a final `RerankingResponse`.\n",
        "size": 2159,
        "parent-class": "RerankingUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "ababd7c2-045b-4892-b575-755da07ab513",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 1,
        "end_line": 16,
        "content": "import os\nimport time\nimport json\nimport asyncio\nfrom typing import List\nfrom typing import List\nfrom fastapi import Depends, HTTPException\nfrom concurrent.futures import ThreadPoolExecutor\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.repositories.index_repository import IndexRepository\nfrom app.repositories.query_repository import QueryRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.pinecone_service import PineconeService\nfrom app.models.domain.queryembed import QueryEmbeddings\nfrom app.utils.logging_util import loggers\nImport statements and dependency injections at the beginning of the `QueryUseCase` class.\n",
        "size": 749,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "212ed909-85ef-4fc1-adaa-4dfce5ea8611",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 23,
        "end_line": 70,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        query_repository: QueryRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(),\n    ):\n        self.index_repository = index_repository\n        self.query_repository = query_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        self.semaphore = asyncio.Semaphore(50)\n        self.embedding_batch = 90\n        self.embedding_batch = 90\nConstructor for the `QueryUseCase` class, initializing dependencies and mapping embedding models to providers and dimensions.  Includes a semaphore for concurrency control and batch size settings.\n",
        "size": 2286,
        "parent-class": "QueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "2355c5fa-741b-4c84-940e-2af61dbaa397",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 72,
        "end_line": 145,
        "content": "async def execute(self, request_data: QueryEndPointRequest):\n        \"\"\"\n        Main execution function for processing query endpoint requests.\n        Breaks down the request handling into smaller, focused functions.\n        \"\"\"\n        \n        total_chunks = await self.index_repository.fetch_total_chunks(request_data.file_name)\n        if total_chunks < request_data.top_k:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Top K value cannot be greater than the total number of chunks: {total_chunks}\",\n            )\n        \n        try:\n            model = self.embeddings_provider_mapping[request_data.embedding_model]\n        except KeyError:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Invalid embedding model. Please provide a valid model.\",\n            )\n            \n        if request_data.dimension not in self.model_to_dimensions[request_data.embedding_model]:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Invalid dimension. Please provide a valid dimension for embedding model: {request_data.embedding_model}\",\n            )\n            \n        namespace_name, host = await self._get_namespace_and_host(request_data)\n        questions_with_ground_turth_chunks = await self.index_repository.fetch_questions(request_data.file_name)\n        \n        batches = [questions_with_ground_turth_chunks[i:min(i + self.embedding_batch, len(questions_with_ground_turth_chunks))]\n            for i in range(0, len(questions_with_ground_turth_chunks), self.embedding_batch)\n        ]\n        \n        embedding_tasks = [self._generate_batch_embeddings(batch, request_data) for batch in batches]\n        embeddings = await asyncio.gather(*embedding_tasks, return_exceptions=True)\n        \n        dense_embeddings = []\n        for x in embeddings:\n            dense_embeddings.extend(x)\n\n        loggers['evaluation'].info(f\"Total number of questions: {len(questions_with_ground_turth_chunks)}\")\n        loggers['evaluation'].info(f\"Total number of dense embeddings: {len(dense_embeddings)}\")\n\n        \n        s = time.time()\n        tasks = [self._process_question(embedding, question, namespace_name, host, request_data) for question, embedding in zip(questions_with_ground_turth_chunks, dense_embeddings)]\n        processed_questions = await asyncio.gather(*tasks)\n        \n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices: {e-s}\")\n        if processed_questions:\n            loggers['evaluation'].info(f\"processed_questions: {len(processed_questions)}\")\n        \n        questions, evaluation_metrics_list = zip(*processed_questions)\n\n        s = time.time()\n        with ThreadPoolExecutor() as executor:\n            average_evaluation_metrics = executor.submit(\n                self.average_metrics,\n                evaluation_metrics_list,\n                request_data.top_k,\n            ).result()\n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices (Average): {e-s}\")\n\n        os.makedirs(\"results\", exist_ok=True)\n        with open(\"results/first_stage_retrieval.json\", \"w\") as f:\n            json.dump(list(questions), f, indent=4)\n        \n        with open(\"results/first_stage_evaluation.json\", \"w\") as f:\n            json.dump(average_evaluation_metrics, f, indent=4)\n            \n        return {\"questions\": questions, \"evaluation_result\" : average_evaluation_metrics}\nThis chunk contains the `execute` method of the `QueryUseCase` class, the main function responsible for handling query requests, processing embeddings, performing searches (regular or hybrid), calculating evaluation metrics, and saving the results to JSON files.\n",
        "size": 3793,
        "parent-class": "QueryUseCase",
        "function_name": "execute"
    },
    {
        "id": "18029956-0ce7-4cc2-9ff4-2b9164d094f7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 147,
        "end_line": 156,
        "content": "async def _generate_batch_embeddings(self, questions: List[dict], request_data: QueryEndPointRequest):\n        \n        questions = [question[\"question\"] for question in questions]\n        loggers['evaluation'].info(f'Generating embeddings for {len(questions)} questions.')\n        dense_embeddings = await self._generate_dense_embedding(request_data, questions)\n            \n        if not dense_embeddings:\n            raise HTTPException(status_code=500, detail=\"Error generating dense embedding.\")\n            \n        return dense_embeddings\nThis function is part of the `QueryUseCase` class and handles generating embeddings for batches of questions before performing a search.  It calls another function to generate the embeddings and raises an exception if there's an error.\n",
        "size": 783,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_batch_embeddings"
    },
    {
        "id": "c556c94f-d597-479c-8a92-ba6d45c8ba24",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 159,
        "end_line": 203,
        "content": "async def _process_question(self, dense_embedding: list, question: dict, namespace_name: str, host:str, request_data: QueryEndPointRequest):\n        \n        async with self.semaphore:\n            \n            results = None\n            if request_data.is_hybrid:\n                results = await self._perform_hybrid_search(\n                    request_data, namespace_name, host, dense_embedding, question['question']\n                )\n            else:\n                results = await self._perform_regular_search(\n                    request_data, namespace_name, host, dense_embedding\n                )\n                \n            if not results:\n                loggers['evaluation'].info(\"No results found.\")\n                \n            relevant_docs_ids = []\n            relevant_docs = []\n            for result in results[\"matches\"]:\n                relevant_docs_ids.append(result[\"id\"])\n                relevant_docs.append(\n                    {\"id\": result[\"id\"], \"text\": result[\"metadata\"][\"text\"]}\n                )\n            \n            question['relevant_docs'] = relevant_docs\n            \n            ground_truth_chunk_ids = question['ground_truth_chunk_ids']\n            \n            if not relevant_docs_ids:\n                return {\n                    \"relevant_docs\": {},\n                    \"error\": \"No relevant documents found.\",\n                }\n\n            else:\n                with ThreadPoolExecutor() as executor:\n                    evaluation_metrics = executor.submit(\n                        self._calculate_evaluation_metrics,\n                        relevant_docs,\n                        ground_truth_chunk_ids,\n                        request_data.top_k\n                    ).result()\n                    \n            return question, evaluation_metrics\nThis function handles the asynchronous processing of individual questions within the `QueryUseCase.execute` method.  It performs either a hybrid or regular search based on user input, retrieves relevant documents, and calculates evaluation metrics using a thread pool.\n",
        "size": 2072,
        "parent-class": "QueryUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "0b69082e-2e95-4baa-ac90-5c20b849d3c1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 206,
        "end_line": 229,
        "content": "async def _get_namespace_and_host(self, request_data: QueryEndPointRequest):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{request_data.similarity_metric}-{request_data.dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    request_data.embedding_model,\n                    request_data.file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers['evaluation'].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function retrieves the Pinecone index namespace and host based on the request data, raising HTTPExceptions if not found or errors occur.\n",
        "size": 1122,
        "parent-class": "QueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "c24e897b-1b97-4120-b9d2-24db5b873ba8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 231,
        "end_line": 304,
        "content": "async def _generate_dense_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate dense embedding for the query using the appropriate provider.\"\"\"\n\n        try:\n            s = time.perf_counter()\n            existing_embeddings = []\n            for question in questions:\n                already_embeddings = await self.query_repository.retrieve_question_embeddings(\n                    request_data.file_name,\n                    request_data.embedding_model,\n                    request_data.dimension,\n                    question,\n                )\n                e = time.perf_counter()\n                if already_embeddings:\n                    loggers['evaluation'].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n                    loggers['evaluation'].info(\"Embeddings already present in the database.\")  \n                    existing_embeddings.append(already_embeddings)\n            \n            loggers['evaluation'].info(f'Existing embeddings: {len(existing_embeddings)}')\n            if existing_embeddings and len(existing_embeddings) == len(questions):\n                return existing_embeddings\n\n            embedding_provider = None\n            for key, value in self.embeddings_provider_mapping.items():\n                if key == request_data.embedding_model:\n                    embedding_provider = value\n\n            embeddings = None\n            if embedding_provider == \"pinecone\":\n                embeddings =  await self._generate_pinecone_embedding(request_data, questions)\n                        \n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by pinecone.')\n                \n            elif embedding_provider == \"cohere\":\n                embeddings = await self._generate_cohere_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by cohere.')\n                \n            elif embedding_provider == \"jina\":\n                embeddings = await self._generate_jina_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by jina.')\n        \n            elif embedding_provider == \"voyage\":\n                embeddings = await self._generate_voyage_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by voyage.')\n                \n            for question, embedding in zip(questions, embeddings):\n                    query_embeddings = QueryEmbeddings(\n                        filename=request_data.file_name,\n                        embedding_model = request_data.embedding_model,\n                        dimension=request_data.dimension,\n                    )\n                    query_embeddings.add_question(question, embedding)\n                    result = await self.query_repository.insert_or_update_embeddings(query_embeddings)\n                    if result is None:\n                        loggers['evaluation'].error(\"Error inserting embeddings in motor\")\n                \n            if not len(embeddings) == len(questions):\n                loggers['main'].error(\"Error generating embeddings by pinecone\")\n                loggers[\"embedding\"].error(\"Error generating embeddings for questions: {questions}\")\n                \n            for question, embedding in zip(questions, embeddings):\n                self.validate_embedding(question, embedding, request_data.dimension)\n            \n            return embeddings\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error generating embedding: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function retrieves existing embeddings from a database or generates them using different embedding providers (Pinecone, Cohere, Jina, Voyage) based on the request's embedding model.  It then stores the generated embeddings in the database before returning them.\n",
        "size": 4086,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_dense_embedding"
    },
    {
        "id": "7134b366-a330-4aee-aaeb-a20347f7df6b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 306,
        "end_line": 319,
        "content": "async def _generate_pinecone_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Pinecone.\"\"\"\n    \n        pinecone_input = [{\"text\": question} for question in questions]\n        embeddings = await self.embedding_service.pinecone_dense_embeddings(\n            inputs=pinecone_input,\n            embedding_model=request_data.embedding_model,\n            dimension=request_data.dimension,\n            input_type=\"query\",\n        )\n        \n        return embeddings\nThis function is one of several within the `QueryUseCase` class that generate embeddings for questions using different embedding providers.  It specifically handles embedding generation using Pinecone.\n",
        "size": 740,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_pinecone_embedding"
    },
    {
        "id": "8b08b248-73b8-4ffb-a3e9-e8cebbeea4ce",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 321,
        "end_line": 331,
        "content": "async def _generate_cohere_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Cohere.\"\"\"\n        embeddings = await self.embedding_service.cohere_dense_embeddings(\n            texts=questions,\n            model_name=request_data.embedding_model,\n            input_type=\"search_query\",\n        )\n    \n        return embeddings\nThis function is one of several within a larger class (`QueryUseCase`) responsible for generating embeddings for queries using different embedding providers.  This specific function handles embedding generation using the Cohere API.\n",
        "size": 634,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_cohere_embedding"
    },
    {
        "id": "84abf0e5-a960-48b1-a5d3-33ae0c69c990",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 333,
        "end_line": 345,
        "content": "async def _generate_jina_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Jina.\"\"\"\n\n        embeddings = await self.embedding_service.jina_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"retrieval.query\",\n        )\n        \n        return embeddings\nThis function is one of several within a larger `QueryUseCase` class that generates embeddings for queries using different embedding providers.  This specific function handles embedding generation using the Jina embedding service.\n",
        "size": 681,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_jina_embedding"
    },
    {
        "id": "91462b9d-8f01-44cb-92ae-af97bbb7b88e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 347,
        "end_line": 357,
        "content": "async def _generate_voyage_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        embeddings = await self.embedding_service.voyageai_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"query\",\n        )\n\n        return embeddings\nThis function is one of several within a `QueryUseCase` class that generates embeddings for queries using different embedding providers.  Specifically, this function handles embedding generation using the VoyageAI provider.\n",
        "size": 615,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_voyage_embedding"
    },
    {
        "id": "ba0b78e8-df53-4e1c-8f13-52476d1a19bd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 359,
        "end_line": 381,
        "content": "async def _perform_hybrid_search(\n        self, request_data, namespace_name, host, dense_embedding, question\n    ):\n        \"\"\"Perform hybrid search using both dense and sparse embeddings.\"\"\"\n\n        try:\n            sparse_embedding = self.embedding_service.pinecone_sparse_embeddings(\n                inputs=[question]\n            )\n\n            return await self.pinecone_service.pinecone_hybrid_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                alpha=request_data.alpha,\n                query_vector_embeds=dense_embedding,\n                query_sparse_embeds=sparse_embedding[0],\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing hybrid search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk defines an asynchronous method `_perform_hybrid_search` within the `QueryUseCase` class.  It performs a hybrid search in Pinecone using both dense and sparse embeddings, handling exceptions and logging errors.\n",
        "size": 1164,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_hybrid_search"
    },
    {
        "id": "a05391bf-805e-4dfa-a9b3-d86c2c514a75",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 383,
        "end_line": 399,
        "content": "async def _perform_regular_search(\n        self, request_data, namespace_name, host, dense_embedding\n    ):\n        \"\"\"Perform regular dense vector search.\"\"\"\n\n        try:\n            return await self.pinecone_service.pinecone_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                vector=dense_embedding,\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing regular search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function `_perform_regular_search` is part of the `QueryUseCase` class and handles the execution of a regular dense vector search using the Pinecone service, a key component of the query processing pipeline.\n",
        "size": 873,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_regular_search"
    },
    {
        "id": "01a93301-31b8-47fa-a9ce-791efcde1d22",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 401,
        "end_line": 404,
        "content": "async def _get_ground_truth(self, query):\n        \"\"\"Fetch ground truth data for the query.\"\"\"\n\n        return await self.index_repository.fetch_ground_truth(query=query)\nThis function retrieves ground truth data from the index repository for a given query, used in evaluating search results.\n",
        "size": 293,
        "parent-class": "QueryUseCase",
        "function_name": "_get_ground_truth"
    },
    {
        "id": "6aff57ff-dd99-451c-84c2-1f1d512602f8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 406,
        "end_line": 450,
        "content": "def _calculate_evaluation_metrics(self, relevant_docs, ground_truth_ids, top_k):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n\n        try:\n            return {\n                \"precision_at_k\": EvaluationService.precision_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"recall_at_k\": EvaluationService.recall_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids, k=top_k\n                ),\n                \"bpref\": EvaluationService.bpref(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids\n                ),\n                \"mrr\": EvaluationService.reciprocal_rank(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids\n                ),\n                \"map\": EvaluationService.mean_average_precision(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k\n                ),\n            }\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error calculating evaluation metrics: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function calculates precision, recall, F1-score, hit rate, NDCG, bpref, MRR, and MAP evaluation metrics for a given set of retrieved documents and ground truth IDs, using helper functions from the `EvaluationService` class.  It's part of a larger query use case that evaluates the performance of a vector search.\n",
        "size": 2333,
        "parent-class": "QueryUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "64cf0a4b-6f6a-419e-9a3e-60060c496c55",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 452,
        "end_line": 504,
        "content": "def average_metrics(self, metrics_list, top_k):\n    \n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_k + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n        \n        avg_dict = sum_dict.copy()\n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    \n                    for sub_key, sub_value in value.items():\n                        sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    \n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] \n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key]\n        \n        return avg_dict\nThis function calculates the average of several evaluation metrics (precision, recall, F1-score, hit rate, NDCG, bpref, MRR, MAP) across multiple queries, handling both single-value and dictionary-valued metrics.  It's part of the `QueryUseCase` class and is called after individual question evaluations are complete.\n",
        "size": 2089,
        "parent-class": "QueryUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "ad4c84be-bbf3-4383-b5e9-a46075b0efff",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 506,
        "end_line": 515,
        "content": "def validate_embedding(self, question: str, embedding: list, expected_dim: int):\n        \"\"\"Check if embedding is valid; otherwise, log failure.\"\"\"\n        if embedding is None or not isinstance(embedding, list):\n            loggers[\"embedding\"].error(f\"Invalid embedding for question: {question}\")\n\n        elif len(embedding) != expected_dim:\n            loggers[\"embedding\"].error(f\"Invalid embedding dimension for question: {question}\")\n    \n        elif any(np.isnan(embedding)) or any(np.isinf(embedding)):\n            loggers[\"embedding\"].error(f\"Invalid embedding values for question: {question}\")\nThis function validates the generated embeddings, checking for null values, correct dimensionality, and the presence of NaN or infinite values, logging errors if any issues are found.\n",
        "size": 790,
        "parent-class": "QueryUseCase",
        "function_name": "validate_embedding"
    },
    {
        "id": "cd51a0ac-bb78-4766-bbee-6660b9ab62e4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 1,
        "end_line": 11,
        "content": "import asyncio\nimport json\nimport os\nfrom uuid import uuid4\nfrom fastapi import UploadFile, HTTPException, status\nimport aiofiles\nfrom app.config.settings import settings\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\nfrom app.utils.llm_utils import LLMUtils\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a FastAPI file upload use case class definition.\n",
        "size": 450,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "a7fa723d-e490-41d9-81cf-f4c7e73c1c82",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 14,
        "end_line": 17,
        "content": "def __init__(self):\n        self.raw_data_repo = RawDataRepo()\n        self.gt_data_repo = GTDataRepo()\n        self.llm_utils = LLMUtils()\nConstructor for the FileUploadUseCase class, initializing repositories and LLM utilities.\n",
        "size": 230,
        "parent-class": "FileUploadUseCase",
        "function_name": "__init__"
    },
    {
        "id": "c083bf19-0f4c-47dd-abce-fbd2399cfa3a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 19,
        "end_line": 25,
        "content": "async def store_file_locally(self, file: UploadFile):\n        os.makedirs(settings.UPLOAD_DIR, exist_ok=True)\n        file_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n        async with aiofiles.open(file_path, \"wb\") as f:\n            while chunk := await file.read(2 * 1024 * 1024):  # Read in 2MB chunks\n                await f.write(chunk)\n        return file_path\nThis chunk defines a method within the `FileUploadUseCase` class that stores an uploaded file locally, creating the directory if necessary, and writing the file in 2MB chunks.\n",
        "size": 570,
        "parent-class": "FileUploadUseCase",
        "function_name": "store_file_locally"
    },
    {
        "id": "5c7961f5-c253-4967-9f46-904474d6c30a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 27,
        "end_line": 39,
        "content": "async def process_and_enrich_json(self, file_path: str):\n        async with aiofiles.open(file_path, \"r\") as f:\n            content = await f.read()\n            data = json.loads(content)\n        if not isinstance(data, list):\n            raise ValueError(\"JSON data must be a list\")\n        enriched_data = []\n        for item in data:\n            item[\"_id\"] = str(uuid4())\n            enriched_data.append(item)\n        async with aiofiles.open(file_path, \"w\") as f:\n            await f.write(json.dumps(enriched_data))\n        return enriched_data\nThis function enriches a JSON file by adding a UUID `_id` field to each item in a list and overwrites the original file.  It's part of a larger file upload and processing use case.\n",
        "size": 733,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_and_enrich_json"
    },
    {
        "id": "12785bc5-7227-4f7c-810c-e066e9b58059",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 41,
        "end_line": 73,
        "content": "async def process_multi_chunk(self, data: dict):\n\n        loggers['main'].info(f\"length of data before : {len(data)}\")\n        chunks = [item for item in data[\"chunks\"] if item.get(\"text\", \"\").strip()]\n        loggers['main'].info(f\"length of data after : {len(chunks)}\")\n\n        chunk_data_for_llm = [\n            {\"text\": chunk[\"text\"], \"_id\": chunk[\"_id\"]} for chunk in data[\"chunks\"]\n        ]\n\n        response_json = await self.llm_utils.generate_multi_chunk_question(\n            {\"chunks\": chunk_data_for_llm, \"file_type\": data[\"file_type\"]}\n        )\n        # loggers['main'].info(f\"response_json from generate multi : {response_json}\")\n\n        if isinstance(response_json, str):\n            try:\n                response = json.loads(response_json)\n            except Exception as e:\n                raise ValueError(str(e))\n        else:\n            response = response_json\n\n        final_results = []\n        for question_item in response:\n            relevant_ids = question_item[\"relevant_ids\"]\n            relevant_chunks = [chunk for chunk in data[\"chunks\"] if str(chunk[\"_id\"]) in relevant_ids]\n            \n            final_results.append({\n                \"question\": question_item[\"question\"],\n                \"chunks\": relevant_chunks\n            })\n        return final_results\nThis function `process_multi_chunk` is part of a larger `FileUploadUseCase` class.  It takes a dictionary containing JSON data chunks, sends them to an LLM for question generation, and returns a list of questions with their corresponding relevant chunks.  It's called by `generate_multi_chunk_queries` which processes the data in batches.\n",
        "size": 1644,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_multi_chunk"
    },
    {
        "id": "a7aa5a76-c8af-4a03-baa3-e67fc7cbd352",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 75,
        "end_line": 92,
        "content": "async def generate_multi_chunk_queries(self, data):\n        dataset = []\n        tasks = []\n        for i in range(\n            0,\n            min(len(data[\"chunks_with_metadata\"]), settings.NO_OF_CHUNKS_AT_A_TIME*settings.MULTI_CHUNK_QUERIES_COUNT),\n            settings.NO_OF_CHUNKS_AT_A_TIME\n        ):\n\n            selected_items = data[\"chunks_with_metadata\"][i:i+settings.NO_OF_CHUNKS_AT_A_TIME]\n            task = self.process_multi_chunk({\"chunks\": selected_items, \"file_type\": data[\"file_type\"]})\n            tasks.append(task)\n        \n        results = await asyncio.gather(*tasks)\n        for result in results:\n            dataset.extend(result)\n        loggers['main'].info(f\"length of results in generate multi : {len(results)}\")\n        return dataset\nThis function `generate_multi_chunk_queries` processes a list of data chunks, dividing them into smaller batches to generate LLM-based queries concurrently using `asyncio.gather`.  The results are then combined and returned.  It's part of a larger file upload and processing pipeline.\n",
        "size": 1053,
        "parent-class": "FileUploadUseCase",
        "function_name": "generate_multi_chunk_queries"
    },
    {
        "id": "85c5be4c-af34-4de8-a3fa-fee6fdc783ce",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 94,
        "end_line": 171,
        "content": "async def execute(self, request_data):\n        try:\n\n            # File Store\n            file = request_data.get(\"input_data\")\n            file_name = request_data.get(\"file_name\")\n            file_type = request_data.get(\"file_type\")\n\n            if not isinstance(file_name, str):\n                raise ValueError(\"File name must be a string\")\n            _, file_extension = os.path.splitext(file_name)\n            if file_extension.lower() != \".json\":\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file is not in .json format\")\n\n            file_path = await self.store_file_locally(file)\n\n            existing_gt_data = await self.gt_data_repo.is_exist(file_name, file_type)\n            \n            if existing_gt_data:\n                doc = await self.raw_data_repo.is_exist(file_name, file_type)\n                doc = doc[\"data\"][0]\n                file_schema = {key: type(value).__name__ for key, value in doc.items() if key != \"_id\"}\n                if \"text\" not in file_schema.keys():\n                    raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n                \n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_gt_data.get(\"data\", []), default=str))\n                \n                existing_raw_data = await self.raw_data_repo.is_exist(file_name, file_type)\n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_raw_data.get(\"data\", []), default=str))\n                return {\"data\": \"File already processed\", \"file_schema\": json.dumps(file_schema)}\n            \n            enriched_data = await self.process_and_enrich_json(file_path)\n\n            loggers['main'].info(f\"length of data before : {len(enriched_data)}\")\n            enriched_data = [item for item in enriched_data if item.get(\"text\", \"\").strip()]\n            loggers['main'].info(f\"length of data after : {len(enriched_data)}\")\n\n            file_schema = {key: type(value).__name__ for key, value in enriched_data[0].items() if key != \"_id\"}\n            if \"text\" not in list(file_schema.keys()):\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n            \n            # Generate Queries\n            multi_chunk_dataset = await self.generate_multi_chunk_queries(\n                {\"chunks_with_metadata\": enriched_data, \"file_type\": file_type}\n            )\n            loggers[\"main\"].info(f\"length of multi chunk dataset : {len(multi_chunk_dataset)}\")\n            raw_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": enriched_data\n            }\n            await self.raw_data_repo.insert_documents(raw_data_document)\n\n            gt_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": [\n                    item.copy() for item in multi_chunk_dataset\n                ]\n            }\n            # loggers[\"main\"].info(f\"gt_data_document{gt_data_document}\")\n            try:\n                await self.gt_data_repo.insert_documents(gt_data_document)\n            except Exception as e:\n                loggers['main'].error(f\"documents were not inserted in mongodb , length of gt: {len(gt_data_document.get('data', []))}\")\n\n            dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n            async with aiofiles.open(dataset_path, \"w\") as f:\n                await f.write(json.dumps(multi_chunk_dataset))\n\n            return {\"data\": \"File processed and dataset generated successfully\", \"file_schema\": json.dumps(file_schema)}\n        except Exception as e:\n            loggers['main'].error(f\"file upload usecase outermost code breaks : {str(e)}\")\n            raise Exception(str(e))\nThis chunk contains the `execute` method of the `FileUploadUseCase` class, which handles the main logic of file upload, processing, and data storage.\n",
        "size": 4302,
        "parent-class": "FileUploadUseCase",
        "function_name": "execute"
    },
    {
        "id": "f5322a29-8df5-4d57-bead-5df1f3f9e2a2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi import Depends, HTTPException, status\nfrom app.models.domain.indexupsert import IndexUpsert, Namespace\nfrom app.repositories.index_upsert_repository import IndexUpsertRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.utils.logging_util import loggers\nimport time\nImport statements at the beginning of the `IndexUpsertUseCase` class definition.\n",
        "size": 523,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ec90cc51-bfd0-4c84-8bc8-7e07b6ff12df",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 17,
        "end_line": 49,
        "content": "def __init__(\n        self,\n        index_upsert_repository=Depends(IndexUpsertRepository),\n        pinecone_service=Depends(PineconeService),\n        embedding_service=Depends(EmbeddingService),\n    ):\n        self.index_upsert_repository = index_upsert_repository\n        self.pinecone_service = pinecone_service\n        self.embedding_service = embedding_service\n        self.file_path = \"uploads/raw_dataset.json\"\n        self.chunk_size = 90\n        self.semaphore = asyncio.Semaphore(3)\n        self.upsert_batch_size = 50\n        self.model_provider = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"jina-clip-v2\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\nConstructor for the `IndexUpsertUseCase` class, initializing dependencies and setting class variables including file path, chunk size, semaphore, upsert batch size, and a dictionary mapping embedding models to their providers.\n",
        "size": 1596,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "__init__"
    },
    {
        "id": "2272c99b-396d-4f01-9bef-6fa8b9f55642",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 51,
        "end_line": 76,
        "content": "async def process_chunk(self, chunk, provider, embed_model, dimension=None):\n        async with self.semaphore:\n            try:\n                if provider == \"pinecone\":\n                    return (\n                        await self.embedding_service.pinecone_dense_embeddings(\n                            chunk, embed_model, dimension=dimension\n                        )\n                    )\n                elif provider == \"cohere\":\n                    return await self.embedding_service.cohere_dense_embeddings(\n                        embed_model, chunk\n                    )\n                elif provider == \"jina\":\n                    return await self.embedding_service.jina_dense_embeddings(\n                        embed_model, dimension, chunk, \"retrieval.passage\"\n                    )\n                elif provider == \"voyage\":\n                    return await self.embedding_service.voyageai_dense_embeddings(\n                        embed_model, dimension, chunk\n                    )\n            except Exception as e:\n                loggers[\"main\"].error(\n                    f\"Error processing chunk with {provider} provider: {str(e)}\"\n                )\n                raise HTTPException(status_code=500, detail=str(e))\nThis function `process_chunk` handles the embedding generation for a given chunk of data using different embedding providers (Pinecone, Cohere, Jina, VoyageAI), using a semaphore to limit concurrent requests.  It's part of the `IndexUpsertUseCase` class which handles the overall process of upserting vectors to a Pinecone index.\n",
        "size": 1576,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "process_chunk"
    },
    {
        "id": "4f8be86f-e883-4103-a10a-22cef70b2ef0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 78,
        "end_line": 112,
        "content": "async def _get_embeddings(self, data, embed_model, dimension):\n        try:\n            all_embeddings = []\n            embedding_provider = self.model_provider.get(embed_model)\n\n            if embedding_provider == \"pinecone\":\n                inputs = [{\"text\": item[\"text\"]} for item in data]\n            elif embedding_provider == \"cohere\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"jina\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"voyage\":\n                inputs = [item.get(\"text\", item.get(\"code\")) for item in data]\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            chunks = [\n                inputs[i : i + self.chunk_size]\n                for i in range(0, len(inputs), self.chunk_size)\n            ]\n            tasks = [\n                self.process_chunk(\n                    chunk, embedding_provider, embed_model, dimension\n                )\n                for chunk in chunks\n            ]\n            chunk_results = await asyncio.gather(*tasks)\n\n            for embeddings in chunk_results:\n                all_embeddings.extend(embeddings)\n\n            return all_embeddings\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function `_get_embeddings` retrieves embeddings for a given dataset using different embedding providers (Pinecone, Cohere, Jina, VoyageAI) based on the specified embedding model, handling chunking and asynchronous processing to improve efficiency.  It's part of a larger `IndexUpsertUseCase` class responsible for upserting data into a Pinecone vector database.\n",
        "size": 1832,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_get_embeddings"
    },
    {
        "id": "72078002-89d1-4310-a18f-529792c11925",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 114,
        "end_line": 122,
        "content": "async def _upsert_batch(self, index_host, batch, namespace_name):\n        \"\"\"Helper function to upsert a single batch of vectors\"\"\"\n        try:\n            return await self.pinecone_service.upsert_vectors(\n                index_host, batch, namespace_name\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error upserting batch: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nHelper function within an asynchronous index upsert class; upserts a batch of vectors to Pinecone using PineconeService.\n",
        "size": 558,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_upsert_batch"
    },
    {
        "id": "0736076a-57fc-41a2-9ac5-ef8d68755672",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 124,
        "end_line": 167,
        "content": "async def _prepare_and_upsert(\n        self, data, embed_model, dimension, index_host, namespace_name\n    ):\n        try:\n            all_embeddings = await self._get_embeddings(\n                data, embed_model, dimension\n            )\n\n            text_list = [item[\"text\"] for item in data]\n            sparse_embeds = self.embedding_service.pinecone_sparse_embeddings(\n                text_list\n            )\n            final_upsert_format = await self.pinecone_service.upsert_format(\n                data, all_embeddings, sparse_embeds\n            )\n\n            batches = [\n                final_upsert_format[i : i + self.upsert_batch_size]\n                for i in range(0, len(final_upsert_format), self.upsert_batch_size)\n            ]\n\n            loggers[\"main\"].info(f\"Upserting {len(final_upsert_format)} vectors in {len(batches)} batches\")\n\n            upsert_tasks = [\n                self._upsert_batch(index_host, batch, namespace_name)\n                for batch in batches\n            ]\n            \n            # Gather results from all batches\n            batch_results = await asyncio.gather(*upsert_tasks)\n            \n            # Combine results\n            total_upserted = sum(result.get(\"upserted_count\", 0) for result in batch_results)\n            time.sleep(15)\n            return {\n                \"upserted_count\": total_upserted,\n                \"batches_processed\": len(batches),\n                \"batch_results\": batch_results\n            }\n\n    \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in preparing and upserting vectors : {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function prepares and upserts vector embeddings to a Pinecone index in batches, handling potential errors and logging relevant information.  It's part of an `IndexUpsertUseCase` class that manages the entire process of indexing data.\n",
        "size": 1908,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_prepare_and_upsert"
    },
    {
        "id": "17e2aeaa-5773-422c-969a-691dc03d9292",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 169,
        "end_line": 196,
        "content": "async def _save_in_db(\n        self,\n        file_name,\n        embed_model,\n        index_name,\n        index_host,\n        dimension,\n        similarity_metric,\n    ):\n        namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n        namespace = Namespace(\n            name=namespace_name, filename=file_name, embedding_model=embed_model\n        )\n\n        index_upsert = IndexUpsert(\n            index_name=index_name,\n            index_host=index_host,\n            dimension=dimension,\n            similarity_metric=similarity_metric,\n        )\n\n        index_upsert.add_namespace(namespace)\n        return (\n            await self.index_upsert_repository.add_index_upsert_details(\n                index_upsert\n            ),\n        )\nThis function saves index metadata (index name, host, dimension, similarity metric, filename, embedding model) to a database after a successful upsert operation.\n",
        "size": 909,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_save_in_db"
    },
    {
        "id": "d812918e-5dfa-41ee-83ea-abcc9f8180da",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 198,
        "end_line": 300,
        "content": "async def index_upsert(self, request):\n        try:\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            embed_model = request.embed_model\n\n            already_upserted = (\n                await self.index_upsert_repository.find_matching_index_upsert(\n                    dimension, similarity_metric, file_name, embed_model\n                )\n            )\n\n            if already_upserted:\n                return {\n                    \"message\": \"such dimension, similarity metric, filename and embed_model configuration already exists, move on to query\"\n                }\n\n            with open(self.file_path, \"r\") as file:\n                data = json.load(file)\n\n            loggers[\"main\"].info(f\"length of data before : {len(data)}\")\n            data = [item for item in data if item.get(\"text\", \"\").strip()]\n            loggers[\"main\"].info(f\"length of data after : {len(data)}\")\n\n\n\n            already_index = (\n                await self.index_upsert_repository.find_matching_index(\n                    dimension, similarity_metric\n                )\n            )\n\n            if not already_index:\n                index_json = await self.pinecone_service.list_pinecone_indexes()\n                index_list = index_json.get(\"indexes\")\n                index_names = [index[\"name\"] for index in index_json[\"indexes\"]]\n                if(len(index_list) >= 5):\n                    loggers[\"main\"].error(f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n                    raise HTTPException(status_code= status.HTTP_403_FORBIDDEN, detail = f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n\n                loggers[\"main\"].info(f\"already index {already_index}\")\n                loggers[\"main\"].info(f\"index list {index_json}\")\n\n\n                index_name = f\"{similarity_metric}-{dimension}\"\n                response = await self.pinecone_service.create_index(\n                    index_name, dimension, similarity_metric\n                )\n                index_host = response.get(\"host\")\n\n                namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n                upsert_result = await self._prepare_and_upsert(\n                    data, embed_model, dimension, index_host, namespace_name\n                )\n\n                db_result = await self._save_in_db(\n                    file_name,\n                    embed_model,\n                    index_name,\n                    index_host,\n                    dimension,\n                    similarity_metric,\n                )\n\n                return {\n                    \"upsert_result\": upsert_result,\n                    \"database_result\": db_result,\n                }\n\n            index_name = already_index.get(\"index_name\")\n            index_host = already_index.get(\"index_host\")\n\n            index_json = await self.pinecone_service.list_pinecone_indexes()\n            index_list = index_json.get(\"indexes\")\n            loggers[\"main\"].info(f\"length of index list : {len(index_list)}\")\n\n            loggers[\"main\"].info(f\"already index outside if{already_index}\")\n            loggers[\"main\"].info(f\"index list outside if {index_list}\")\n\n            namespace_name = f\"{file_name}-{embed_model}-namespace\"\n            upsert_result = await self._prepare_and_upsert(\n                data, embed_model, dimension, index_host, namespace_name\n            )\n\n            db_result = await self._save_in_db(\n                file_name,\n                embed_model,\n                index_name,\n                index_host,\n                dimension,\n                similarity_metric,\n            )\n\n            return {\n                \"upsert_result\": upsert_result,\n                \"database_result\": db_result,\n            }\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in index upsert {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk contains the `index_upsert` method, the main function of the `IndexUpsertUseCase` class, which handles the logic for upserting vectors into a Pinecone index and saving metadata to a database.  It checks for existing indexes and configurations before processing data.\n",
        "size": 4364,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "index_upsert"
    },
    {
        "id": "72c5b1dd-3be2-4ae1-be98-b620e50f5e19",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.repositories.index_repository import IndexRepository\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a FastAPI-based use case class definition.\n",
        "size": 355,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "866a9a79-b8fd-49a7-95d3-a7c35176eb05",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 10,
        "end_line": 52,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(), \n    ):\n        self.index_repository = index_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\nConstructor for `RandomQueryUseCase` class, initializing dependencies and mapping embedding models to providers and dimensions.\n",
        "size": 1999,
        "parent-class": "RandomQueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "54c44239-370c-48a7-aa9f-f59a062964c4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 55,
        "end_line": 78,
        "content": "async def _get_namespace_and_host(self, similarity_metric, dimension, embedding_model, file_name):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{similarity_metric}-{dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    embedding_model,\n                    file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers[\"main\"].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function retrieves the Pinecone index namespace and host based on similarity metric, dimension, embedding model, and filename, raising HTTP exceptions for errors or missing data.\n",
        "size": 1122,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "ddb47650-e222-4e9e-b396-1e62fa4d5173",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 81,
        "end_line": 119,
        "content": "async def _get_query_embeddings(self, query, embed_model, dimension):\n        try:\n            embedding_provider = self.embeddings_provider_mapping.get(embed_model)\n            if embedding_provider == \"pinecone\":\n\n                pinecone_input = [{\"text\": query}]\n                embeddings =  await self.embedding_service.pinecone_dense_embeddings(\n                    pinecone_input, embed_model, dimension=dimension,input_type=\"query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"cohere\":\n                cohere_input = [query]\n                embeddings = await self.embedding_service.cohere_dense_embeddings(\n                    cohere_input, embed_model, input_type=\"search_query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"jina\":\n                jina_input = [query]\n                embeddings = await self.embedding_service.jina_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = jina_input, input_type = \"retrieval.query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"voyage\":\n                voyage_input = [query]\n                embeddings = await self.embedding_service.voyageai_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = voyage_input, input_type = \"query\"\n                )\n                return embeddings[0]\n\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function retrieves query embeddings using different embedding providers (Pinecone, Cohere, Jina, VoyageAI) based on the specified embedding model.  It's part of a larger use case for performing vector searches.\n",
        "size": 2019,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_query_embeddings"
    },
    {
        "id": "4d0fb58c-5239-4e1b-bf5d-96fa10af387f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 122,
        "end_line": 166,
        "content": "async def random_query(self, request):\n        try:\n            query = request.query\n            embed_model = request.embedding_model\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            top_k = request.top_k\n            include_metadata = request.include_metadata\n            namespace, host = await self._get_namespace_and_host(similarity_metric, dimension, embed_model,file_name)\n        \n           \n            query_dense_vector = await self._get_query_embeddings(query, embed_model, dimension)\n            \n            if request.is_hybrid:\n                query_sparse_vector = self.embedding_service.pinecone_sparse_embeddings([query])\n                query_sparse_vector = query_sparse_vector[0]\n                alpha = request.alpha\n                loggers[\"main\"].info(\"sparse embeddings generated in random query use case\")\n                pinecone_response = await self.pinecone_service.pinecone_hybrid_query(\n                    host, namespace, top_k, alpha, query_dense_vector, query_sparse_vector, include_metadata\n                )\n            else:\n                pinecone_response = await self.pinecone_service.pinecone_query(\n                    host, namespace, top_k, query_dense_vector, include_metadata\n                )\n            \n            matches = pinecone_response.get(\"matches\", [])\n            final_responses = []\n            for match in matches:\n                score = match.get(\"score\", None)\n                id = match.get(\"id\", None)\n                text = match.get(\"metadata\", None).get(\"text\", None)\n                metadata = {key: value for key, value in match.get(\"metadata\").items() if key != \"text\"}\n                final_responses.append({\n                    \"id\": id,\n                    \"score\": score,\n                    \"text\": text,\n                    \"metadata\": metadata\n                })\n            return final_responses\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in random_query_usecase: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\nThis chunk contains the `random_query` method of the `RandomQueryUseCase` class.  This method handles querying a Pinecone index (potentially hybrid) based on user request parameters, retrieves results, and formats them for return.\n",
        "size": 2439,
        "parent-class": "RandomQueryUseCase",
        "function_name": "random_query"
    },
    {
        "id": "40cf2338-f7b9-40d4-96de-99c80d7bcfc8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\nImport statements for FastAPI dependencies and data repositories used in a RandomQuestionUseCase class.\n",
        "size": 263,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "27bafe88-561b-42de-8c0a-d26bc4557a40",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 9,
        "end_line": 15,
        "content": "def __init__(\n        self, \n        gt_data_repo: GTDataRepo = Depends(),\n        raw_data_repo: RawDataRepo = Depends(),\n    ):\n        self.gt_data_repo = gt_data_repo\n        self.raw_data_repo = raw_data_repo\nConstructor for the RandomQuestionUseCase class, injecting dependencies for data repositories.\n",
        "size": 309,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "__init__"
    },
    {
        "id": "c274acaa-f74e-41cd-a6e8-951831995dee",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 17,
        "end_line": 28,
        "content": "async def random_question(self, file_name):\n        try:\n            question_with_groundtruth, ids = await self.gt_data_repo.get_random_question(file_name)\n           \n            text_content = await self.raw_data_repo.fetch_texts_by_ids(file_name,ids)\n            \n            for i in range(len(ids)):\n                question_with_groundtruth[\"chunks\"][i][\"text\"] = text_content[i]\n               \n            return question_with_groundtruth\n        except Exception as e:\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n`RandomQuestionUseCase` class method that retrieves a random question and its associated text content from repositories, handling exceptions with HTTP 500 error.\n",
        "size": 739,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "random_question"
    },
    {
        "id": "4dcfa889-805b-44ad-aca3-20b1e4be9e83",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict\nimport httpx\nfrom fastapi import HTTPException\nfrom pinecone import Pinecone\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Pinecone service class definition.\n",
        "size": 334,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "a25e4d8a-3e9d-461c-bbb0-5f837b2a9486",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 16,
        "end_line": 31,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.api_version = settings.PINECONE_API_VERSION\n        self.index_url = settings.PINECONE_CREATE_INDEX_URL\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.upsert_url = settings.PINECONE_UPSERT_URL\n        self.query_url = settings.PINECONE_QUERY_URL\n        self.list_index_url = settings.PINECONE_LIST_INDEXES_URL\n        self.semaphore = asyncio.Semaphore(10)\n        self.pc = Pinecone(api_key=settings.PINECONE_API_KEY)\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\nConstructor for the PineconeService class, initializing Pinecone API credentials, URLs, a semaphore for concurrency control, a Pinecone client object, and an HTTP request timeout.\n",
        "size": 1059,
        "parent-class": "PineconeService",
        "function_name": "__init__"
    },
    {
        "id": "4dfe6e78-8c22-43a0-b233-4b0ad7e04d42",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 33,
        "end_line": 53,
        "content": "async def list_pinecone_indexes(self):\n        url = self.list_index_url\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url, headers=headers)\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n\n            loggers[\"main\"].error(f\"Error creating index: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk defines an asynchronous method `list_pinecone_indexes` within the `PineconeService` class, which retrieves a list of Pinecone indexes using the Pinecone API.  It handles HTTP errors and other exceptions.\n",
        "size": 998,
        "parent-class": "PineconeService",
        "function_name": "list_pinecone_indexes"
    },
    {
        "id": "a54cdf4f-a742-4c0b-b335-36dbefece903",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 55,
        "end_line": 118,
        "content": "async def create_index(\n        self, index_name: str, dimension: int, metric: str\n    ) -> Dict[str, Any]:\n        if self.pc.has_index(index_name) == False:\n            index_data = {\n                \"name\": index_name,\n                \"dimension\": dimension,\n                \"metric\": metric,\n                \"spec\": {\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}},\n            }\n\n            headers = {\n                \"Accept\": \"application/json\",\n                \"Content-Type\": \"application/json\",\n                \"Api-Key\": self.pinecone_api_key,\n                \"X-Pinecone-API-Version\": self.api_version,\n            }\n\n            try:\n                async with httpx.AsyncClient() as client:\n                    response = await client.post(\n                        self.index_url, headers=headers, json=index_data\n                    )\n                    response.raise_for_status()\n\n                    retry_count = 0\n                    max_retries = 30\n                    while retry_count < max_retries:\n                        status = (\n                            self.pc.describe_index(index_name)\n                            .get(\"status\")\n                            .get(\"state\")\n                        )\n                        loggers[\"main\"].info(f\"Index status: {status}\")\n\n                        if status == \"Ready\":\n                            loggers[\"main\"].info(f\"Index {index_name} is ready\")\n                            break\n\n                        retry_count += 1\n                        time.sleep(2)\n\n                    if retry_count > max_retries:\n                        raise HTTPException(\n                            status_code=500, detail=\"Index creation timed out\"\n                        )\n\n                    loggers[\"main\"].info(\"Index Created\")\n                    return response.json()\n\n            except httpx.HTTPStatusError as e:\n                parsed_response = json.loads(response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\n                    \"message\", \"Unknown error occurred\"\n                )\n                loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            except Exception as e:\n                loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        else:\n            loggers[\"main\"].info(\"index already created\")\n            return {\"host\": self.pc.describe_index(index_name).get(\"host\")}\nThis chunk defines an asynchronous method `create_index` within the `PineconeService` class.  It handles creating a Pinecone index, checking its status, and returning the index host.  It includes error handling and checks for pre-existing indexes.\n",
        "size": 2859,
        "parent-class": "PineconeService",
        "function_name": "create_index"
    },
    {
        "id": "03f25471-041a-43e8-86f6-359b92469219",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 120,
        "end_line": 138,
        "content": "async def upsert_format(\n        self, chunks: list, vector_embeddings: list, sparse_embeddings: list\n    ):\n        results = []\n        for i in range(len(chunks)):\n            metadata = {key: value for key, value in chunks[i].items() if key != \"_id\"}\n\n            metadata[\"created_at\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            result = {\n                \"id\": chunks[i][\"_id\"],\n                \"values\": vector_embeddings[i],\n                \"metadata\": metadata,\n                \"sparse_values\": {\n                    \"indices\": sparse_embeddings[i][\"indices\"],\n                    \"values\": sparse_embeddings[i][\"values\"],\n                },\n            }\n            results.append(result)\n        return results\nThis function formats data for upserting into a Pinecone index, combining dense and sparse embeddings with metadata.\n",
        "size": 856,
        "parent-class": "PineconeService",
        "function_name": "upsert_format"
    },
    {
        "id": "97ba0524-e7c3-46f1-9b78-3a8f5554df35",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 140,
        "end_line": 169,
        "content": "async def upsert_vectors(self, index_host, input, namespace):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        url = self.upsert_url.format(index_host)\n\n        payload = {\"vectors\": input, \"namespace\": namespace}\n        try:\n            async with httpx.AsyncClient(timeout= self.timeout) as client:\n                response = await client.post(\n                    url=url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors http status error : {str(e)} - {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)    \n        \n        except httpx.HTTPError as e:    \n            loggers[\"main\"].error(f\"Error in upsert vectors http error : {str(e)}\")\n            raise HTTPException(status_code=400, detail=str(e))\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors : {str(e)} \")\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk defines an asynchronous method `upsert_vectors` within the `PineconeService` class, responsible for upserting vectors to a Pinecone index using the httpx library.  It handles HTTP errors and other exceptions, logging errors and raising appropriate HTTPExceptions.\n",
        "size": 1524,
        "parent-class": "PineconeService",
        "function_name": "upsert_vectors"
    },
    {
        "id": "0b8589a5-806a-4c64-b8ef-e86ef2390f3e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 171,
        "end_line": 181,
        "content": "def hybrid_scale(self, dense, sparse, alpha: float):\n\n        if alpha < 0 or alpha > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        # scale sparse and dense vectors to create hybrid search vecs\n        hsparse = {\n            \"indices\": sparse[\"indices\"],\n            \"values\": [v * (1 - alpha) for v in sparse[\"values\"]],\n        }\n        hdense = [v * alpha for v in dense]\n        return hdense, hsparse\nHelper function within a PineconeService class; scales dense and sparse vectors to create hybrid search vectors for hybrid search queries.\n",
        "size": 574,
        "parent-class": "PineconeService",
        "function_name": "hybrid_scale"
    },
    {
        "id": "2683f5bd-6131-4359-8e61-41682d8b3c40",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 183,
        "end_line": 247,
        "content": "async def pinecone_hybrid_query(\n        self,\n        index_host,\n        namespace,\n        top_k,\n        alpha: int,\n        query_vector_embeds: list,\n        query_sparse_embeds: dict,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        if query_vector_embeds is None or query_sparse_embeds is None:\n            time.sleep(2)\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        hdense, hsparse = self.hybrid_scale(\n            query_vector_embeds, query_sparse_embeds, alpha\n        )\n\n        payload = {\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n            \"vector\": hdense, \n            \"sparseVector\": {\n                \"indices\": hsparse.get(\n                    \"indices\"\n                ),  \n                \"values\": hsparse.get(\n                    \"values\"\n                ),  \n            },\n            \"topK\": top_k,\n            \"namespace\": namespace,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone hybrid query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error performing hybrid query: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk defines an asynchronous function `pinecone_hybrid_query` within a PineconeService class, which performs a hybrid query (combining dense and sparse vectors) against a Pinecone index.\n",
        "size": 2541,
        "parent-class": "PineconeService",
        "function_name": "pinecone_hybrid_query"
    },
    {
        "id": "4de4949d-3e37-4656-9fae-e2a3b15ff737",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 249,
        "end_line": 297,
        "content": "async def pinecone_query(\n        self,\n        index_host: str,\n        namespace: str,\n        top_k: int,\n        vector: list,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        payload = {\n            \"namespace\": namespace,\n            \"vector\": vector,\n            # \"filter\": filter_dict,\n            \"topK\": top_k,\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone Normal query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis chunk defines an asynchronous function `pinecone_query` within a `PineconeService` class, responsible for querying a Pinecone index using a given vector and returning the results.  It handles HTTP errors and exceptions.\n",
        "size": 2040,
        "parent-class": "PineconeService",
        "function_name": "pinecone_query"
    },
    {
        "id": "9f5b8bc0-e61a-4604-8f69-0f816354d49a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nimport pickle\nimport httpx\nfrom fastapi import HTTPException, status\nfrom pinecone_text.sparse import BM25Encoder\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Python file defining an EmbeddingService class.\n",
        "size": 313,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "740d0274-65f2-46af-abb5-ee111dcbc90e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 18,
        "end_line": 38,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.pinecone_embedding_url = settings.PINECONE_EMBED_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.togetherai_api_key = settings.TOGETHERAI_API_KEY\n        self.voyageai_api_key = settings.VOYAGEAI_API_KEY\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.togetherai_base_url = settings.TOGETHERAI_BASE_URL\n        self.voyageai_base_url = settings.VOYAGEAI_BASE_URL\n        self.EMBED_SUFFIX = \"embed\"\n        self.JINA_EMBED_SUFFIX = \"embeddings\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=300.0,    # Time to read the response\n                        write=300.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\nConstructor for the `EmbeddingService` class, initializing API keys and URLs for various embedding providers.\n",
        "size": 1260,
        "parent-class": "EmbeddingService",
        "function_name": "__init__"
    },
    {
        "id": "7b4483de-5e40-43dc-9de5-34b0fb7761da",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 40,
        "end_line": 84,
        "content": "async def pinecone_dense_embeddings(\n        self,\n        inputs: list,\n        embedding_model: str = \"llama-text-embed-v2\",\n        input_type: str = \"passage\",\n        truncate: str = \"END\",\n        dimension: int = 1024,\n    ):\n        payload = {\n            \"model\": embedding_model,\n            \"parameters\": {\n                \"input_type\": input_type,\n                \"truncate\": truncate,\n                # \"dimension\": dimension,\n            },\n            \"inputs\": inputs,\n        }\n\n        if embedding_model != \"multilingual-e5-large\":\n            payload[\"parameters\"][\"dimension\"] = dimension \n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n        }\n\n        url = self.dense_embed_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"embeddings generated\")\n                response = response.json()\n                loggers[\"pinecone\"].info(f\"pinecone hosted embedding model tokens usage: {response['usage']}\")\n                list_result = [item[\"values\"] for item in response[\"data\"]]\n                return list_result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=f\"{str(e)}-{e.response.text}\")\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code snippet defines an asynchronous method `pinecone_dense_embeddings` within the `EmbeddingService` class.  This method generates dense embeddings using Pinecone's embedding API.\n",
        "size": 2000,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_dense_embeddings"
    },
    {
        "id": "1e3ce639-3084-4d4e-a9b2-2c739d795b13",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 86,
        "end_line": 93,
        "content": "def pinecone_sparse_embeddings(self, inputs):\n        try:\n            sparse_vector = bm25.encode_documents(inputs)\n            return sparse_vector\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating sparse embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis function `pinecone_sparse_embeddings` within the `EmbeddingService` class generates sparse embeddings using a pre-loaded BM25 encoder.\n",
        "size": 467,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_sparse_embeddings"
    },
    {
        "id": "1ea9e8fb-cea7-4929-90b0-43c62e239e8d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 95,
        "end_line": 137,
        "content": "async def cohere_dense_embeddings(\n        self,\n        model_name: str,\n        texts: list[str],\n        input_type: str = \"search_document\",\n    ):\n\n        url = f\"{self.cohere_base_url}/{self.EMBED_SUFFIX}\"\n\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.cohere_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"texts\": texts,\n            \"input_type\": input_type,\n            \"embedding_types\": [\"float\"],\n        }\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout,verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                # return response.json()\n                response = response.json()\n                loggers[\"cohere\"].info(f\"cohere hosted embedding model tokens usage: { response.get('meta', {}).get('billed_units', {})}\")\n                result = response[\"embeddings\"][\"float\"]\n                return result\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}-{e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense cohere embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code snippet defines an asynchronous method `cohere_dense_embeddings` within the `EmbeddingService` class, responsible for generating dense embeddings using the Cohere API.  It handles HTTP requests, error handling, and logging.\n",
        "size": 1994,
        "parent-class": "EmbeddingService",
        "function_name": "cohere_dense_embeddings"
    },
    {
        "id": "a66a3f46-3678-45b7-8b76-c8c0e5362c6a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 139,
        "end_line": 187,
        "content": "async def jina_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n\n        url = f\"{self.jina_base_url}/{self.JINA_EMBED_SUFFIX}\"\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"embedding_type\": \"float\",\n            \"input\": inputs,\n        }\n\n        if model_name == \"jina-embeddings-v3\":\n            data[\"task\"] = input_type\n            data[\"late_chunking\"] = False\n            data['dimensions'] = dimension\n        elif model_name == \"jina-embeddings-v2-base-code\":\n            data[\"normalized\"] = True\n        else:\n            data[\"normalized\"] = True\n            data['dimensions'] = dimension\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout, verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"jina\"].info(f\"jina hosted embedding model tokens usage: {response.get('usage', {})}\")\n                result = [item[\"embedding\"] for item in response[\"data\"]]\n                return result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.content} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}, {e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502,  # Bad Gateway (Failed to connect)\n                detail= f\"Failed to connect to API httpx Request error : {str(e)}\",\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense jina embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code snippet defines an asynchronous method `jina_dense_embeddings` within the `EmbeddingService` class, which uses the Jina API to generate dense embeddings for given input texts.  It handles different Jina model versions and includes robust error handling.\n",
        "size": 2333,
        "parent-class": "EmbeddingService",
        "function_name": "jina_dense_embeddings"
    },
    {
        "id": "adebbe7f-f140-428d-a81c-8a5754eeb167",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 189,
        "end_line": 219,
        "content": "async def togetherai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n        url = f\"{self.togetherai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        headers = {\n            \"accept\": \"application/json\",\n            \"authorization\": f\"Bearer {self.togetherai_api_key}\",\n            \"content-type\": \"application/json\"\n        }\n        payload = {\n            \"model\": model_name,\n            \"input\": inputs\n        }\n\n        try:\n            async with httpx.AsyncClient(verify = False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error:{str(e)} {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx : {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in togetherai_dense_embedding: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured : {str(e)}\")\nThis chunk defines an asynchronous method `togetherai_dense_embeddings` within the `EmbeddingService` class, responsible for generating dense embeddings using the TogetherAI API.  It handles HTTP requests, error handling, and logging.\n",
        "size": 1765,
        "parent-class": "EmbeddingService",
        "function_name": "togetherai_dense_embeddings"
    },
    {
        "id": "daf8ae70-86b0-48f8-869c-0c257c711d42",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 223,
        "end_line": 263,
        "content": "async def voyageai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list, input_type: str = \"document\"\n    ):\n        url = f\"{self.voyageai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.voyageai_api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        data = {\n            \"input\": inputs,\n            \"model\": model_name,\n            \"input_type\": input_type,\n            \"output_dimension\": dimension\n        }\n\n        try:\n\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"voyage\"].info(f\"Embedding model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                embedding_list = [item[\"embedding\"] for item in response[\"data\"]]\n                return embedding_list\n            \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {e.response.text}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error occurred in httpx status error  : {str(e)} - {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx voyage dense embed: {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in voyageai_dense_embedding: {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured in voyageai_dense_embedding: {str(e)}, \")\nThis code chunk defines an asynchronous function `voyageai_dense_embeddings` within an `EmbeddingService` class, responsible for generating dense embeddings using the VoyageAI API.  It handles HTTP requests, error handling, and logging.\n",
        "size": 2470,
        "parent-class": "EmbeddingService",
        "function_name": "voyageai_dense_embeddings"
    },
    {
        "id": "a00df34d-0c87-48a5-9767-f798868ab2ab",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import math\nimport logging\nfrom typing import Dict, List\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Python class definition for an EvaluationService.\n",
        "size": 190,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "108ad3df-4994-4f1a-8b9f-cd7d11a0737d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 10,
        "end_line": 45,
        "content": "def _discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Discounted Cumulative Gain (DCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            retrieved_texts = [doc[\"id\"] for doc in retrieved_docs[:k]]\n            relevance_scores = [\n                1 if doc in ground_truth else 0 for doc in retrieved_texts\n            ]\n\n            if not relevance_scores:\n                return 0.0\n\n            dcg_at_k = relevance_scores[0] if relevance_scores else 0\n            for i in range(1, len(relevance_scores)):\n                dcg_at_k += relevance_scores[i] / math.log2(i + 1)\n\n            return dcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis code snippet is a static method within the `EvaluationService` class that calculates Discounted Cumulative Gain (DCG)@K, a metric for evaluating ranked retrieval results.  It's part of a larger class containing other information retrieval evaluation metrics.\n",
        "size": 1555,
        "parent-class": "EvaluationService",
        "function_name": "_discounted_cumulative_gain_at_k"
    },
    {
        "id": "7efdb102-a312-451e-b7f2-aceff2f3930e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 48,
        "end_line": 78,
        "content": "def _ideal_discounted_cumulative_gain_at_k(\n        ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Ideal Discounted Cumulative Gain (IDCG) @ K.\n        \"\"\"\n        try:\n            if not isinstance(ground_truth, list) or not isinstance(k, int):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ideal_relevance_scores = [1] * min(len(ground_truth), k)\n\n            if not ideal_relevance_scores:\n                return 0.0\n\n            idcg_at_k = (\n                ideal_relevance_scores[0] if ideal_relevance_scores else 0\n            )\n            for i in range(1, len(ideal_relevance_scores)):\n                idcg_at_k += ideal_relevance_scores[i] / math.log2(i + 1)\n\n            return idcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in ideal_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis code snippet defines a static method `_ideal_discounted_cumulative_gain_at_k` within the `EvaluationService` class, which calculates the Ideal Discounted Cumulative Gain (IDCG) at a given rank k for information retrieval evaluation.  It's used as a helper function for NDCG calculation.\n",
        "size": 1398,
        "parent-class": "EvaluationService",
        "function_name": "_ideal_discounted_cumulative_gain_at_k"
    },
    {
        "id": "d682716e-d88f-44a1-9df6-81a8d3fb4997",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 81,
        "end_line": 119,
        "content": "def normalized_discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Normalized Discounted Cumulative Gain (NDCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ndcg_at_k = {}\n            for i in range(k):\n                dcg_at_i = EvaluationService._discounted_cumulative_gain_at_k(\n                    retrieved_docs, ground_truth, i + 1\n                )\n                idcg_at_i = (\n                    EvaluationService._ideal_discounted_cumulative_gain_at_k(\n                        ground_truth, i + 1\n                    )\n                )\n                ndcg_at_i = dcg_at_i / idcg_at_i if idcg_at_i > 0 else 0.0\n\n                ndcg_at_k[f\"NDCG@{i+1}\"] = ndcg_at_i\n\n            loggers['evaluation'].info(f\"NDCG Result: {ndcg_at_k}\")\n            return ndcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in normalized_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis code snippet defines a static method `normalized_discounted_cumulative_gain_at_k` within the `EvaluationService` class, calculating Normalized Discounted Cumulative Gain (NDCG)@K for information retrieval evaluation.  It uses helper methods to compute DCG@K and IDCG@K.\n",
        "size": 1749,
        "parent-class": "EvaluationService",
        "function_name": "normalized_discounted_cumulative_gain_at_k"
    },
    {
        "id": "f012101c-3c00-4ec2-a57f-3c1b7dd4215a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 122,
        "end_line": 153,
        "content": "def bpref(retrieved_docs: List[Dict], ground_truth: List[str]) -> float:\n        \"\"\"\n        Computes BPREF (Binary Preference).\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            relevant_docs = set(ground_truth)\n            irrelevant_count = 0\n            total_relevant = len(relevant_docs)\n            bpref_score = 0.0\n\n            if total_relevant == 0:\n                return 0.0\n\n            for doc in retrieved_docs:\n                if doc[\"id\"] in relevant_docs:\n                    bpref_score += 1 - (min(irrelevant_count, total_relevant) / total_relevant)\n                else:\n                    irrelevant_count += 1\n\n            loggers['evaluation'].info(f\"BPREF Result: {bpref_score / total_relevant}\")\n            return bpref_score / total_relevant\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in bpref: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis chunk defines a static method `bpref` within the `EvaluationService` class, calculating the BPREF (Binary Preference) metric for information retrieval evaluation.  It's one of several methods in the class that compute different evaluation metrics.\n",
        "size": 1405,
        "parent-class": "EvaluationService",
        "function_name": "bpref"
    },
    {
        "id": "33f962b7-6dd1-492f-9314-02670a4c5e43",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 156,
        "end_line": 201,
        "content": "def precision_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Precision@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Precision@k' to precision scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            precision_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision_results[f\"Precision@{k}\"] = (\n                    round(matches / float(k), 2) if k > 0 else 0.0\n                )\n            loggers['evaluation'].info(f\"Precision Result: {precision_results}\")\n            return precision_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in precision_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis chunk defines a static method `precision_at_k` within the `EvaluationService` class, which calculates precision@k scores for information retrieval evaluation.  It's part of a larger class containing other evaluation metrics like NDCG, BPREF, recall@k, F1-score@k, hit rate@k, reciprocal rank, and mean average precision.\n",
        "size": 2130,
        "parent-class": "EvaluationService",
        "function_name": "precision_at_k"
    },
    {
        "id": "ee675a76-581c-406d-876b-a9a312193359",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 204,
        "end_line": 251,
        "content": "def recall_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Recall@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Recall@k' to recall scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            recall_results = {}\n\n            if len(ground_truth) == 0:\n                return {f\"Recall@{k}\": 0.0 for k in range(1, max_k + 1)}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                matches = len(ground_truth_ids.intersection(retrieved_at_k))\n                recall_results[f\"Recall@{k}\"] = round(\n                    matches / float(len(ground_truth)), 2\n                )\n            loggers['evaluation'].info(f\"Recall Results: {recall_results}\")\n            return recall_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in recall_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis code chunk defines a static method `recall_at_k` within the `EvaluationService` class, which calculates Recall@K for information retrieval evaluation.  It's part of a larger class containing various other evaluation metrics like precision, F1-score, NDCG, and MAP.\n",
        "size": 2156,
        "parent-class": "EvaluationService",
        "function_name": "recall_at_k"
    },
    {
        "id": "255aa227-0b45-4ad3-9131-ff6e3c0ba94e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 254,
        "end_line": 314,
        "content": "def f1_score_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes F1-Score@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'F1-Score@k' to F1 scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            f1_score_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n\n                # Calculate precision\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision = matches / float(k) if k > 0 else 0.0\n\n                # Calculate recall\n                recall = (\n                    matches / float(len(ground_truth))\n                    if ground_truth\n                    else 0.0\n                )\n\n                # Calculate F1 score\n                f1 = 0.0\n                if precision + recall > 0:\n                    f1 = 2 * (precision * recall) / (precision + recall)\n\n                f1_score_results[f\"F1-Score@{k}\"] = round(f1, 2)\n\n            loggers['evaluation'].info(f\"F1-Score Results: {f1_score_results}\")\n            return f1_score_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in f1_score_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\nThis chunk defines a static method `f1_score_at_k` within the `EvaluationService` class, which calculates the F1-score@k for information retrieval evaluation.\n",
        "size": 2359,
        "parent-class": "EvaluationService",
        "function_name": "f1_score_at_k"
    },
    {
        "id": "92930511-2ef5-4f0a-ad0e-8b4ee649ae81",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 317,
        "end_line": 365,
        "content": "def hit_rate_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Hit Rate@K for all k values from 1 to max_k.\n        (Binary outcome: 1 if at least one relevant document is in top-K, 0 otherwise)\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Hit_Rate@k' to binary hit values for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            hit_rate_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                hit = (\n                    1.0\n                    if len(ground_truth_ids.intersection(retrieved_at_k)) > 0\n                    else 0.0\n                )\n                hit_rate_results[f\"Hit_Rate@{k}\"] = hit\n\n            loggers[\"evaluation\"].info(f\"Hit Rate Results: {hit_rate_results}\")\n            return hit_rate_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in hit_rate_at_k: {e}\")\n            return {}\nThis chunk defines a static method `hit_rate_at_k` within the `EvaluationService` class, which calculates the Hit Rate@K metric for information retrieval evaluation.  It's one of several methods in the class that compute different evaluation metrics.\n",
        "size": 2122,
        "parent-class": "EvaluationService",
        "function_name": "hit_rate_at_k"
    },
    {
        "id": "15fcb923-6433-4a49-982b-772781c4d80e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 368,
        "end_line": 401,
        "content": "def reciprocal_rank(\n        retrieved_docs: List[Dict], ground_truth: List[str]\n    ) -> float:\n        \"\"\"\n        Computes Mean Reciprocal Rank (MRR).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n\n        Returns:\n            MRR score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            reciprocal_rank = 0.0\n            ground_truth_set = set(ground_truth)\n\n            for rank, doc in enumerate(retrieved_docs, start=1):\n                if doc[\"id\"] in ground_truth_set:\n                    reciprocal_rank = 1.0 / rank\n                    break\n\n            return reciprocal_rank\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_reciprocal_rank: {e}\")\n            return 0.0\nThis chunk defines a static method `reciprocal_rank` within the `EvaluationService` class, calculating the Mean Reciprocal Rank (MRR) for information retrieval evaluation.\n",
        "size": 1265,
        "parent-class": "EvaluationService",
        "function_name": "reciprocal_rank"
    },
    {
        "id": "a82a185b-798b-477b-9ab0-575405115c85",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 404,
        "end_line": 452,
        "content": "def mean_average_precision(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> float:\n        \"\"\"\n        Computes Mean Average Precision (MAP).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            MAP score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_set = set(ground_truth)\n            average_precision = 0.0\n            relevant_count = 0\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_docs[:k]\n                matches = sum(\n                    1 for doc in retrieved_at_k if doc[\"id\"] in ground_truth_set\n                )\n                precision_at_k = matches / float(k) if k > 0 else 0.0\n\n                if retrieved_at_k[-1][\"id\"] in ground_truth_set:\n                    average_precision += precision_at_k\n                    relevant_count += 1\n\n            return average_precision / relevant_count if relevant_count > 0 else 0.0\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_average_precision: {e}\")\n            return 0.0\nThis chunk defines a static method `mean_average_precision` within the `EvaluationService` class, which calculates the Mean Average Precision (MAP) metric for information retrieval evaluation.  It's one of several evaluation metrics (including NDCG, BPREF, precision@k, recall@k, F1-score@k, hit rate@k, and reciprocal rank) provided by the class.\n",
        "size": 2132,
        "parent-class": "EvaluationService",
        "function_name": "mean_average_precision"
    },
    {
        "id": "c3abaff5-50eb-4f20-84e9-270de78e0500",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nfrom fastapi import HTTPException\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\nImport statements at the beginning of a Python class definition for a reranking service.\n",
        "size": 232,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "6f7b2b17-7ae5-46f7-b0e6-8d9164e1a141",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 11,
        "end_line": 27,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.voyage_api_key=settings.VOYAGEAI_API_KEY\n        self.pinecone_rerank_url = settings.PINECONE_RERANK_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.voyage_base_url=settings.VOYAGEAI_BASE_URL\n        self.RERANK_SUFFIX = \"rerank\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\nConstructor for the RerankerService class, initializing API keys, URLs, and timeout settings for different reranking services (Pinecone, Cohere, Jina, Voyage).\n",
        "size": 1071,
        "parent-class": "RerankerService",
        "function_name": "__init__"
    },
    {
        "id": "6b1c36cc-9b6a-45f7-bc48-dc05f2c5e88f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 29,
        "end_line": 70,
        "content": "async def pinecone_reranker(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n            \"Api-Key\": self.pinecone_api_key,\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"return_documents\": True,\n            \"top_n\": top_n,\n            \"documents\": documents,\n            \"parameters\": {\n                \"truncate\": \"END\",\n            },\n        }\n\n        url = self.pinecone_rerank_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done\")\n                loggers[\"pinecone\"].info(f\"Reranking model hosted by Pinecone tokens usage : {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            parsed_response = json.loads(response.content.decode(\"utf-8\"))\n            error_message = parsed_response.get(\"error\", {}).get(\n                \"message\", \"Unknown error occurred\"\n            )\n            loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n            raise HTTPException(status_code=400, detail=error_message)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code snippet defines the `pinecone_reranker` method within the `RerankerService` class.  This method uses the Pinecone API to rerank documents based on a given query.  It's one of several similar methods in the class that interface with different reranking services (Cohere, Jina, Voyage).\n",
        "size": 1939,
        "parent-class": "RerankerService",
        "function_name": "pinecone_reranker"
    },
    {
        "id": "2249137f-b13a-4151-a588-387a46c23343",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 72,
        "end_line": 114,
        "content": "async def cohere_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        rerank_url = f\"{self.cohere_base_url}/{self.RERANK_SUFFIX}\"\n\n        headers = {\n            \"content-type\": \"application/json\",\n            \"accept\": \"application/json\",\n            \"Authorization\": f\"bearer {self.cohere_api_key}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url,\n                    headers=headers,\n                    json=payload,\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by cohere\")\n                loggers[\"cohere\"].info(f\"Reranking model hosted by Cohere tokens usage : {response.json().get('meta',{}).get('billed_units', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in cohere {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code snippet defines an asynchronous function `cohere_rerank` within a `RerankerService` class.  This function uses the Cohere API to rerank a list of documents based on a given query.\n",
        "size": 1966,
        "parent-class": "RerankerService",
        "function_name": "cohere_rerank"
    },
    {
        "id": "87ee80e7-f14c-45e4-a1fe-d16c7845b663",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 116,
        "end_line": 155,
        "content": "async def jina_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.jina_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by jina\")\n                loggers[\"jina\"].info(f\"Reranking model hosted by Jina tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in jina {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code chunk defines an asynchronous method `jina_rerank` within the `RerankerService` class, responsible for reranking documents using a Jina-based model.  It handles HTTP requests, error handling, and logging.\n",
        "size": 1914,
        "parent-class": "RerankerService",
        "function_name": "jina_rerank"
    },
    {
        "id": "abcea73f-3215-4f0f-bfbe-cda99e9a7b79",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 158,
        "end_line": 196,
        "content": "async def voyage_rerank(\n            self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        headers = {\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.voyage_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_k\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.voyage_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by voyage\")\n                loggers[\"voyage\"].info(f\"Reranking model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail = f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in Voyage {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\nThis code chunk defines an asynchronous function `voyage_rerank` within the `RerankerService` class.  This function uses the Voyage AI API to rerank documents based on a given query.\n",
        "size": 1917,
        "parent-class": "RerankerService",
        "function_name": "voyage_rerank"
    }
]