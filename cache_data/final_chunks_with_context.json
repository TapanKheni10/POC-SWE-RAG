[
    {
        "id": "518d657108f393569259b411567b9b09f195336a00e66766a9c32ebe5ca1360a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nimport asyncio\nimport streamlit as st\nfrom typing import Dict, Tuple, List, Optional\n\nImport statements for the application, including JSON handling (json), HTTP client for async requests (httpx), async functionality (asyncio), Streamlit for the web interface (st), and type hints from typing module. These imports support the RAG Pipeline Comparison Tool's functionality for API communication, data serialization, asynchronous operations, and UI rendering.",
        "size": 482,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "1dad10623d6a652f09141a3ac5cf41fcd5be08bc1cd9c79ee4159952962c7783",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 11,
        "end_line": 47,
        "content": "def initialize():\n        \"\"\"Initialize all session state variables\"\"\"\n        if \"pipeline_states\" not in st.session_state:\n            st.session_state.pipeline_states = {\n                \"1\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                },\n                \"2\": {\n                    \"search_performed\": False,\n                    \"reranking_performed\": False,\n                    \"search_results\": {},\n                    \"reranking_results\": {},\n                    \"random_question\": {},\n                    \"random_question_results\": {},\n                    \"random_query\": str,\n                    \"index_created\": False,\n                    \"top_k\": 0,\n                    \"random_question_generated\": False,\n                    \"random_question_answer_generated\": False\n                }\n            }\n        \n        if \"file_uploaded\" not in st.session_state:\n            st.session_state.file_uploaded = False\n        \n        if \"file_name\" not in st.session_state:\n            st.session_state.file_name = \"\"\n\nStatic method in the SessionState class that initializes Streamlit session state variables for tracking the state of two parallel retrieval pipelines. It creates a nested dictionary structure storing search and reranking states, results, metrics, and flags for each pipeline. The method ensures session variables exist for tracking file upload status and filename, establishing the foundation for state management in the RAG pipeline comparison application.",
        "size": 1968,
        "parent-class": "SessionState",
        "function_name": "initialize"
    },
    {
        "id": "73a4ecce0b7b287dbb64cdf2f712599bc3f1315a70417df3a7eff70470860dad",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 50,
        "end_line": 53,
        "content": "def reset_search_result(pipeline_id: str):\n        \"\"\"Reset search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = {}\n\nMethod in SessionState class that resets search-related state variables for a specified pipeline by setting 'search_performed' flag to False and clearing 'search_results' dictionary. Used to reset search state when users want to start a new search or clear previous results.",
        "size": 536,
        "parent-class": "SessionState",
        "function_name": "reset_search_result"
    },
    {
        "id": "e17502054a6f7247dcf06f6b167f49bd3ebc713f4d1c6378e78d2a1fce012b63",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 56,
        "end_line": 59,
        "content": "def reset_reranking_result(pipeline_id: str):\n        \"\"\"Reset reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = False\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = {}\n\nA static method in the SessionState class that resets the reranking state for a specified pipeline. It marks reranking as not performed and clears any existing reranking results from the session state. Used as part of the state management system for tracking and comparing RAG pipeline configurations in the Streamlit application.",
        "size": 604,
        "parent-class": "SessionState",
        "function_name": "reset_reranking_result"
    },
    {
        "id": "ae5af9ec84f9cdef5fa46e171f06eb0a8ff3622cd39c63597b331862cbf15ac2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 62,
        "end_line": 65,
        "content": "def set_search_performed(pipeline_id: str, top_k: int):\n        \"\"\"Mark search as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_performed\"] = True\n        st.session_state.pipeline_states[pipeline_id][\"top_k\"] = top_k\n\nStatic method in the SessionState class that marks a search as completed for a specific pipeline and stores the top_k value in the session state. Part of the state management system for tracking search operations in a Streamlit application that compares information retrieval pipelines.",
        "size": 558,
        "parent-class": "SessionState",
        "function_name": "set_search_performed"
    },
    {
        "id": "087f226b74564a10be38c181afadc82dc9bbc4bdd114d75c017c08ebab01f888",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 68,
        "end_line": 70,
        "content": "def set_reranking_performed(pipeline_id: str):\n        \"\"\"Mark reranking as performed for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_performed\"] = True\n\n\nStatic method within the SessionState class that updates the session state to mark reranking as completed for a specified pipeline. It sets the \"reranking_performed\" flag to True in the state management system, which is used to track pipeline progress and determine when to display reranking results in the Streamlit interface.\n",
        "size": 527,
        "parent-class": "SessionState",
        "function_name": "set_reranking_performed"
    },
    {
        "id": "aeecaae9c0d071470a64763e9d318e25df72d0e4dc5600041bdebf561dd37abb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 73,
        "end_line": 75,
        "content": "def set_index_created(pipeline_id: str):\n        \"\"\"Mark index as created for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"index_created\"] = True\n\nSession state management method in the SessionState class that marks an index as created for a specific pipeline by setting the \"index_created\" flag to True in Streamlit's session state. This method is called after successful index creation and dataset upserting to track pipeline state across application interactions.",
        "size": 499,
        "parent-class": "SessionState",
        "function_name": "set_index_created"
    },
    {
        "id": "8d03b16b865d2a75b8673205359ec37e8bdf959b0c0a7dd555dffb083eee043c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 78,
        "end_line": 80,
        "content": "def store_search_results(pipeline_id: str, results: Dict):\n        \"\"\"Store search results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"search_results\"] = results\n\nStatic method within SessionState class that stores search results in the Streamlit session state for a specific pipeline. Part of a centralized state management system that handles search and reranking operations in a RAG (Retrieval Augmented Generation) comparison tool. This method updates the pipeline state by assigning search results to the appropriate pipeline identified by pipeline_id.",
        "size": 595,
        "parent-class": "SessionState",
        "function_name": "store_search_results"
    },
    {
        "id": "db302d394fcc619e2f69c51f9ef9211baea7a381b81772a4782e6f40749bed23",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 83,
        "end_line": 85,
        "content": "def store_reranking_results(pipeline_id: str, results: Dict):\n        \"\"\"Store reranking results for a specific pipeline\"\"\"\n        st.session_state.pipeline_states[pipeline_id][\"reranking_results\"] = results\n\nStatic method in the SessionState class responsible for storing reranking results in the Streamlit session state. Takes a pipeline identifier and results dictionary as parameters and updates the corresponding pipeline's state. Part of the session state management system that tracks retrieval pipeline evaluation results within the RetrieveWise application.",
        "size": 567,
        "parent-class": "SessionState",
        "function_name": "store_reranking_results"
    },
    {
        "id": "9d350c5ab0d7b2b9ed634fe09145bae18374fbe4bc724d12463f33fb6679230e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 88,
        "end_line": 89,
        "content": "def store_random_question(pipeline_id: str, generated_question: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_question\"] = generated_question\n\nStatic method within the SessionState class that stores a randomly generated question in the session state for a specific pipeline. It updates the \"random_question\" attribute in the pipeline's state dictionary with the provided generated_question data. Part of the state management functionality for tracking random question generation in the RAG pipeline evaluation tool.",
        "size": 538,
        "parent-class": "SessionState",
        "function_name": "store_random_question"
    },
    {
        "id": "93f57c716868e393d8e97e99c67087737a3803a42c9b823d6c3aa06922df27c8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 92,
        "end_line": 94,
        "content": "def store_random_question_answer(pipeline_id: str, query: str, results: Dict):\n        st.session_state.pipeline_states[pipeline_id][\"random_query\"] = query\n        st.session_state.pipeline_states[pipeline_id][\"random_question_results\"] = results\n\nSessionState method for storing random question search results in the session state, saving both the query string and search results for a specific pipeline. Part of the state management system that maintains query results for displaying random search functionality in the RAG pipeline comparison tool.",
        "size": 551,
        "parent-class": "SessionState",
        "function_name": "store_random_question_answer"
    },
    {
        "id": "018e35f55d7ecc3062ad9c724edd2fe7a8b7f709ca382259b34e9c3d75cd4433",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 100,
        "end_line": 116,
        "content": "def get_embedding_models() -> List[str]:\n        \"\"\"Get list of available embedding models\"\"\"\n        return [\n            \"\",\n            \"llama-text-embed-v2\",\n            \"multilingual-e5-large\",\n            \"embed-english-v3.0\",\n            \"embed-multilingual-v3.0\",\n            \"embed-english-light-v3.0\",\n            \"embed-multilingual-light-v3.0\",\n            \"embed-english-v2.0\",\n            \"embed-english-light-v2.0\",\n            \"embed-multilingual-v2.0\",\n            \"jina-embeddings-v3\",\n            \"jina-clip-v2\",\n            \"voyage-3-large\"\n        ]\n\nStatic method within the ModelRegistry class that returns a comprehensive list of available text embedding models. This function is used by the UI to populate model selection dropdowns for configuring search pipelines in the RAG comparison tool. The method returns a collection of models including Llama, E5, Cohere, Jina and Voyage embedding models.",
        "size": 922,
        "parent-class": "ModelRegistry",
        "function_name": "get_embedding_models"
    },
    {
        "id": "e37b4e7ed54c71756eacd38fff0ae5d8f3c83dc5737ced1c7c14bf789791668c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 119,
        "end_line": 124,
        "content": "def get_code_embedding_models() -> List[str]:\n        return [\n            \"\",\n            \"jina-embeddings-v2-base-code\",\n            \"voyage-code-3\",\n        ]\n\nStatic method in the ModelRegistry class that returns a list of available embedding models specifically designed for code content. The method provides predefined code-specific embedding model options that can be selected in the UI, supporting code retrieval pipelines in the application.",
        "size": 450,
        "parent-class": "ModelRegistry",
        "function_name": "get_code_embedding_models"
    },
    {
        "id": "036f05172b616a5e4745dfa86c0f1ed6c1edf10b6966984c5d3c4cc5e1d4b9e0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 126,
        "end_line": 139,
        "content": "def get_reranking_models() -> List[str]:\n        \"\"\"Get list of available reranking models\"\"\"\n        return [\n            \"\",\n            \"pinecone-rerank-v0\",\n            \"bge-reranker-v2-m3\",\n            \"rerank-v3.5\",\n            \"rerank-english-v3.0\",\n            \"rerank-multilingual-v3.0\",\n            \"jina-reranker-v2-base-multilingual\",\n            \"rereank-lite-1\",\n            \"rerank-2\",\n            \"rerank-1\"\n        ]\n\nStatic method within the ModelRegistry class that returns a list of all available reranking models for the RAG pipeline comparison tool. This function provides model options that can be selected in the UI for reranking search results after initial retrieval.",
        "size": 693,
        "parent-class": "ModelRegistry",
        "function_name": "get_reranking_models"
    },
    {
        "id": "dcf5ee8b07146d1094c5b103b4422df213818e0e8fc545aae7f355cbdaa19c49",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 142,
        "end_line": 158,
        "content": "def get_dimensions(dense_embedding_model: str) -> List[int]:\n        \"\"\"Get available dimensions for a specific embedding model\"\"\"\n        model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        return model_to_dimensions.get(dense_embedding_model, [])\n\nStatic method within the ModelRegistry class that maps embedding model names to their available vector dimensions. Returns a list of supported dimensions for a given embedding model or an empty list if the model is not found in the mapping dictionary. Used for configuring embedding dimensions in RAG pipeline setup.",
        "size": 1174,
        "parent-class": "ModelRegistry",
        "function_name": "get_dimensions"
    },
    {
        "id": "d404c5711618dbd547b83ed6f4ff39dd418f42bb1182707660a19164c9a9bfe9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 164,
        "end_line": 180,
        "content": "def display_results_tabs(pipeline_id: str):\n        \"\"\"Display results in tabbed interface\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        tab1, tab2 = st.tabs([\"Search Results\", \"Reranking Results\"])\n        \n        with tab1:\n            if pipeline_state[\"search_performed\"]:\n                UIComponents.display_search_results(pipeline_state[\"search_results\"], pipeline_id)\n            else:\n                st.info(\"Run a search to see results here.\")\n        \n        with tab2:\n            if pipeline_state[\"reranking_performed\"]:\n                UIComponents.display_reranking_results(pipeline_state[\"reranking_results\"], pipeline_id)\n            else:\n                st.info(\"Run reranking to see results here.\")\n\nMethod in the UIComponents class that creates a tabbed interface for displaying search and reranking results. It uses Streamlit components to create tabs, conditionally renders search or reranking results based on pipeline state, and shows informational messages when results aren't available. The method takes a pipeline_id parameter to identify which pipeline's results to display.",
        "size": 1152,
        "parent-class": "UIComponents",
        "function_name": "display_results_tabs"
    },
    {
        "id": "d1c8767b6b01a0be93fed6b2905e551689e274ddb807e1d4ce1cb079976d4b01",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 183,
        "end_line": 196,
        "content": "def display_search_results(results: Dict, pipeline_id: str):\n        \"\"\"Display search results\"\"\"\n        if not results:\n            st.info(\"No search results available.\")\n            return\n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Search metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_search_{pipeline_id}\"\n        )\n        st.json(results, expanded = False)\n\nStatic method within the UIComponents class that displays search results for a RAG pipeline. Renders a download button for search metrics and formats the results as JSON in the Streamlit interface, taking a results dictionary and pipeline identifier as parameters. Used in the results visualization flow of the RetrieveWise application.",
        "size": 903,
        "parent-class": "UIComponents",
        "function_name": "display_search_results"
    },
    {
        "id": "e4efd93e660cb666be7ef3202a5e73a7d7f4f457af1ab87ed98bbb4c9dec4b24",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 200,
        "end_line": 215,
        "content": "def display_reranking_results(results: Dict, pipeline_id: str):\n        \"\"\"Display reranking results\"\"\"\n        if not results:\n            st.info(\"No reranking results available.\")\n            return\n        \n        json_results_str = json.dumps(results, indent = 4)\n        st.download_button(\n            label = \"Download Rerank metrics\",\n            data = json_results_str,\n            file_name = \"search_eval_metrics.json\",\n            mime = \"application/json\",\n            key = f\"download_button_reranking_{pipeline_id}\"\n        )\n        \n        st.json(results, expanded = False)\n\nStreamlit utility method within the UIComponents class that renders reranking results in the interface. The method checks if results exist, provides a download button for reranking metrics in JSON format, and displays the results in a collapsible JSON viewer. The pipeline_id parameter allows the function to generate unique keys for Streamlit components across multiple pipelines being compared.",
        "size": 993,
        "parent-class": "UIComponents",
        "function_name": "display_reranking_results"
    },
    {
        "id": "ccf44c9d0c31f66894a6dca9650c65f13f695c71f5f4039555da48a78b6dcf8f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 218,
        "end_line": 245,
        "content": "def display_random_question(pipeline_id: str):\n\n        if st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"]:\n            results = st.session_state.pipeline_states[pipeline_id][\"random_question\"]\n            question = results[\"question\"]\n\n            if len(results) > 0:\n                st.markdown(f\"### Random Question: \\n> {question}\")\n\n                for i, res in enumerate(results[\"chunks\"]):\n\n                    col1, col2 = st.columns([1, 1])\n                    with col1:\n                        st.markdown(f\"**Ground Truth Chunk {i+1}**\")\n                    with col2:\n                        st.markdown(f\"**ID:** {res['_id']}\")\n                # Create expander for each chunk\n                    with st.expander(\"Ground Truth\", expanded=False):\n                        \n                        # Display the text with wrapping\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"gt_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\n\nStatic method within the UIComponents class responsible for displaying randomly generated questions and their corresponding ground truth chunks. When random questions have been generated, it renders the question and displays all associated ground truth text chunks with column layout, IDs, and expandable content areas with text wrapping. The method checks the session state to determine if random questions exist before rendering UI components.",
        "size": 1690,
        "parent-class": "UIComponents",
        "function_name": "display_random_question"
    },
    {
        "id": "1dcfc0497b3b7859093f2fc670e3e1d694db7f2e235b5131ebbba3add96ed93a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 248,
        "end_line": 276,
        "content": "def display_random_question_answer(pipeline_id: str):\n        \n        if st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"]:\n            response = st.session_state.pipeline_states[pipeline_id][\"random_question_results\"]\n            query = st.session_state.pipeline_states[pipeline_id][\"random_query\"]\n            \n            # Container for the results to improve layout\n            if len(response) > 0:\n                st.markdown(\"### Search Results\")\n                st.markdown(f\"**Query:** \\n> {query}\")\n\n                for i, res in enumerate(response):\n                    # Create expander for each chunk\n                    score_indicator = \"\ud83d\udfe9\" if res['score'] > 0.8 else \"\ud83d\udfe7\" if res['score'] > 0.5 else \"\ud83d\udfe5\"\n                    col1, col2 = st.columns([4, 1])\n                    with col1:\n                        st.markdown(f\"**Relevant chunk {i+1}** || **ID:** {res['id']}\")\n                    with col2:\n                        st.markdown(f\"{score_indicator} **Score:** {res['score']:.4f}\")\n\n                    with st.expander(\"**Chunk**\",expanded=False):\n                        st.text_area(\n                            \"Content\",\n                            value=res['text'],\n                            height=min(350, 400 + 20 * res['text'].count('\\n')),\n                            key=f\"chunk_text_{pipeline_id}_{i}\"\n                        )\n            else:\n                st.info(\"No results found for this query.\")\n        \n\nUI rendering method within the UIComponents class that displays custom query search results for RetrieveWise. Presents retrieved chunks from custom user queries with visual score indicators (green/orange/red) based on relevance thresholds. Formats each result with expandable content areas, readable text formatting, and clear metadata including chunk ID and relevance score. Used as part of the RAG evaluation pipeline's user-driven testing capabilities.",
        "size": 1949,
        "parent-class": "UIComponents",
        "function_name": "display_random_question_answer"
    },
    {
        "id": "4bddb8c6c98ba7808c33a2a20978fc3f595bc62ae713f2fc275e1389dfd475bc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 287,
        "end_line": 297,
        "content": " fetch_user_previous_configurations():\n        \"\"\"Fetch user's previous configurations\"\"\"\n        async with httpx.AsyncClient() as client:\n            try:\n                response = await client.get(\n                    f\"{APIClient.BASE_URL}/get-configurations\",\n                    timeout=APIClient.TIMEOUT,\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n    \n   \n\nAsynchronous method within the APIClient class that retrieves user's previous RAG pipeline configurations from the backend server. The method makes a GET request to the \"/get-configurations\" endpoint, handles success/error responses, and returns a tuple containing success status, response data, and error message if applicable. This is part of the RESTful client functionality used to maintain user configuration state in the retrieval evaluation application.",
        "size": 1007,
        "parent-class": ":\n    \"\"\"",
        "function_name": "r_previous_configurations():\n     "
    },
    {
        "id": "3b0c75f99a229b28e524ad9cf0fad2918ebeb8eb25da789855260600f55d715c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 300,
        "end_line": 315,
        "content": " upload_file(data):\n        \"\"\"Upload a file to the backend service\"\"\"\n        \n        files = {\"file\": data['uploaded_file']}\n        form_data = {\"file_type\" : data[\"file_type\"]}\n\n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/upload-files\",\n                    files=files,\n                    data=form_data\n                )\n                return response.status_code == 200, response, response.json()[\"error\"] if response.status_code != 200 else \"None\"\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nStatic method in the APIClient class that handles file uploads to the backend service. Takes a data dictionary containing the uploaded file and file type, sends an asynchronous HTTP POST request to the upload-files endpoint, and returns a tuple containing success status, response object, and error message if applicable. Part of the application's API communication layer that enables uploading files for RAG pipeline processing.",
        "size": 1112,
        "parent-class": ":\n    \"\"\"",
        "function_name": "le(data):\n "
    },
    {
        "id": "486bbe0a504bf5fefe08384ce662286beb9f7d54b42cf34636cdeba1995606f2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 318,
        "end_line": 335,
        "content": " create_index(file_name: str, embed_model: str, similarity_metric: str, dimension: int) -> Tuple[bool, str]:\n        \"\"\"Create an index and upsert dataset\"\"\"\n        payload = {\n            \"file_name\": file_name,\n            \"embed_model\": embed_model,\n            \"similarity_metric\": similarity_metric,\n            \"dimension\": dimension,\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/index-upsert\",\n                    json=payload,\n                )\n                return response.status_code == 200, response.json()[\"error\"] if response.status_code != 200 else \"\"\n            except Exception as e:\n                return False, str(e)\n        \n\nStatic method in the APIClient class that handles asynchronous creation of search indexes. The method posts configuration parameters (file name, embedding model, similarity metric, and dimension) to the /index-upsert endpoint, creating an index and upserting dataset content. Returns a tuple containing a success boolean and error message string if applicable. Part of the communication layer between the UI and backend service in a RAG pipeline comparison tool.",
        "size": 1271,
        "parent-class": ":\n    \"\"\"",
        "function_name": "dex(file_nam"
    },
    {
        "id": "48cb9443f4068b8bb01d67a86af75087e5b242e2d07e5498dd2e81ad8d7164f1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 338,
        "end_line": 366,
        "content": " perform_search(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform a search query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/query\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_result\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nAPI method in the APIClient class that sends search requests to the backend service. It constructs a payload with search parameters (hybrid search configuration, file details, embedding model settings), handles hybrid search alpha parameter or similarity metric appropriately, makes an asynchronous HTTP POST request to the query endpoint, and processes the response, returning a tuple containing success status, evaluation results, and any error messages.",
        "size": 1693,
        "parent-class": ":\n    \"\"\"",
        "function_name": "earch(is_hybri"
    },
    {
        "id": "bc14d9f84c064721afe6fecad62543059fa01b9b5c9cb701079c32b93ff37f09",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 369,
        "end_line": 390,
        "content": " perform_reranking(model_name: str, top_n: int, top_k: int) -> Tuple[bool, Dict, str]:\n        \"\"\"Perform reranking\"\"\"\n        payload = {\n            \"model_name\": model_name,\n            \"top_n\": top_n,\n            \"top_k\": top_k\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/rerank\",\n                    json=payload,\n                    # timeout=APIClient.TIMEOUT,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"evaluation_metrics\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nAPI method within the APIClient class that handles communication with the reranking endpoint. Takes reranking model name and pagination parameters (top_n and top_k), makes an asynchronous HTTP POST request to the rerank endpoint, and returns a tuple containing success status, evaluation metrics from the response, and any error message. Part of the system's second-stage retrieval functionality that refines initial search results.",
        "size": 1301,
        "parent-class": ":\n    \"\"\"",
        "function_name": "eranking(model_na"
    },
    {
        "id": "18ff2c78cf10780b2f2fdb42d35c1a45a30c75696e11394e9694b0f10df47b7b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 393,
        "end_line": 411,
        "content": " random_question(file_name: str) -> Tuple[bool, Dict, str]:\n        \"\"\"Generate a random question\"\"\"\n        payload = {\n            \"file_name\": file_name\n        }\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-question\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nAPI method within the APIClient class that makes an asynchronous HTTP POST request to generate a random question related to file content. It takes a filename parameter, sends it to the backend endpoint, and returns a tuple containing success status, response data (or empty dict), and error message (if any). Used for generating test questions to evaluate retrieval quality.",
        "size": 1117,
        "parent-class": ":\n    \"\"\"",
        "function_name": "estion(file_nam"
    },
    {
        "id": "62d51e8c823aad5c1b2b612ba1a5444b14730db71317160d4f641278622f7795",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 414,
        "end_line": 442,
        "content": " random_query(is_hybrid: bool, file_name: str, embedding_model: str, dimension: int, top_k: int, query: str, similarity_metric: str = \"dotproduct\", alpha: Optional[float] = None):\n        \"\"\"Perform a random query\"\"\"\n        payload = {\n            \"is_hybrid\": is_hybrid,\n            \"file_name\": file_name,\n            \"embedding_model\": embedding_model,\n            \"dimension\": dimension,\n            \"top_k\": top_k,\n            \"query\": query,\n        }\n        \n        if is_hybrid and alpha is not None:\n            payload[\"alpha\"] = alpha\n        else:\n            payload[\"similarity_metric\"] = similarity_metric\n        \n        async with httpx.AsyncClient(timeout = APIClient.TIMEOUT) as client:\n            try:\n                response = await client.post(\n                    f\"{APIClient.BASE_URL}/random-query\",\n                    json=payload,\n                )\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return True, data[\"data\"][\"response\"], \"\"\n                return False, {}, response.json()[\"error\"]\n            except Exception as e:\n                return False, {}, str(e)\n        \n\nAPI client method for performing a random search query with custom text input. This asyncio function creates a payload with search configuration parameters, handles hybrid search logic by conditionally adding alpha or similarity_metric, makes an HTTP POST request to the backend endpoint, and returns a tuple containing success status, response data, and error message. Used in the random query section of the RAG pipeline comparison tool.",
        "size": 1637,
        "parent-class": ":\n    \"\"\"",
        "function_name": "ery(is_hybri"
    },
    {
        "id": "5fd622d4cbca96d3757c8e55fbc37bf619e49cf9c60db6862958083e3fa0c043",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 448,
        "end_line": 500,
        "content": " index_creation_section(pipeline_id: str, is_hybrid: bool) -> bool:\n        \"\"\"Handle index creation section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = \"\"\n        if st.session_state.get(f'file_type', None) == \"Code\":\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_code_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        else:\n            dense_embedding_model = st.selectbox(\n                \"Select Dense Embedding Model:\",\n                ModelRegistry.get_embedding_models(),\n                key=f\"dense_embedding_model_{pipeline_id}\",\n            )\n        \n        dimensions = ModelRegistry.get_dimensions(dense_embedding_model)\n        dense_dimension = st.selectbox(\n            \"Enter Dimension of the Dense Model:\",\n            dimensions,\n            key=f\"dense_dimension_{pipeline_id}\",\n        )\n        \n        if not dense_embedding_model or not dense_dimension:\n            st.warning(\"Please select the required models and dimensions.\")\n            return False\n        \n        similarity_metric = \"dotproduct\"\n        if not is_hybrid:\n            similarity_metric = st.selectbox(\n                \"Enter Similarity Metric:\",\n                [\"dotproduct\", \"cosine\", \"euclidean\"],\n                key=f\"similarity_metric_{pipeline_id}\",\n            )\n        else:\n            st.warning(\"By default, dot product similarity is used for the hybrid search.\")\n        \n        if st.button(\"Create Index and Upsert Dataset\", key=f\"create_index_{pipeline_id}\"):\n            with st.spinner(\"Creating index and upserting dataset...\"):\n                success, error_msg = await APIClient.create_index(\n                    file_name, dense_embedding_model, similarity_metric, dense_dimension\n                )\n                \n                if success:\n                    st.success(\"Index created and dataset upserted successfully!\")\n                    SessionState.set_index_created(pipeline_id)\n                else:\n                    st.error(f\"Index creation and dataset upsert failed: {error_msg}\")\n        \n        return pipeline_state[\"index_created\"]\n    \n   \n\nStatic method within the PipelineManager class that handles the UI components for vector index creation. Manages embedding model selection (different options for code vs. text), dimension selection, similarity metric configuration, and initiates index creation through an API call. Controls UI flow for hybrid search vs. standard search by adjusting available options. Returns a boolean indicating whether the index is ready for the next pipeline stage.",
        "size": 2812,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ation_section(pipeline"
    },
    {
        "id": "1057142f8dadace7117139201b1417ee9ead8cbb13a488cd607b3306eb4475a0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 503,
        "end_line": 554,
        "content": " search_section(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Handle search section of the UI\"\"\"\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.number_input(\"Enter the value for top_k:\", min_value=1, value=\"min\", step=1, key=f\"top_k_{pipeline_id}\")\n        \n        alpha = None\n        if is_hybrid:\n            alpha = st.slider(\n                \"Select alpha value (between 0 and 1):\",\n                min_value=0.0,\n                max_value=1.0,\n                step=0.1,\n                value=0.5,\n                key=f\"alpha_{pipeline_id}\",\n            )\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get First Stage Evaluation Metrics\",\n                key=f\"perform_search_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing search...\"):\n                    success, results, error_msg = await APIClient.perform_search(\n                        is_hybrid=is_hybrid,\n                        file_name=file_name,\n                        embedding_model=dense_embedding_model,\n                        dimension=dense_dimension,\n                        top_k=top_k,\n                        similarity_metric=similarity_metric,\n                        alpha=alpha,\n                    )\n                    \n                    if success:\n                        st.success(\"Search performed successfully!\")\n                        SessionState.store_search_results(pipeline_id, results)\n                        SessionState.set_search_performed(pipeline_id, top_k)\n                    else:\n                        st.error(f\"First stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_similarity_{pipeline_id}\",\n            ):\n                SessionState.reset_search_result(pipeline_id)\n    \n   \n\nStatic method within the PipelineManager class that handles the search configuration and execution UI. Retrieves necessary parameters from session state, displays input fields for search parameters like top_k and alpha (for hybrid search), and provides buttons to execute the search or reset results. When search is executed, it calls the APIClient to perform the search using the specified parameters, stores results in the session state, and updates the pipeline status. The method is part of the RAG pipeline comparison flow, representing the first-stage retrieval configuration step after index creation.",
        "size": 2889,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ction(pipeline"
    },
    {
        "id": "8e65613add2a76570af15b22e4f10651ee53d351425385e626ee2a83703554e8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 557,
        "end_line": 605,
        "content": " reranking_section(pipeline_id: str):\n        \"\"\"Handle reranking section of the UI\"\"\"\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        if not pipeline_state[\"search_performed\"] or not pipeline_state[\"search_results\"]:\n            return\n        \n        reranking_model = st.selectbox(\n            \"Select Reranking Model:\",\n            ModelRegistry.get_reranking_models(),\n            key=f\"reranking_model_{pipeline_id}\",\n        )\n        \n        top_n = st.number_input(\"Enter the value for top_n:\", min_value=1, value=\"min\", step=1, key=f\"top_n_{pipeline_id}\")\n        \n        if pipeline_state[\"top_k\"] < top_n:\n            st.warning(\"The value of top_n should be less than or equal to the value of top_k.\")\n            return\n        \n        if not reranking_model or not top_n:\n            st.warning(\"Please select the reranking model and enter the top_n value.\")\n            return\n        \n        col1, col2 = st.columns([1, 1])\n        with col1:\n            if st.button(\n                \"Get Reranking Evaluation Metrics\",\n                key=f\"perform_reranking_{pipeline_id}\",\n            ):\n                with st.spinner(\"Performing reranking...\"):\n                    success, results, error_msg = await APIClient.perform_reranking(\n                        model_name=reranking_model,\n                        top_n=top_n,\n                        top_k=pipeline_state[\"top_k\"],\n                    )\n                    \n                    if success:\n                        st.success(\"Reranking performed successfully!\")\n                        SessionState.store_reranking_results(pipeline_id, results)\n                        SessionState.set_reranking_performed(pipeline_id)\n                    else:\n                        st.error(f\"Second stage retrieval failed: {error_msg}\")\n        \n        with col2:\n            if st.button(\n                \"Reset Results\",\n                key=f\"reset_reranked_{pipeline_id}\",\n            ):\n                SessionState.reset_reranking_result(pipeline_id)\n        \n\nStatic method of the PipelineManager class that manages the reranking UI section in a RAG pipeline comparison tool. Renders reranking model selection controls, validates parameters against previous search results, handles reranking API calls, displays results, and provides reset functionality. Connects to the SessionState for persistent state management and APIClient for backend communication. Requires that first-stage search has been completed before allowing reranking operations.",
        "size": 2569,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "_section(pipeline"
    },
    {
        "id": "f2a6ecdece855fe9ecf77544fa74d8518fd88a6a8c1e27923913453fa247175d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 608,
        "end_line": 627,
        "content": " random_question_section(pipeline_id: str):\n        if \"file_name\" in st.session_state:\n            file_name = st.session_state.file_name\n            \n            if st.button(\n                \"Get random question\",\n                key=f\"generate_random_question_{pipeline_id}\",\n            ):\n                with st.spinner(\"processing random question...\"):\n                    success, response, error_msg = await APIClient.random_question(file_name)\n                    \n                    if success:\n                        st.session_state.pipeline_states[pipeline_id][\"random_question_generated\"] = True\n                        SessionState.store_random_question(pipeline_id = pipeline_id, generated_question = response)\n\n                    else:\n                        st.error(f\"Random question generation failed: {error_msg}\")\n\n        else:\n            st.warning(\"No file selected. Please upload a file first.\")\n        \n\nStatic method within the PipelineManager class that handles generating random questions for RAG evaluation. It verifies a file is loaded, provides a UI button to trigger question generation, makes an API call to get random questions based on the document, and updates session state with the results. This component fits into the overall pipeline evaluation workflow, allowing users to test retrieval performance with automatically generated questions.",
        "size": 1390,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "estion_section(pipeline"
    },
    {
        "id": "deb382d3237a82731491631bcaa87ac79b90128ae19f8a31ab32af8878500523",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 630,
        "end_line": 670,
        "content": " random_query_section(pipeline_id: str):\n        file_name = st.session_state.file_name\n        pipeline_state = st.session_state.pipeline_states[pipeline_id]\n        \n        dense_embedding_model = st.session_state.get(f\"dense_embedding_model_{pipeline_id}\", \"\")\n        dense_dimension = st.session_state.get(f\"dense_dimension_{pipeline_id}\", 0)\n        similarity_metric = st.session_state.get(f\"similarity_metric_{pipeline_id}\", \"dotproduct\")\n        \n        top_k = st.session_state.get(f\"top_k_{pipeline_id}\", 0)\n        is_hybrid = st.session_state.get(f\"hybrid_search_{pipeline_id}\", \"No\") == \"Yes\"\n        alpha = st.session_state.get(f\"alpha_{pipeline_id}\", None)\n            \n        query = st.text_input(\"Enter the query for random search:\", key=f\"query_{pipeline_id}\")\n        \n        if not query:\n            st.warning(\"Please enter a query for random search.\")\n            return\n        \n        if st.button(\n            \"Search custom query\", \n            key=f\"search_custom_query_{pipeline_id}\"\n        ):\n            with st.spinner(\"Performing search...\"):\n                success, response, error_msg = await APIClient.random_query(\n                    is_hybrid=is_hybrid,\n                    file_name=file_name,\n                    embedding_model=dense_embedding_model,\n                    dimension=dense_dimension,\n                    top_k=top_k,\n                    query=query,\n                    similarity_metric=similarity_metric,\n                    alpha=alpha,\n                )\n                \n                if success:\n                    st.success(\"Search performed successfully!\")\n                    st.session_state.pipeline_states[pipeline_id][\"random_question_answer_generated\"] = True\n                    SessionState.store_random_question_answer(pipeline_id = pipeline_id, query=query, results = response)\n                        \n                else:\n                    st.error(f\"Error performing search: {error_msg}\")\n    \n   \n\nStatic method in PipelineManager class that handles the UI section for custom user queries in a retrieval pipeline. Retrieves session parameters, presents a text input for query entry, performs search using APIClient.random_query with configured parameters (embedding model, dimensions, similarity metrics), and stores results in session state for display. Part of the RAG pipeline comparison tool's functionality for testing search with user-defined queries alongside automated evaluation metrics.",
        "size": 2490,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ery_section(pipeline"
    },
    {
        "id": "1ca7fa9b0a6c7ef2eda4ccd02ca34ca747a71b24e8e3f29ee2f5108816afae5b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 673,
        "end_line": 691,
        "content": " run_pipeline(pipeline_id: str, is_hybrid: bool):\n        \"\"\"Run a complete RAG pipeline\"\"\"\n\n        index_ready = await PipelineManager.index_creation_section(pipeline_id, is_hybrid)\n        \n        if index_ready:\n            \n            await PipelineManager.search_section(pipeline_id, is_hybrid)\n            \n            await PipelineManager.reranking_section(pipeline_id)\n            \n            await PipelineManager.random_question_section(pipeline_id)\n            UIComponents.display_random_question(pipeline_id=pipeline_id)\n            \n            await PipelineManager.random_query_section(pipeline_id)\n            UIComponents.display_random_question_answer(pipeline_id=pipeline_id)\n        \n        st.subheader(\"Results\")\n        UIComponents.display_results_tabs(pipeline_id)\n        \n\nPipeline orchestration method within the PipelineManager class that coordinates the sequential execution of RAG pipeline stages including index creation, search, reranking, random question generation, and results display. Controls the workflow by awaiting completion of each stage and conditionally proceeding based on index readiness. Uses Streamlit for UI rendering and leverages UI component helper methods to present results from each pipeline step.",
        "size": 1260,
        "parent-class": "anager:\n    \"\"\"",
        "function_name": "ine(pipeline"
    },
    {
        "id": "fad0e38a1518eaffb4da8924c92fb7535414dc9a41a547ccc8f438ad911a7212",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 693,
        "end_line": 721,
        "content": " handle_file_upload():\n    \"\"\"Handle file upload\"\"\"\n    file_type = st.radio(\"Select File Type:\", [\"Text\", \"Code\"])\n    if \"file_type\" not in st.session_state:\n        st.session_state.file_type = file_type\n    st.session_state.file_type = file_type\n\n\n    uploaded_file = st.file_uploader(\"Upload a file:\", type=[\"json\"])\n    \n    if uploaded_file and not st.session_state.file_uploaded:\n        with st.spinner(\"Uploading file...\"):\n            data = {\"uploaded_file\": uploaded_file, \"file_type\": file_type}\n            success, response, error_msg = await APIClient.upload_file(data)\n\n            if success:\n                success_message = response.json()[\"detail\"]\n                st.success(f\"Success Message: {success_message}\")\n\n                st.session_state.file_uploaded = True\n                st.session_state.file_name = uploaded_file.name\n\n                st.write(\"Here is the schema of the uploaded file:\")\n                st.json(response.json()[\"data\"][\"file_schema\"])\n            else:\n                st.error(f\"Upload failed: {error_msg}\")\n\n    \n    return st.session_state.file_uploaded\n\nasync d\n\nAsynchronous file upload handler function for Streamlit UI that manages JSON file uploads for text or code documents. The function creates a file type selector, displays a file uploader, sends the file to the backend API via the APIClient, and updates session state variables upon successful upload. It returns a boolean indicating whether a file was successfully uploaded, and displays the file schema when successful or error messages when upload fails.",
        "size": 1578,
        "parent-class": null,
        "function_name": "le_upload():\n    \""
    },
    {
        "id": "a185fde68b5427f0256d60519904fcc4a2b37c3c61c818561a1726ab3fbb3261",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app.py",
        "file_name": "app.py",
        "start_line": 723,
        "end_line": 788,
        "content": " main():\n    \"\"\"Main application entry point\"\"\"\n    \n    SessionState.initialize()\n    \n    st.set_page_config(\n        page_title=\"RAG Pipeline Comparison Tool | Pinecone\",\n        layout=\"wide\",\n        page_icon=\"\ud83e\uddca\",\n    )\n    \n    st.title(\"RetrieveWise\")\n    st.divider()\n    st.markdown(\n        \"\"\"\n        Compare and Evaluate different Information Retrieval Pipelines, Configure two retrieval pipelines side by side \n        with different settings, embedding models, rerankers. Once set compare key performance metrics like precision, recall\n        NDCG, MRR, F1 etc \n    \"\"\"\n    )\n    \n    success, response, error_msg = await APIClient.fetch_user_previous_configurations()\n    \n    if success:\n        data = response.json().get(\"data\", None)\n        if isinstance(data, dict) and \"message\" in data:\n            st.info(data[\"message\"])\n        else:\n            st.write(\"Here are your previous configurations:\")\n            st.json(response.json()[\"data\"], expanded = False)\n    else:\n        st.error(f\"Failed to fetch previous configurations: {error_msg}\")\n    \n    file_uploaded = await handle_file_upload()\n    \n    if not file_uploaded:\n        st.warning(\"Please upload the JSON files for the pipelines to compare.\")\n        return\n\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.header(\"Pipeline 1\")\n        hybrid_search_1 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_1\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"1\", \n            is_hybrid=(hybrid_search_1 == \"Yes\")\n        )\n        \n    with col2:\n        st.header(\"Pipeline 2\")\n        hybrid_search_2 = st.radio(\n            \"Do you want to perform a hybrid search?\",\n            (\"Yes\", \"No\"),\n            key=\"hybrid_search_2\",\n        )\n        \n        await PipelineManager.run_pipeline(\n            pipeline_id=\"2\", \n            is_hybrid=(hybrid_search_2 == \"Yes\")\n        )\n        \nif\n\nMain entry point function that initializes the Streamlit web application for comparing RAG pipelines. Sets up the UI layout, displays application title and description, retrieves user's previous configurations via API, handles file uploads, and creates a side-by-side comparison interface with two columns for configuring and running separate retrieval pipelines with options for hybrid search. Contains core application flow control and orchestrates the various components of the RetrieveWise tool.",
        "size": 2515,
        "parent-class": null,
        "function_name": "   \""
    },
    {
        "id": "e9d1417c3d6a02ae7f07c4dec66d86858849da21faf7c2d1c98337416c3b60e5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom app.apis import file_upload, index_upsert_route, query, reranking_router, configuration_route, random_question_route, random_query_route\nfrom app.config.database import db_helper\n\nFastAPI application imports for a RAG Playground, including database connectivity module, async context manager, and various API route modules for file upload, indexing, querying, reranking, configuration, and random question/query functionality.",
        "size": 502,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f1dd41fa44a3aff7239563f46ae9c9f7e7828e6f7c825bef00ab12bef3082c58",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 10,
        "end_line": 14,
        "content": "async def lifespan(app: FastAPI):\n    await db_helper.connect()\n    db = await db_helper.get_db()\n    yield\n    await db_helper.disconnect()\n\nFastAPI lifecycle management function that establishes database connections when the application starts and disconnects when it shuts down. Used as an asynccontextmanager for the main application to ensure proper database connection handling throughout the application's lifecycle.",
        "size": 423,
        "parent-class": null,
        "function_name": "lifespan"
    },
    {
        "id": "db1543b5da92dedc27c7670ce4dd1ab7699065cbcb3f814a17dbf8c628313972",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/main.py",
        "file_name": "main.py",
        "start_line": 30,
        "end_line": 31,
        "content": "async def root():\n    return {\"message\": \"Welcome to the RAG Playground\"}\n\nRoot endpoint handler that returns a welcome message for the RAG Playground API. This function serves as the default endpoint (/) of the FastAPI application, providing a simple response to verify the API is running.",
        "size": 290,
        "parent-class": null,
        "function_name": "root"
    },
    {
        "id": "1432ef6aa59492de4edf5970dd8a533f4397ce738bc44a5ffbbb8758bfdfe083",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.query_controller import QueryController\nfrom app.models.schemas.query_schema import QueryEndPointRequest\n\nFastAPI router module imports for query endpoint implementation, including dependency injection, error handling, response formatting capabilities, and the controller and schema model for query operations.",
        "size": 475,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "cf2aa73894882018e37850b305f4938c8952a2dcd58f537f4b3e3d368eabbb3e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/query.py",
        "file_name": "query.py",
        "start_line": 12,
        "end_line": 26,
        "content": "async def make_query(\n    request: QueryEndPointRequest, query_controller: QueryController = Depends()\n):\n\n    response_data = await query_controller.make_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Query execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI route handler function for the \"/query\" endpoint that processes query requests. Accepts a QueryEndPointRequest object and a QueryController dependency, calls the controller's make_query method asynchronously, and returns a formatted JSONResponse with status code 200 upon successful query execution. Part of the API router implementation for handling query-related operations.",
        "size": 800,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "4530c2f53987221843de3bc45c345e7bb5de6dc80d40b368ef586d7594bfbbb4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.models.schemas.random_query_schema import RandomQueryRequest\nfrom app.controllers.random_query_controller import RandomQueryController\n\nImport statements for a FastAPI router module handling random query functionality, importing core FastAPI components, custom error handling, schema validation, and controller dependencies.",
        "size": 477,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "67d5a5721ec1a272d7df4f360faedd5ac18a36854324a5b96725967d1ab87046",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_query_route.py",
        "file_name": "random_query_route.py",
        "start_line": 13,
        "end_line": 28,
        "content": "async def random_query(\n    request: RandomQueryRequest,\n    random_query_controller: RandomQueryController = Depends(),\n):\n\n    response = await random_query_controller.random_query(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Query Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler function for the \"/random-query\" route that processes RandomQueryRequest objects, delegates processing to RandomQueryController, and returns a structured JSONResponse with the query results. The function is decorated with error handling and utilizes FastAPI's dependency injection system for controller instantiation.",
        "size": 813,
        "parent-class": null,
        "function_name": "random_query"
    },
    {
        "id": "434420bbba938cc92e8c69d674d6c634a6fce1624f489c68e67db4fddee60505",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.random_question_controller import RandomQuestionController\n\nImport statements for a FastAPI endpoint that generates random questions. Imports FastAPI components for routing and responses, Pydantic for request validation, custom error handling, and the controller responsible for random question generation logic.",
        "size": 508,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "a7b474d8417ec27adb73705b1c1a3ede40957d55e28511ae970c188aded47f98",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/random_question_route.py",
        "file_name": "random_question_route.py",
        "start_line": 16,
        "end_line": 31,
        "content": "async def random_question(\n    request: RQRequest,\n    random_question_controller: RandomQuestionController=Depends(),\n):\n\n    response = await random_question_controller.random_question(request.file_name)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"response\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Random Question Generated Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler function that processes random question generation requests. Accepts a request containing a file_name parameter, delegates processing to a RandomQuestionController instance, and returns a structured JSON response with the generated question. Route is defined at \"/random-question\" as a POST endpoint with error handling via decorator.",
        "size": 847,
        "parent-class": null,
        "function_name": "random_question"
    },
    {
        "id": "4143aa5d609c26199b51af5fe4b22530151f305f9dcda9a86c7ae847c2964e8d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/configuration_route.py",
        "file_name": "configuration_route.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.config_controller import ConfigurationController\n\nImports required modules for a FastAPI configuration API endpoint, including core FastAPI components, error handling utilities, and the ConfigurationController that will process configuration-related operations.",
        "size": 426,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "3ad54080bdac8d559055daf67b4147d81d51fd0eda398a9f548054b25449f6a6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/configuration_route.py",
        "file_name": "configuration_route.py",
        "start_line": 11,
        "end_line": 25,
        "content": "async def make_query(\n    config_controller: ConfigurationController = Depends()\n):\n\n    response_data = await config_controller.get_config()\n\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": \"Configuration fetching successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler function that retrieves configuration data using a ConfigurationController dependency, then returns a successful JSON response with the configuration data. This function is associated with a GET route at \"/get-configurations\" and is decorated with an error handler. The response includes status code 200, retrieved configuration data, and a success message.",
        "size": 777,
        "parent-class": null,
        "function_name": "make_query"
    },
    {
        "id": "74bb0477a82c57a67c762acb064b14b53b7e4eea1c5d66cc8ccfe3da89771d3a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Body, Depends,status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.reranking_controller import RerankingController\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest\n)\n\nImport statements for a FastAPI API router handling document reranking functionality. Imports the necessary components for request processing, response handling, error management, and data validation. References the RerankingController class and RerankingRequest schema model that define the core reranking implementation and request structure.",
        "size": 636,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "e9a5af5c47e00db05926efdf91c6f9c5f45077a8f65264587cc8370653f21887",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/reranking_router.py",
        "file_name": "reranking_router.py",
        "start_line": 15,
        "end_line": 31,
        "content": "async def rerank_documents(\n    request: RerankingRequest = Body(...),\n    controller: RerankingController = Depends(),\n):\n    \n    response_data = await controller.rerank_documents(request)\n    response = response_data.model_dump()\n\n    return JSONResponse(\n        content={\n            \"data\": response,\n            \"statuscode\": 200,\n            \"detail\": \"Rerank execution successful!\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI route handler function that processes document reranking requests by accepting a RerankingRequest payload, delegating processing to a RerankingController, and returning a standardized JSON response with the reranked results. Used within an API router with error handling decoration to expose document reranking functionality at the \"/rerank\" endpoint.",
        "size": 834,
        "parent-class": null,
        "function_name": "rerank_documents"
    },
    {
        "id": "8ab55feaabcc01f59e6f8923216e2c7f95775125375b32129a7c3f92e2a6c445",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, status\nfrom fastapi.responses import JSONResponse\nfrom app.utils.error_handler import handle_exceptions\nfrom app.controllers.index_upsert_controller import IndexUpsertController\nfrom app.models.schemas.index_upsert_schema import IndexUpsertRequest\n\nImport statements for FastAPI router implementation handling index upsert operations, including dependencies, response formatting, error handling, controller logic, and schema validation components.",
        "size": 487,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "7bc30b159aa18165682968b657ff138de2b3c5e0e0bd97682efe39aa413e3cb6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/index_upsert_route.py",
        "file_name": "index_upsert_route.py",
        "start_line": 13,
        "end_line": 30,
        "content": "async def index_upsert(\n    request: IndexUpsertRequest,\n    index_upsert_controller: IndexUpsertController = Depends(\n        IndexUpsertController\n    ),\n):\n    \n    response = await index_upsert_controller.index_upsert(request)\n\n    return JSONResponse(\n        content={\n            \"data\": {\"host\": response},\n            \"status_code\": status.HTTP_200_OK,\n            \"detail\": \"Upserted Successfully\",\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI route handler function for document indexing or updating operations. Receives an IndexUpsertRequest and delegates processing to the IndexUpsertController. Returns a standardized JSON response with success status upon completion of the upsert operation. Part of an API router implementing REST endpoints for document management functionality.",
        "size": 841,
        "parent-class": null,
        "function_name": "index_upsert"
    },
    {
        "id": "de8501eee0b63f3c61c79447f9abd94f7c1c686384ca4f8b7dae2dbf403e060b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import APIRouter, Depends, UploadFile, File, status, Form\nfrom fastapi.responses import JSONResponse\nfrom app.controllers.file_upload_controller import FileUploadController\nfrom app.utils.error_handler import handle_exceptions\nimport logging\n\nFastAPI route file imports for file upload functionality, including dependencies for routing, form handling, file uploads, response formatting, error handling, and logging setup within the application's API structure.",
        "size": 473,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "875226f3e7eb48b7fecbb298035bcdda0507e96640d900b9b6d99b2d8be62ed8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/apis/file_upload.py",
        "file_name": "file_upload.py",
        "start_line": 14,
        "end_line": 32,
        "content": "async def upload_files(\n    file_type: str = Form(),\n    file: UploadFile = File(...),\n    file_controller: FileUploadController = Depends(),\n):\n    response_data = await file_controller.upload_files({\n        \"input_data\": file,\n        \"file_name\": file.filename,\n        \"file_type\": file_type\n    })\n    return JSONResponse(\n        content={\n            \"data\": response_data,\n            \"statuscode\": 200,\n            \"detail\": response_data[\"data\"],\n            \"error\": \"\",\n        },\n        status_code=status.HTTP_200_OK,\n    )\n\nFastAPI endpoint handler for file uploads that accepts file_type as a form field and a file as an upload. Uses dependency injection to access FileUploadController, processes the upload, and returns a standardized JSON response with status code 200. This function is defined within a router module and decorated with @handle_exceptions for error handling.",
        "size": 895,
        "parent-class": null,
        "function_name": "upload_files"
    },
    {
        "id": "345f48f7d51fe8682a5033c39e57c477d68afb947e67b47a5ce0019ba9237914",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from motor.motor_asyncio import AsyncIOMotorClient\nfrom app.config.settings import settings\n\nMongoDB connection imports for an asynchronous database helper, importing AsyncIOMotorClient and application settings that contain database configuration parameters.",
        "size": 258,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b3f88c227f4a75ff0a14a836a24b2652b3cb364597b3e9b72c4437e33325c4ff",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 7,
        "end_line": 13,
        "content": "def __init__(self):\n        self.client = AsyncIOMotorClient(settings.MONGODB_URL)\n        self.db = self.client[settings.DATABASE_NAME]\n        self.raw_data = self.db[\"raw_data\"]\n        self.index_upsert_collection = self.db[\"index_upsert\"]\n        self.gt_data = self.db[\"gt_data\"]\n        self.query_embeddings_collection = self.db[\"query_embeddings\"]\n\nMongoDB database initialization constructor in DBHelper class that establishes connection with AsyncIOMotorClient and sets up references to collections including raw_data, index_upsert, gt_data, and query_embeddings for asynchronous database operations.",
        "size": 611,
        "parent-class": "DBHelper",
        "function_name": "__init__"
    },
    {
        "id": "1f18e25dff987db907be909f34ded28cb73177db867d3ff4eb9d86324a4f55a3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 15,
        "end_line": 33,
        "content": "async def connect(self):\n        try:\n            if self.client is None:\n                self.client = AsyncIOMotorClient(\n                    settings.MONGODB_URL,\n                    maxPoolSize=1000,\n                    minPoolSize=50,\n                    maxIdleTimeMS=50000,\n                    connectTimeoutMS=20000,\n                )\n\n                self.db = self.client[settings.DATABASE_NAME]\n                await self.client.admin.command(\"ping\")\n                await self.create_collections()\n\n        except Exception as e:\n            if self.client:\n                await self.disconnect()\n            raise\n\nMongoDB connection method within the DBHelper class that establishes an AsyncIOMotorClient connection with specific pool settings, pings the admin database to verify connectivity, and initializes required collections. Includes error handling that disconnects on failure. Part of the database abstraction layer for an asynchronous MongoDB implementation.",
        "size": 982,
        "parent-class": "DBHelper",
        "function_name": "connect"
    },
    {
        "id": "13becea9128bf7fa05556dcad26343d9ba21c345f64dcc75d5dbb109ca746b79",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 35,
        "end_line": 40,
        "content": "async def create_collections(self):\n        required_collections = [\"raw_data\", \"gt_data\"]\n        existing_collections = await self.db.list_collection_names()\n        for collection in required_collections:\n            if collection not in existing_collections:\n                await self.db.create_collection(collection)\n\nMongoDB helper method that ensures required collections exist by checking against existing collections and creating any missing ones. Part of the DBHelper class initialization process for setting up the database structure.",
        "size": 546,
        "parent-class": "DBHelper",
        "function_name": "create_collections"
    },
    {
        "id": "6fb45cf05887e0eb1cfc6daf486c11203b5d52e653cf37580cd6a873f73c6642",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 42,
        "end_line": 45,
        "content": "async def get_db(self):\n        if self.client is None:\n            await self.connect()\n        return self.db\n\nMongoDB database connection method that ensures a client connection exists, initializing it if needed, and returns the database instance for performing operations on MongoDB collections like raw_data, gt_data, and others in an asynchronous context.",
        "size": 361,
        "parent-class": "DBHelper",
        "function_name": "get_db"
    },
    {
        "id": "41203c1418fb66992d29bd26d94bccfa1b6743b88f092dfd81c142879aeee0b8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/database.py",
        "file_name": "database.py",
        "start_line": 47,
        "end_line": 51,
        "content": "async def disconnect(self):\n        if self.client:\n            self.client.close()\n            self.client = None\n            self.db = None\n\nMongoDB connection cleanup method in DBHelper class that closes the client connection and resets client and database attributes to None when the application disconnects from the database.",
        "size": 330,
        "parent-class": "DBHelper",
        "function_name": "disconnect"
    },
    {
        "id": "22b6c6a3e77fc69106fa80c11fccea98a58062af33139f0a8fd186e66624186e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/config/settings.py",
        "file_name": "settings.py",
        "start_line": 1,
        "end_line": 1,
        "content": "from pydantic_settings import BaseSettings\n\nPython import statement for BaseSettings from pydantic_settings library, used to create the Settings class for environment variable management in this application that handles API keys, URLs, and configuration parameters for RAG systems.",
        "size": 281,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c5434f4351467a90be709a31c58a785de5df82bdcce1530fafe56332caf3808f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import os\nimport json\nimport logging\nfrom datetime import datetime\n\nPackage imports for a logging module that includes standard Python libraries for operating system interactions, JSON parsing, logging functionality, and datetime handling, used in the implementation of a custom JSON-based logging system.",
        "size": 305,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "61ac248d713f099d32df2824017c87b7fa79ed2ad69bd4cb8897deae385e7009",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 8,
        "end_line": 27,
        "content": "def format(self, record):\n        log_entry = {\n            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n            \"levelname\": record.levelname,\n            \"module\": record.module,\n            \"funcName\": record.funcName,\n            \"lineno\": record.lineno\n        }\n\n        message = record.getMessage()\n        try:\n            parsed_message = json.loads(message)\n            log_entry[\"message\"] = json.dumps(parsed_message, indent=4, ensure_ascii=False)\n        except json.JSONDecodeError:\n            log_entry[\"message\"] = message\n        \n        if record.args:\n            log_entry[\"extra\"] = record.args\n            \n        return json.dumps(log_entry, ensure_ascii = False, indent=4)\n\nFormat method in JSONFormatter class that transforms logging records into structured JSON format. Creates a log entry dictionary with timestamp, level, module, function name and line number. Attempts to parse the message as JSON, falling back to raw text if parsing fails. Adds extra arguments if present. Returns a formatted JSON string with indentation and non-ASCII character support.",
        "size": 1107,
        "parent-class": "JSONFormatter",
        "function_name": "format"
    },
    {
        "id": "c800a648287d8f57c2b09ea7470c99242d5cc920d0dfb1ccd96c0abd12d955aa",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/logging_util.py",
        "file_name": "logging_util.py",
        "start_line": 29,
        "end_line": 52,
        "content": "def setup_logger(name: str, log_file: str, log_dir: str = \"struct_logs\", level=logging.INFO) -> logging.Logger:\n    \"\"\"\n    Sets up a logger with a specified name and log file.\n    \n    Args:\n        name (str): The name of the logger.\n        log_file (str): The name of the log file.\n        log_dir (str): Directory where logs will be stored.\n        level (int): Logging level (default: logging.INFO).\n    \n    Returns:\n        logging.Logger: Configured logger instance.\n    \"\"\"\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    handler = logging.FileHandler(log_path)\n    handler.setFormatter(JSONFormatter())\n\n    logger.addHandler(handler)\n    return logger\n\nFunction that creates and configures a logging system with JSON formatting. Creates the log directory if needed, sets up a logger with specified name, assigns a file handler with the custom JSONFormatter, and configures the logging level. Used to initialize all the specialized loggers defined in the loggers dictionary for services like Pinecone, OpenAI, and Cohere.",
        "size": 1141,
        "parent-class": null,
        "function_name": "setup_logger"
    },
    {
        "id": "28cf4662f57f1264fdf55232551c9bcb43c3ea114ddd298f52af767ee4da41b5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nfrom typing import Dict, List\nimport httpx\nfrom app.config.settings import Settings\nfrom app.prompts import rag_generation\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers\n\nImport statements for the LLMUtils class module that handles OpenAI API interactions. Imports necessary libraries for HTTP requests, JSON processing, typing, logging, and application-specific modules for settings, prompts, and error handling.",
        "size": 470,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "61331708401cbe92d9fb9a56152bc4a8c7e220b53b1e404b340aee8568c307e3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 11,
        "end_line": 24,
        "content": "def __init__(self):\n        self.settings = Settings()\n        self.rag_generation = rag_generation\n        self.OPENAI_BASE_URL = self.settings.OPENAI_BASE_URL \n        self.model = self.settings.OPENAI_MODEL\n        self.openai_api_key = self.settings.OPENAI_API_KEY\n        self.OPENAI_CHAT_SUFFIX = \"chat/completions\"\n        self.openai_url = f\"{self.OPENAI_BASE_URL}/{self.OPENAI_CHAT_SUFFIX}\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nInitialization method for the LLMUtils class that sets up OpenAI API connection parameters, including base URL, model selection, API key, timeouts, and endpoints. Configures the httpx client timeout settings for API communication with detailed connection parameters for establishing, reading, writing, and pool connections.",
        "size": 1067,
        "parent-class": "LLMUtils",
        "function_name": "__init__"
    },
    {
        "id": "d7ce31b9a94cf4ff7e58654474988b621105c88a9aa9bf56b234f89f26a35820",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 26,
        "end_line": 53,
        "content": "async def _make_openai_request(\n        self, messages: List[Dict[str, str]], **params\n    ):\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.openai_api_key}\",\n        }\n\n        data = {\"model\": self.model, \"messages\": messages, **params}\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(\n                    self.openai_url, headers=headers, json=data\n                )\n                \n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {e.response.text}\")\n            raise HTTPException(detail = f\"error in openai call httpx error : {str(e)} - {e.response.text}\", status_code = e.response.status_code)\n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\n        except Exception as e:\n            loggers[\"main\"].error(f\"error in openai call httpx error : {str(e)}\")\n            raise HTTPException(detail=str(e), status_code=500)\n\nCore asynchronous method in LLMUtils class that handles API communication with OpenAI. Constructs HTTP requests with proper headers, sends payload to the OpenAI API endpoint, and manages response handling. Includes comprehensive error handling for different types of HTTP errors with appropriate logging and exception propagation. Used as a foundation for higher-level methods like generate_questions and generate_multi_chunk_question that implement specific LLM functionality.",
        "size": 1750,
        "parent-class": "LLMUtils",
        "function_name": "_make_openai_request"
    },
    {
        "id": "dbdc3d4ed0328e7328fa502d1e11f095efe51b1436bc9b59f518a79bb781779a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 55,
        "end_line": 80,
        "content": "async def generate_questions(self, chunk: str):\n        user_msg = f\"Text chunk:\\n{chunk}\"\n\n        response = await self._make_openai_request(\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": self.rag_generation.GENERATE_QUESTIONS_PROMPT,\n                },\n                {\"role\": \"user\", \"content\": user_msg}\n            ],\n            temperature=0.3,\n            max_tokens=512\n        )\n        print(json.dumps(response, indent=4))\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n\n\n        if \"error\" in response:\n            return [\"Could not generate questions - API error\"]\n\n        content = response[\"choices\"][0][\"message\"][\"content\"]\n        return [q.strip() for q in content.split(\"\\n\") if q.strip()]\n\nAsynchronous method in LLMUtils class that generates questions based on a text chunk by making API calls to OpenAI. Takes a text chunk as input, formats a request with specific system prompts, parameters, and user message, then processes the response to extract a list of questions. Includes error handling and logging of token usage.",
        "size": 1177,
        "parent-class": "LLMUtils",
        "function_name": "generate_questions"
    },
    {
        "id": "9f2bc1f157cf2226810163abd92326d066610bd0af1c62ce2bbc5c59c0293d2e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 82,
        "end_line": 123,
        "content": "async def generate_multi_chunk_question(self, data: dict):\n        formatted_chunks = \"\\n\\n\".join(\n            f\"Chunk ID: {c['_id']}\\nContent: {c['text']}\" for c in data[\"chunks\"]\n        )\n        if data[\"file_type\"] == 'Text':\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_TXT\n        if data[\"file_type\"] == \"Code\":\n            content = self.rag_generation.GEN_MULTI_CHUNK_QUE_CODE\n\n        messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": content,\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Text chunks:\\n{formatted_chunks}\"\n                }\n            ]\n        \n        response = await self._make_openai_request(\n            messages=messages,\n            temperature=0.7,\n            max_tokens=1024\n        )\n\n        tokens_usage = response[\"usage\"]\n        loggers[\"openai\"].info(json.dumps(tokens_usage, indent=4))\n\n        if \"error\" in response:\n            return {\n                \"question\": \"Could not generate question - API error\",\n                \"relevant_ids\": [\n                    data[\"chunks\"][0][\"_id\"], \n                    data[\"chunks\"][1][\"_id\"]\n                ] if len(data[\"chunks\"]) >= 2 else []\n            }\n        loggers[\"main\"].info(f\"response_json from generate multi : {response}\")\n\n        raw_content = response[\"choices\"][0][\"message\"][\"content\"]\n        loggers[\"main\"].info(raw_content)\n        return self._parse_multi_chunk_response(raw_content, data)\n\nMethod within LLMUtils class that generates questions from multiple text chunks. Takes a dictionary containing chunks and file type, formats the chunks, selects appropriate prompt based on file type (text or code), makes an API request to OpenAI, logs token usage, handles errors, and parses the response using the _parse_multi_chunk_response helper method. Used for RAG (Retrieval-Augmented Generation) systems to create contextually relevant questions from multiple document fragments.",
        "size": 2026,
        "parent-class": "LLMUtils",
        "function_name": "generate_multi_chunk_question"
    },
    {
        "id": "bb369c6b3a2f370a944d8f4c1a2279be0faea181c76c8dfeb68023e092b59f49",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/llm_utils.py",
        "file_name": "llm_utils.py",
        "start_line": 125,
        "end_line": 145,
        "content": "def _parse_multi_chunk_response(self, raw_content: str, chunks: List[Dict]):\n        try:\n            questions = json.loads(raw_content)\n            if not isinstance(questions, list):\n                raise ValueError(\"Expected a list of questions\")\n            \n            result_list = []\n            for q in questions:\n                if \"question\" not in q or \"chunk_ids\" not in q:\n                    raise ValueError(\"Missing required fields in question item\")\n                    \n                result_list.append({\n                    \"question\": q[\"question\"].strip(),\n                    \"relevant_ids\": [str(id) for id in q[\"chunk_ids\"]]\n                })\n            return result_list\n        except (json.JSONDecodeError, ValueError):\n            return {\n                \"question\": raw_content.strip(),\n                \"relevant_ids\": [c[\"_id\"] for c in chunks[:2]]\n            }\n\nMethod in LLMUtils class that parses JSON responses from LLM multi-chunk question generation. Extracts structured question data and associated chunk IDs, validates format, handles errors by falling back to raw content with default chunk IDs. Part of a RAG system for processing multiple text chunks simultaneously. Used in conjunction with generate_multi_chunk_question method.",
        "size": 1280,
        "parent-class": "LLMUtils",
        "function_name": "_parse_multi_chunk_response"
    },
    {
        "id": "526a8224be3af6a8087a92a48bbe60de72c8fad2470a86f5ccebfb8d8e15a8cc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi.responses import JSONResponse\nfrom functools import wraps\nfrom fastapi import status\n\nImport statements for a FastAPI exception handler module, bringing in JSONResponse for HTTP response formatting, wraps from functools for preserving function metadata in decorators, and status constants from FastAPI for standardized HTTP status codes.",
        "size": 350,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ca755c034146d993d36a5ec14de24baa11a14d10cc9bd3ba93a7123a7bb1c011",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/utils/error_handler.py",
        "file_name": "error_handler.py",
        "start_line": 5,
        "end_line": 21,
        "content": "def handle_exceptions(func):\n    \"\"\"A decorator to catch exceptions and return a consistent JSON error response.\"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except Exception as e:\n            return JSONResponse(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                content={\n                    \"data\": {},\n                    \"statuscode\": 500,\n                    \"detail\": \"An internal server error occurred.\",\n                    \"error\": str(e),\n                },\n            )\n    return wrapper\n\nDecorator function for FastAPI endpoint handlers that wraps API functions in a try-except block, catching all exceptions and converting them to consistent JSONResponse objects with HTTP 500 status code, standardized error details, and the original exception message. Uses functools.wraps to preserve the original function's metadata.",
        "size": 952,
        "parent-class": null,
        "function_name": "handle_exceptions"
    },
    {
        "id": "aeb2e3692e43bc63f9d17aae01e6b6055dcf191cc8af6b4af3d6d02368d13ae2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException\nfrom app.utils.logging_util import loggers\n\nDatabase import and utility module imports for the IndexRepository class in a FastAPI application. These imports provide access to database helper functions, HTTP exception handling, and logging capabilities used throughout the repository.",
        "size": 359,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5a117d2f8a976f5c2e32deabe70ca52cafbc4a1706580db4c153de2ba8f1eda5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 6,
        "end_line": 9,
        "content": "def __init__(self):\n        self.ground_truth_collection = db_helper.gt_data\n        self.raw_collection = db_helper.raw_data\n        self.index_info_collection = db_helper.index_upsert_collection\n\nIndexRepository initialization method that establishes database collection connections for ground truth data, raw data, and index information using the db_helper module. Sets up essential database access points used throughout repository operations for querying and retrieving vector database metadata.",
        "size": 500,
        "parent-class": "IndexRepository",
        "function_name": "__init__"
    },
    {
        "id": "50385903f1dbe4c532cba64da0ee59db60e2037e6ba67a69ce61cdb98b3f5260",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 11,
        "end_line": 27,
        "content": "async def fetch_ground_truth(self, query):\n\n        query = {\"question\": query}\n\n        ground_truth_doc = await self.ground_truth_collection.find_one(query)\n\n        ground_truth_ids = []\n        for x in ground_truth_doc[\"chunks\"]:\n            ground_truth_ids.append(x[\"_id\"])\n            \n        ground_truth = []\n        for _id in ground_truth_ids:\n            chunk = await self.raw_collection.find_one({\"_id\": _id})\n\n            ground_truth.append({\"id\": _id, \"chunk\": chunk[\"text_content\"]})\n\n        return ground_truth\n\nDatabase repository method that retrieves ground truth data for evaluation purposes. It queries a MongoDB collection to find document chunks that represent the ground truth for a given question, extracting their IDs and then fetching the corresponding chunk content from a raw data collection. Used for comparing retrieval results against known relevant documents.",
        "size": 898,
        "parent-class": "IndexRepository",
        "function_name": "fetch_ground_truth"
    },
    {
        "id": "98e487721b31d06e495e6ee9bf0ece834791b23333aa448bd5df03272f75188e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 29,
        "end_line": 56,
        "content": "async def get_namespace_and_host(\n        self, index_name: str, embedding_model: str, filename: str\n    ):\n\n        query = {\n            \"index_name\": index_name,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": filename,\n                    \"details.embedding_model\": embedding_model,\n                }\n            },\n        }\n\n        document = await self.index_info_collection.find_one(query)\n        \n        if document is None:\n            return None, None\n        \n        namespace_name = None\n        namespaces = document[\"namespaces\"]\n        for namespace in namespaces:\n            if namespace['details']['embedding_model'] == embedding_model and namespace['details']['filename'] == filename:\n                namespace_name = namespace[\"name\"]\n\n        host = document[\"index_host\"]\n\n        return namespace_name, host\n\nMongoDB query method in IndexRepository class that retrieves namespace details and host information for a vector search index based on index name, embedding model, and filename parameters. Uses MongoDB's $elemMatch operator to find matching documents in the index_info_collection, then extracts the appropriate namespace name by iterating through namespaces that match the specified criteria.",
        "size": 1283,
        "parent-class": "IndexRepository",
        "function_name": "get_namespace_and_host"
    },
    {
        "id": "80068762ae52bd55e32a0880bf5928b92a277866270829b0eb2650a314e676cb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 58,
        "end_line": 84,
        "content": "async def fetch_questions(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.ground_truth_collection.find_one(file_query)\n            \n            if not file_doc:\n                raise HTTPException(status_code=404, detail=\"File not found\")\n            \n            questions_with_ground_truth = []\n\n            data_doc = file_doc[\"data\"]\n\n            for document in data_doc:\n                question = document['question']\n                ground_truth_chunk_ids = [chunk['_id'] for chunk in document['chunks']]\n                questions_with_ground_truth.append({\n                    'question': question,\n                    'ground_truth_chunk_ids': ground_truth_chunk_ids\n                })\n            loggers[\"main\"].info(f\"length of questions with ground truth : {len(questions_with_ground_truth)}\")\n\n            return questions_with_ground_truth\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nDatabase repository method that retrieves question data with associated ground truth chunk IDs from MongoDB. Queries the ground_truth_collection using a file name, extracts question-chunk relationships from the document structure, and returns a formatted list of questions with their corresponding ground truth identifiers. Part of the IndexRepository class used for managing search index data and ground truth references.",
        "size": 1486,
        "parent-class": "IndexRepository",
        "function_name": "fetch_questions"
    },
    {
        "id": "b23cee46e7119423a11b6ff85d278cc55b1d4b2d3d464e4d976985ac17d648da",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 86,
        "end_line": 96,
        "content": "async def fetch_total_chunks(self, file_name: str):\n        try:\n            file_query = {\n                \"file_name\" : file_name\n            }\n            file_doc = await self.raw_collection.find_one(file_query)\n            \n            return len(file_doc[\"data\"])\n            \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in the IndexRepository class that retrieves the total number of chunks for a given file by querying the raw_collection database. It constructs a query using the file_name parameter, retrieves the document, and returns the count of elements in the \"data\" array. Error handling includes throwing an HTTPException with appropriate status code and message if the operation fails.",
        "size": 761,
        "parent-class": "IndexRepository",
        "function_name": "fetch_total_chunks"
    },
    {
        "id": "217a018a3898a21e5d348b6f24d5514ea9d32682580d7af893214fe47dc3831a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_repository.py",
        "file_name": "index_repository.py",
        "start_line": 98,
        "end_line": 137,
        "content": "async def fetch_user_previous_configurations(self):\n\n        collection_names = await db_helper.db.list_collection_names()\n        if \"index_upsert\" not in collection_names:\n            return {\"message\": \"You have no previous configurations.\"}\n    \n        count = await self.index_info_collection.count_documents({})\n        if count == 0:\n            return {\"message\": \"You have no previous configurations.\"}\n        \n\n\n        try:\n            cursor = self.index_info_collection.find(\n                {}, \n                {\n                    \"index_name\" : 1, \n                    \"dimension\" : 1, \n                    \"similarity_metric\" : 1, \n                    \"namespaces.details.filename\" : 1, \n                    \"namespaces.details.embedding_model\" : 1\n                }\n            )\n            \n            configurations = []\n            async for doc in cursor:\n                configurations.append(\n                    {\n                        \"index_name\" : doc[\"index_name\"],\n                        \"dimension\" : doc[\"dimension\"],\n                        \"similarity_metric\" : doc[\"similarity_metric\"],\n                        \"filename\" : [namespace[\"details\"][\"filename\"] for namespace in doc[\"namespaces\"]],\n                        \"embedding_model\" : [namespace[\"details\"][\"embedding_model\"] for namespace in doc[\"namespaces\"]]\n                    }\n                )\n                \n            return configurations\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Error in fetching previous configurations: {str(e)}\")\n\nRepository method that retrieves user's previous vector index configurations from MongoDB. Checks if the index_upsert collection exists, verifies it contains documents, then queries and formats index configuration data including index names, dimensions, similarity metrics, filenames, and embedding models. Returns either a formatted list of configurations or appropriate message if none exist. Implements error handling with HTTP exceptions.",
        "size": 2046,
        "parent-class": "IndexRepository",
        "function_name": "fetch_user_previous_configurations"
    },
    {
        "id": "eac311fb1cf82a2dd89ea793d4f8bcbe2411509f9de9f7f29e3e668dd45a90ce",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from app.config.database import db_helper\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers\n\nImport statements for MongoDB database connectivity, FastAPI error handling, and custom logging utilities in a raw data repository module. These imports enable database operations, exception handling, and logging functionality for the RawDataRepo class.",
        "size": 381,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9947e068f0dfffd8a75e31f13244af3f962b3afb67846f3ccd962f304b9dae42",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.raw_data\n\nRepository class constructor that initializes access to the raw_data MongoDB collection through the db_helper database connection object",
        "size": 202,
        "parent-class": "RawDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "bc3e08e71d45dc8ae3d0e28b0e80b1e8a796aef4fc64a098741abf715013ecf7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})\n\nRepository method that deletes all documents from the raw_data MongoDB collection, completely emptying it by using the delete_many operation with an empty filter criteria.",
        "size": 252,
        "parent-class": "RawDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "8d3f9557eb1598718709f2e0db3f737f63d7cee4ec29cce72f0d2472acaae3f8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 13,
        "end_line": 14,
        "content": "async def insert_documents(self, document: dict):\n        await self.collection.insert_one(document)\n\nMethod in the RawDataRepo class that inserts a single document into the MongoDB raw_data collection via an asynchronous database operation. Part of the repository pattern implementation for handling raw data storage operations.",
        "size": 329,
        "parent-class": "RawDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "449a6c679673cebec485888ee9d0b7ce263a0edb53f12df3bf22e9a874fbdf2a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 16,
        "end_line": 21,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)\n\nMongoDB repository method that checks for document existence by file name and type, returning the matching document or None. Part of the RawDataRepo class used for interacting with the raw_data collection.",
        "size": 416,
        "parent-class": "RawDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "eacdb958e77a8e5571eab0255196919ffbc9ecb1d02365f446995fdbba94c023",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/raw_data_repo.py",
        "file_name": "raw_data_repo.py",
        "start_line": 23,
        "end_line": 41,
        "content": "async def fetch_texts_by_ids(self,file_name: str, ids: list):\n        try:\n            \n            query = {\"file_name\": file_name}\n            ids_list = []\n            # projection = {\"data.$\": 1}  # Use positional projection to get the matching element\n            document = await self.collection.find_one(query)\n            for doc in document[\"data\"]:\n                if doc[\"_id\"] in ids:\n                    ids_list.append(doc[\"text\"])\n            # print(document)\n            return ids_list\n            # if document and \"data\" in document and document[\"data\"]:\n            #     return document[\"data\"][0][\"text\"]\n            \n\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside fetch_texts_by_ids error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\nMongoDB repository method that retrieves text content from documents by matching file name and specific document IDs. Queries the database for documents with the specified file name, then filters the returned document's data array to extract only texts whose _id matches the provided IDs list. Returns a list of matching text entries. Includes error handling with logging and appropriate HTTP exception responses.",
        "size": 1266,
        "parent-class": "RawDataRepo",
        "function_name": "fetch_texts_by_ids"
    },
    {
        "id": "0a72a96da08961a5f86a4a8d0e8af91665ee38e6d0eb204051c1ca0ac539df90",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.queryembed import QueryEmbeddings\nimport time\nfrom datetime import datetime, timezone\nfrom app.utils.logging_util import loggers\n\nImport statements for the QueryRepository class that manages database operations for query embeddings. Includes FastAPI HTTP exception handling, database connection, data models, time tracking utilities, datetime functionality with timezone support, and logging capabilities.",
        "size": 504,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "f7eefb7d2e1ff4390040eff98cb05c44fdcdd94c74250e458af88e2f4d2273b3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 13,
        "end_line": 14,
        "content": "def __init__(self):\n        self.collection = db_helper.query_embeddings_collection\n\nDatabase repository class constructor that initializes a MongoDB collection connection for storing and retrieving query embeddings, utilizing the query_embeddings_collection from the database helper.",
        "size": 284,
        "parent-class": "QueryRepository",
        "function_name": "__init__"
    },
    {
        "id": "9788cadbb82ed2b96c7ff05f0edc0264156145bf6259c6aa1ca7026fd18e04f2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 16,
        "end_line": 57,
        "content": "async def insert_or_update_embeddings(\n        self,\n        query_embeddings: QueryEmbeddings\n    ):\n        \"\"\"\n        Upsert embeddings - either update existing document or create new one\n        \"\"\"\n        try:\n            # Construct the unique identifier for the document\n            filter_query = {\n                \"filename\": query_embeddings.filename,\n                \"embedding_model\": query_embeddings.embedding_model,\n                \"dimension\": query_embeddings.dimension\n            }\n            \n            # Prepare the update operation\n            update_query = {\n                \"$set\": {\n                    \"filename\": query_embeddings.filename,\n                    \"embedding_model\": query_embeddings.embedding_model,\n                    \"dimension\": query_embeddings.dimension,\n                    \"updated_at\": datetime.now(timezone.utc).isoformat()\n                },\n                \"$addToSet\": {\n                    \"questions\": {\n                        \"$each\": query_embeddings.questions\n                    }\n                }\n            }\n            \n            # Perform upsert operation\n            result = await self.collection.update_one(\n                filter_query, \n                update_query, \n                upsert=True\n            )\n            \n            # Return the upserted or updated document's ID\n            return str(result.upserted_id) if result.upserted_id else str(result.modified_count)\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in upserting query embeds: {str(e)}\")\n\nMongoDB upsert method for query embeddings that identifies documents by filename, embedding model, and dimension. Updates existing records with new timestamp while appending questions using $addToSet operator, or creates new documents when no match exists. Returns either the new document ID or modification count, with exception handling for database operations.",
        "size": 1965,
        "parent-class": "QueryRepository",
        "function_name": "insert_or_update_embeddings"
    },
    {
        "id": "e14702bca8894f4b7474f6b08ab8c9bc0b4c62b7db69bb8f12b06952fb71c769",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/query_repository.py",
        "file_name": "query_repository.py",
        "start_line": 70,
        "end_line": 111,
        "content": "async def retrieve_question_embeddings(\n        self,\n        file_name: str,\n        embed_model: str,\n        dimension: int,\n        question_text: str \n    ):\n        query = {\n            \"filename\": file_name,\n            \"embedding_model\": embed_model,\n            \"dimension\": dimension,\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        projection = {\n            \"questions\": {\n                \"$elemMatch\": {\n                    \"question_text\": question_text\n                }\n            }\n        }\n\n        \n        try:\n            s = time.time()\n            document = await self.collection.find_one(query, projection)\n            if document is None:\n                return None\n            \n            matching_questions = document.get('questions', [])\n            if matching_questions:\n                return matching_questions[0].get('embedding')\n            e = time.time()\n            loggers[\"main\"].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n            return None\n        \n        except Exception as e:\n            raise HTTPException(status_code=400, detail=f\"Error in retrieving query embeds in motor : {str(e)}\")\n\nMongoDB query method in QueryRepository class that retrieves question embedding vectors by searching for exact question text matches. Uses MongoDB's $elemMatch operator to find specific questions within a document identified by filename, embedding model, and dimension parameters. Implements performance timing and error handling with HTTP exceptions. Returns the embedding vector for a specific question or None if not found.",
        "size": 1715,
        "parent-class": "QueryRepository",
        "function_name": "retrieve_question_embeddings"
    },
    {
        "id": "5e567e9ee6a28d9c045ae968ecd05deb77a1a55bc6dc27127edca68cf9d49fd7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import HTTPException\nfrom app.config.database import db_helper\nfrom app.models.domain.indexupsert import IndexUpsert\n\nMongoDB repository import statements for the IndexUpsertRepository class, defining dependencies on FastAPI error handling, database connection helper, and the IndexUpsert domain model used for managing vector index metadata storage operations.",
        "size": 374,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5597637039335252acd30fd1964400becef61f575c801012483168c98c7b6336",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self):\n        self.collection = db_helper.index_upsert_collection\n\nConstructor method for IndexUpsertRepository class that initializes a MongoDB collection reference to the index_upsert_collection from the database helper to manage vector index upsert operations.",
        "size": 277,
        "parent-class": "IndexUpsertRepository",
        "function_name": "__init__"
    },
    {
        "id": "7f254f46a44a24028da3254fdf6b5cdf45225c88d254438afa1d7d591f689ba2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 12,
        "end_line": 30,
        "content": "async def find_matching_index_upsert(\n        self,\n        dimension: str,\n        similarity_metric: str,\n        file_name: str,\n        embed_model: str,\n    ):\n        query = {\n            \"dimension\": dimension,\n            \"similarity_metric\": similarity_metric,\n            \"namespaces\": {\n                \"$elemMatch\": {\n                    \"details.filename\": file_name,\n                    \"details.embedding_model\": embed_model,\n                }\n            },\n        }\n        document = await self.collection.find_one(query)\n        return document\n\nMongoDB query method within IndexUpsertRepository class that searches for vector index configurations matching specific dimension, similarity metric, filename, and embedding model parameters. Uses MongoDB's $elemMatch operator to find documents where namespaces array contains elements with matching filename and embedding model details. Part of database access layer for managing vector index metadata.",
        "size": 970,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index_upsert"
    },
    {
        "id": "4a010d5a87505ad3ae18bba488dec975169665c31babecde825d29b150a3dd0e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 32,
        "end_line": 35,
        "content": "async def find_matching_index(self, dimension: str, similarity_metric: str):\n        query = {\"dimension\": dimension, \"similarity_metric\": similarity_metric}\n        document = await self.collection.find_one(query)\n        return document\n\nMongoDB repository method for retrieving vector index configurations by querying on dimension and similarity metric parameters. Part of the IndexUpsertRepository class that manages database operations for vector index management, working alongside methods that find more specific matches or add new index configurations.",
        "size": 560,
        "parent-class": "IndexUpsertRepository",
        "function_name": "find_matching_index"
    },
    {
        "id": "67f16c19574c5e374615674673031f39e804c104aee55f96279c73845ee26908",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/index_upsert_repository.py",
        "file_name": "index_upsert_repository.py",
        "start_line": 37,
        "end_line": 83,
        "content": "async def add_index_upsert_details(self, indexupsert: IndexUpsert):\n        try:\n            # Check if an index with same dimension and similarity_metric exists\n            existing_index = await self.collection.find_one(\n                {\n                    \"dimension\": indexupsert.dimension,\n                    \"similarity_metric\": indexupsert.similarity_metric,\n                }\n            )\n\n            if existing_index:\n                # Get the first namespace from the new data\n                new_namespace = indexupsert.namespaces[0]\n\n                # Check if namespace with same name already exists\n                namespace_exists = any(\n                    ns[\"name\"] == new_namespace.name\n                    for ns in existing_index.get(\"namespaces\", [])\n                )\n\n                if namespace_exists:\n                    # Namespace already exists, no need to update\n                    return str(existing_index[\"_id\"])\n\n                # Add new namespace to existing index\n                result = await self.collection.update_one(\n                    {\"_id\": existing_index[\"_id\"]},\n                    {\n                        \"$push\": {\n                            \"namespaces\": {\n                                \"name\": new_namespace.name,\n                                \"details\": {\n                                    \"filename\": new_namespace.details.filename,\n                                    \"embedding_model\": new_namespace.details.embedding_model,\n                                },\n                            }\n                        }\n                    },\n                )\n                return str(existing_index[\"_id\"])\n            else:\n                # Create new index document\n                index_upsert_dict = indexupsert.to_dict()\n                result = await self.collection.insert_one(index_upsert_dict)\n                return str(result.inserted_id)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in IndexUpsertRepository class for adding vector index details to MongoDB. Implements upsert logic that either updates an existing index by adding a new namespace or creates a fresh index document. Checks for existing indexes with matching dimensions and similarity metrics, handles namespace validation, and returns document ID. Uses MongoDB operations for querying and modification with error handling that converts exceptions to HTTP 500 responses.",
        "size": 2481,
        "parent-class": "IndexUpsertRepository",
        "function_name": "add_index_upsert_details"
    },
    {
        "id": "f863062b8b492f80d233f66498a3a12daaba1e5874dacfeb34d4f40e18c79c67",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from app.config.database import db_helper\nimport random\nfrom fastapi import HTTPException, status\nfrom app.utils.logging_util import loggers\n\nMongoDB repository imports module for a ground truth data service, importing database helper, random module for selecting random questions, FastAPI HTTP handling utilities, and logging components for error tracking in a data retrieval application.",
        "size": 389,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "287d481a94e36162eb3e7896a1596eb0cb1cf8e729641b836c269abfed750744",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self):\n        self.collection = db_helper.gt_data\n\nMongoDB repository initialization method for ground truth data collection access, used in GTDataRepo class for database operations like inserting documents, checking existence, and retrieving random questions.",
        "size": 274,
        "parent-class": "GTDataRepo",
        "function_name": "__init__"
    },
    {
        "id": "bc3e08e71d45dc8ae3d0e28b0e80b1e8a796aef4fc64a098741abf715013ecf7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 10,
        "end_line": 11,
        "content": "async def clear_collection(self):\n        await self.collection.delete_many({})\n\nMongoDB repository method in the GTDataRepo class that removes all documents from the gt_data collection, providing a way to clear ground truth data.",
        "size": 230,
        "parent-class": "GTDataRepo",
        "function_name": "clear_collection"
    },
    {
        "id": "3fdce67eb0138b592a5fd40bbc976a03ddc0ed44f8d28c6802832c415960c8bd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 13,
        "end_line": 17,
        "content": "async def insert_documents(self, document: dict):\n        try :\n            await self.collection.insert_one(document)\n        except Exception as e :\n            loggers[\"main\"].info(f\"inside insert documents : {str(e)}\")\n\nMongoDB document insertion method within GTDataRepo class that adds a single document to the gt_data collection, with error logging. Part of a data repository layer that interfaces with a MongoDB database for ground truth data management.",
        "size": 462,
        "parent-class": "GTDataRepo",
        "function_name": "insert_documents"
    },
    {
        "id": "449a6c679673cebec485888ee9d0b7ce263a0edb53f12df3bf22e9a874fbdf2a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 19,
        "end_line": 24,
        "content": "async def is_exist(self, file_name: str, file_type: str):\n        query = {\n            \"file_name\": file_name,\n            \"file_type\": file_type\n        }\n        return await self.collection.find_one(query)\n\nMongoDB query method within GTDataRepo class that checks for existence of a document with matching file_name and file_type in the gt_data collection. Returns the document if found or None if not found. Used for ground truth data verification.",
        "size": 453,
        "parent-class": "GTDataRepo",
        "function_name": "is_exist"
    },
    {
        "id": "feebb6d8c3e1012a39d3d444cc246951477e6b3cfe245d7b2f4ce6680abfff9e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/repositories/gt_data_repo.py",
        "file_name": "gt_data_repo.py",
        "start_line": 27,
        "end_line": 49,
        "content": "async def get_random_question(self, file_name: str):\n        try:\n            document = await self.collection.find_one({\"file_name\": file_name})\n            if not document:\n                return {\"message\": \"ground truth file not found in database\"}\n            \n            data = document.get(\"data\", [])\n            if not data:\n                return {\"message\": \"no data found in ground truth file\"}\n            \n            total_length = len(data)\n            random_number = random.randint(0, total_length - 1)\n            index = random_number % total_length\n\n            chunks = data[index].get(\"chunks\", [])\n            ids = []\n            for chunk in chunks:\n                ids.append(chunk.get(\"_id\", \"\"))\n            selected_question_gt = data[index]\n            return selected_question_gt, ids\n        except Exception as e:\n            loggers[\"main\"].error(f\"inside get_random_question error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\nMongoDB repository method for retrieving a random question from ground truth data. Accepts a file name parameter, queries the database, selects a random data entry, extracts the associated chunks and their IDs, and returns both the selected question and chunk IDs. Includes error handling with logging and HTTP exception raising. Used in the GTDataRepo class for working with the gt_data collection.",
        "size": 1429,
        "parent-class": "GTDataRepo",
        "function_name": "get_random_question"
    },
    {
        "id": "08a5c595e45806677c5f2d4a66c0a762d163c6087b297a8bd1321081cbfda657",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 1,
        "end_line": 6,
        "content": "from pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nfrom pydantic.config import ConfigDict\nfrom pydantic import BaseModel, field_validator, ValidationError\nfrom typing import ClassVar\nimport logging\n\nImport statements for a Pydantic-based validation framework module. These imports support a data validation system using Pydantic's BaseModel for schema definition, field validators for custom validation logic, and ClassVar for defining class-level constants. The module includes configuration options and error handling for a vector database index creation request validator.",
        "size": 617,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "ee1902d07122db88d482ac3d527d235cd9022d243f5f18126d08f8139aab736e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 39,
        "end_line": 42,
        "content": "def validate_similarity_metric(cls, value):\n        if value.lower() not in cls.ALLOWED_METRICS:\n            raise ValueError(f\"Invalid similarity_metric '{value}'. Must be one of {cls.ALLOWED_METRICS}.\")\n        return value.lower()  # Normalize to lowercase\n\nPydantic field validator method for the similarity_metric attribute in the IndexUpsertRequest model. Verifies that the provided value is within the predefined ALLOWED_METRICS set (\"cosine\", \"dotproduct\", \"euclidean\"), raises a ValueError with available options if invalid, and normalizes valid values to lowercase.",
        "size": 575,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_similarity_metric"
    },
    {
        "id": "58d413409d18c787c614f11c4b036235cc7544d4f5932306b73e8fde83c9ae0a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/index_upsert_schema.py",
        "file_name": "index_upsert_schema.py",
        "start_line": 47,
        "end_line": 59,
        "content": "def validate_dimension(cls, value, info):\n        # Use info.data to access the context dictionary containing input data\n        embed_model = info.data.get(\"embed_model\")\n\n        if not embed_model:\n            raise ValueError(\"embed_model must be provided before validating dimension.\")\n\n        valid_dimensions = cls.MODEL_TO_DIMENSIONS.get(embed_model)\n\n        if valid_dimensions and value not in valid_dimensions:\n            raise ValueError(f\"Invalid dimension '{value}' for model '{embed_model}'. Must be one of {valid_dimensions}.\")\n\n        return value\n\nPydantic field validator method for the 'dimension' field in IndexUpsertRequest class that validates embedding dimensions against allowed values for specific embedding models. The method checks if the provided dimension value is valid for the selected embedding model by referencing the MODEL_TO_DIMENSIONS class variable mapping, ensuring dimension compatibility with embedding models in vector database operations.",
        "size": 986,
        "parent-class": "IndexUpsertRequest",
        "function_name": "validate_dimension"
    },
    {
        "id": "1b8767c42bc7a4987bbdc351c1b22f410f66953a60c5ee16c918a3161d1b588f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/file_upload_schema.py",
        "file_name": "file_upload_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Optional\n\nPython import statements for Pydantic model classes and typing annotations used to define the FileUploadRequest data model with validation capabilities.",
        "size": 219,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "a9242e301d6db955c7392da7d529413d3ba61fa3669d315f2665cf658bda7539",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/query_schema.py",
        "file_name": "query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Optional, Literal\nfrom pydantic import BaseModel, Field\n\nImport statements for Python type hints (Optional, Literal) and Pydantic components (BaseModel, Field) used for defining the data model QueryEndPointRequest that follows in the document.",
        "size": 262,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "db667a4f477a7ad3006e6bf102ac492105adf82087f0e4d0a56f29829d321506",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/random_query_schema.py",
        "file_name": "random_query_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal, Optional\n\nImport statements for Pydantic and typing modules used for defining the RandomQueryRequest model with type hints, validation constraints, and literal type options for similarity metrics in a vector search query interface.",
        "size": 297,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b67ecc977ae23fa3e29267f28de9bfc1ac132e0f2f8a16c132e140bac817c964",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/schemas/reranking_schema.py",
        "file_name": "reranking_schema.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from typing import Any, Dict\nfrom pydantic import BaseModel\n\nPython import statements for type annotations and data validation, used in a module that defines Pydantic models for document handling and reranking operations.",
        "size": 221,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "d9943cd3d7c4aec42c2ff0ee9bde6dfb60ea3a1f0cba2352c821d4e5b460f203",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from datetime import datetime\nfrom typing import Any, Dict, List\nfrom bson import ObjectId\n\nImport statements for a MongoDB-integrated data model implementation, including datetime for timestamp functionality, typing utilities for type annotations, and ObjectId from bson for MongoDB document identification.",
        "size": 308,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "64d73a13407e63293b23f971c60692347fa4417376579d63f0749caf2e607022",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 8,
        "end_line": 10,
        "content": "def __init__(self, filename: str, embedding_model: str):\n        self.filename = filename\n        self.embedding_model = embedding_model\n\nConstructor method for the NamespaceDetails class that initializes filename and embedding_model attributes used in vector database namespace configuration. Part of a data model for vector index management that includes Namespace and IndexUpsert classes.",
        "size": 391,
        "parent-class": "NamespaceDetails",
        "function_name": "__init__"
    },
    {
        "id": "00932efa2bd3bf67e10c42a4e05b63473b643138b9aab36b285ffe4d657fb7f2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 12,
        "end_line": 16,
        "content": "def to_dict(self) -> Dict[str, str]:\n        return {\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n        }\n\nSerialization method for NamespaceDetails class that converts filename and embedding model properties to a dictionary format with string keys and values, used within the vector database indexing system for representing document metadata.",
        "size": 394,
        "parent-class": "NamespaceDetails",
        "function_name": "to_dict"
    },
    {
        "id": "6725b3ef0a74dfd0b5ba72e56918ea73a0f95193dbda5797b32a6d22f34fdf57",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 20,
        "end_line": 22,
        "content": "def __init__(self, name: str, filename: str, embedding_model: str):\n        self.name = name\n        self.details = NamespaceDetails(filename, embedding_model)\n\nConstructor method for the Namespace class in a vector database implementation, initializing a namespace with its name and associated details including filename and embedding model, used within the IndexUpsert system for managing vector search namespaces.",
        "size": 416,
        "parent-class": "Namespace",
        "function_name": "__init__"
    },
    {
        "id": "487c29de2cbd10dccf62b8fd562485dd16ae0938ad953af496cac8b9d5056319",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 24,
        "end_line": 25,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\"name\": self.name, \"details\": self.details.to_dict()}\n\nMethod in the Namespace class that serializes namespace data into dictionary format with name and details, facilitating conversion of object data for storage or transmission in a vector database indexing system.",
        "size": 319,
        "parent-class": "Namespace",
        "function_name": "to_dict"
    },
    {
        "id": "4c31e80443ece5bb4104a006a904c30ee799cd00471f51441ceecba99b14cc8f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 29,
        "end_line": 43,
        "content": "def __init__(\n        self,\n        index_name: str,\n        index_host: str,\n        dimension: int,\n        similarity_metric: str,\n    ):\n        self._id = ObjectId()\n        self.index_name = index_name\n        self.index_host = index_host\n        self.dimension = dimension\n        self.similarity_metric = similarity_metric\n        self.created_at = datetime.utcnow()\n        self.updated_at = datetime.utcnow()\n        self.namespaces: List[Namespace] = []\n\nConstructor method for the IndexUpsert class that initializes a vector index configuration with parameters for name, host, dimension, similarity metric, timestamps, and an empty namespaces list. Creates a unique MongoDB ObjectId and stores metadata for vector search functionality.",
        "size": 747,
        "parent-class": "IndexUpsert",
        "function_name": "__init__"
    },
    {
        "id": "2cffb1c688f878b73a5b7b177f6507505df023d6291164209dc9d7ff568bac8c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 45,
        "end_line": 47,
        "content": "def add_namespace(self, namespace: Namespace) -> None:\n        self.namespaces.append(namespace)\n        self.updated_at = datetime.utcnow()\n\nMethod in the IndexUpsert class that appends a Namespace object to the namespaces list and updates the updated_at timestamp to the current UTC time, tracking when vector index namespaces are modified.",
        "size": 342,
        "parent-class": "IndexUpsert",
        "function_name": "add_namespace"
    },
    {
        "id": "e03e8d2a0e9b7191bb20ed0ab21032e66b2a01fb99d8acaa833a01c95ac02c14",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 49,
        "end_line": 61,
        "content": "def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"_id\": str(self._id),\n            \"index_name\": self.index_name,\n            \"index_host\": self.index_host,\n            \"dimension\": self.dimension,\n            \"similarity_metric\": self.similarity_metric,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n            \"namespaces\": [\n                namespace.to_dict() for namespace in self.namespaces\n            ],\n        }\n\nSerialization method in the IndexUpsert class that converts instance attributes to a dictionary format for storage or transmission. Transforms MongoDB ObjectId to string, datetime objects to ISO format strings, and recursively serializes namespaces collection through list comprehension. Used for data persistence and API responses in a vector database indexing system.",
        "size": 874,
        "parent-class": "IndexUpsert",
        "function_name": "to_dict"
    },
    {
        "id": "3d1e03aff7ea9652ad4d10ec5c28b1edb2e787be86673b6a64dff15dfe8035fa",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/indexupsert.py",
        "file_name": "indexupsert.py",
        "start_line": 64,
        "end_line": 103,
        "content": "def from_dict(cls, data: Dict[str, Any]) -> \"IndexUpsert\":\n        index = cls(\n            index_name=data[\"index_name\"],\n            index_host=data[\"index_host\"],\n            dimension=data[\"dimension\"],\n            similarity_metric=data[\"similarity_metric\"],\n        )\n\n        # Set ID if it exists\n        if \"_id\" in data:\n            if isinstance(data[\"_id\"], str):\n                index._id = ObjectId(data[\"_id\"])\n            else:\n                index._id = data[\"_id\"]\n\n        # Set dates if they exist\n        if \"created_at\" in data:\n            if isinstance(data[\"created_at\"], str):\n                index.created_at = datetime.fromisoformat(data[\"created_at\"])\n            else:\n                index.created_at = data[\"created_at\"]\n\n        if \"updated_at\" in data:\n            if isinstance(data[\"updated_at\"], str):\n                index.updated_at = datetime.fromisoformat(data[\"updated_at\"])\n            else:\n                index.updated_at = data[\"updated_at\"]\n\n        # Add namespaces if they exist\n        if \"namespaces\" in data:\n            for namespace_data in data[\"namespaces\"]:\n                details = namespace_data[\"details\"]\n                namespace = Namespace(\n                    name=namespace_data[\"name\"],\n                    filename=details[\"filename\"],\n                    embedding_model=details[\"embedding_model\"],\n                )\n                index.namespaces.append(namespace)\n\n        return index\n\nClass method that deserializes a dictionary into an IndexUpsert object, handling type conversion for MongoDB ObjectId, datetime fields, and nested Namespace objects. Reconstructs the complete index structure with proper data types from JSON-compatible dictionary representation. Used for database persistence and restoration of vector index metadata.",
        "size": 1813,
        "parent-class": "IndexUpsert",
        "function_name": "from_dict"
    },
    {
        "id": "30cb8a8f9eee436957c0ba582b63308a4ce0b89b45845bd8c0c71346c0776a79",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from typing import List, Union\nimport numpy as np\nfrom bson import ObjectId\nfrom datetime import datetime, timezone\n\nImport statements for the QueryEmbeddings class, including typing annotations, numpy for array operations, MongoDB's ObjectId, and datetime utilities for timestamp management in UTC.",
        "size": 299,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9611409b33bb05d58cce34b86a1fcb0d5df731447e4c8cd26b27ee5d16e0b34d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 7,
        "end_line": 19,
        "content": "def __init__(self, \n                 filename: str, \n                 embedding_model: str, \n                 dimension: int, \n                 questions: List[dict] = None):\n        \n        self._id = ObjectId()\n        self.filename = filename\n        self.embedding_model = embedding_model\n        self.dimension = dimension\n        self.created_at = datetime.now(timezone.utc).isoformat()\n        self.updated_at = datetime.now(timezone.utc).isoformat()\n        self.questions = questions or []\n\nConstructor method for the QueryEmbeddings class that initializes a new instance with unique ID, filename, embedding model details, dimension size, timestamp information, and an optional list of questions. Sets up the fundamental structure for managing question embeddings with metadata tracking.",
        "size": 797,
        "parent-class": "QueryEmbeddings",
        "function_name": "__init__"
    },
    {
        "id": "5411e8b330257a8459849f5e8614549c46d11ad3677b722464253813f9fbcac9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 21,
        "end_line": 35,
        "content": "def add_question(self, question_text: str, embedding: Union[List[float], np.ndarray]):\n        \n        # Ensure embedding is converted to a list\n        if isinstance(embedding, np.ndarray):\n            embedding = embedding.tolist()\n        \n        # Validate embedding dimension\n        if len(embedding) != self.dimension:\n            raise ValueError(f\"Embedding must have {self.dimension} dimensions\")\n        \n        question = {\n            \"question_text\": question_text,\n            \"embedding\": embedding\n        }\n        self.questions.append(question)\n\nMethod of the QueryEmbeddings class that adds a new question with its vector embedding to the collection, handling numpy array conversion to list format and validating the embedding dimensions against the expected dimension size. Part of a document management system that stores embeddings for text-based queries.",
        "size": 882,
        "parent-class": "QueryEmbeddings",
        "function_name": "add_question"
    },
    {
        "id": "6d582958d228183e37cad89e84aa1470874b79a36fc4150d94d4df55db74b91f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/models/domain/queryembed.py",
        "file_name": "queryembed.py",
        "start_line": 37,
        "end_line": 47,
        "content": "def to_dict(self) -> dict:\n        \n        return {\n            \"_id\": str(self._id),\n            \"filename\": self.filename,\n            \"embedding_model\": self.embedding_model,\n            \"dimension\": self.dimension,\n            \"questions\": self.questions,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n        }\n\nSerialization method in the QueryEmbeddings class that converts the object's properties to a dictionary format. Returns a dictionary containing document ID, filename, embedding model details, dimension size, question data, and timestamps. Used for database storage or JSON serialization of query embedding data.",
        "size": 693,
        "parent-class": "QueryEmbeddings",
        "function_name": "to_dict"
    },
    {
        "id": "73a64dd37ed48c68a5d75b8e43ff710365ee8de704375a30275a7822dcda00f6",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 1,
        "end_line": 4,
        "content": "from fastapi import Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\nfrom app.usecases.file_upload_usecase import FileUploadUseCase\nimport logging\n\nImport statements for a FastAPI file upload controller module, including dependencies for HTTP handling, response formatting, the FileUploadUseCase component, and logging functionality. These imports support the controller's ability to manage file upload operations within a FastAPI application.",
        "size": 468,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c23b716b7a1a6cc7676d91e7b9a27c37a46fd9f776b778dc0fec645ca42cc471",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: FileUploadUseCase = Depends()):\n        self.usecase = usecase\n\nInitialization method for FileUploadController class that dependency injects a FileUploadUseCase instance. Part of a FastAPI controller handling file upload functionality.",
        "size": 263,
        "parent-class": "FileUploadController",
        "function_name": "__init__"
    },
    {
        "id": "2d9c204f18903f23a0eba529fcad46ebf9c6f2a7957fc15c14ab1e8ed226cc64",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/file_upload_controller.py",
        "file_name": "file_upload_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def upload_files(self, request_data: dict):\n        return await self.usecase.execute(request_data)\n\nMethod in FileUploadController that accepts file upload request data as a dictionary, delegates processing to the usecase layer by calling its execute method asynchronously, and returns the result. Part of a FastAPI application using the controller-usecase architecture pattern for handling file uploads.",
        "size": 411,
        "parent-class": "FileUploadController",
        "function_name": "upload_files"
    },
    {
        "id": "77b0d66f8cf14e3c7b9be8d01fc33c142ff6913a5315c169754e0f2343c7720f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.usecases.reranking_usecase import RerankingUseCase\n\nImport statements for a FastAPI reranking controller, importing Depends for dependency injection, RerankingRequest/Response schemas for data validation, and RerankingUseCase which contains the core document reranking logic.",
        "size": 409,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "c59af88f57b65cd22fa472b55843c687a12b4ed02e206d081a1fba51dcf41b2c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "def __init__(self, reranking_usecase: RerankingUseCase = Depends()):\n        self.reranking_usecase = reranking_usecase\n\nClass constructor for the RerankingController that initializes the reranking_usecase dependency using FastAPI's dependency injection system. This method connects the controller to the RerankingUseCase that handles the core document reranking logic.",
        "size": 369,
        "parent-class": "RerankingController",
        "function_name": "__init__"
    },
    {
        "id": "ea093031aff6eaedd0314c8f2c7f5954f2d0b10894442a040e4d5c74dc943616",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/reranking_controller.py",
        "file_name": "reranking_controller.py",
        "start_line": 14,
        "end_line": 17,
        "content": "async def rerank_documents(\n        self, request: RerankingRequest\n    ) -> RerankingResponse:\n        return await self.reranking_usecase.execute(request)\n\nController method for reranking documents that accepts a RerankingRequest object, asynchronously delegates processing to the reranking usecase layer, and returns a RerankingResponse. Part of a FastAPI-based controller that follows clean architecture patterns with dependency injection.",
        "size": 443,
        "parent-class": "RerankingController",
        "function_name": "rerank_documents"
    },
    {
        "id": "d8b24b91ae41b8acf56bf92f613c6629edf2057abd0a78259304939c7b051d20",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.index_upsert_usecase import IndexUpsertUseCase\n\nImport statements for FastAPI dependency injection and the IndexUpsertUseCase module, establishing dependencies for the IndexUpsertController class that handles index upsert operations within a REST API context.",
        "size": 305,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "8ddaed12e25b9e9dd687f37b8fcdb49f6b10a98399be2dbf373a1c46dc02f114",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 7,
        "end_line": 8,
        "content": "def __init__(self, index_upsert_usecase=Depends(IndexUpsertUseCase)):\n        self.index_upsert_usecase = index_upsert_usecase\n\nController constructor for index upserting operations that injects an IndexUpsertUseCase dependency using FastAPI's dependency injection system, establishing the foundation for handling document indexing requests in a clean architecture pattern.",
        "size": 373,
        "parent-class": "IndexUpsertController",
        "function_name": "__init__"
    },
    {
        "id": "54a5044b28f2d7b0dd04b88c263e1809f15df954df73725e09b16c36735509d0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/index_upsert_controller.py",
        "file_name": "index_upsert_controller.py",
        "start_line": 10,
        "end_line": 12,
        "content": "async def index_upsert(self, request):\n\n        return await self.index_upsert_usecase.index_upsert(request)\n\nController method that handles index upsert operations by delegating the request to the underlying IndexUpsertUseCase. Asynchronous method that processes request data and passes it directly to the corresponding usecase implementation without modification. Part of the IndexUpsertController class in a FastAPI application following a clean architecture pattern.",
        "size": 470,
        "parent-class": "IndexUpsertController",
        "function_name": "index_upsert"
    },
    {
        "id": "4e53947b94a62c61201f030b221c19c7aa47d7541490501934af324817593797",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.usecases.query_usecase import QueryUseCase\n\nImport statements for the QueryController class, importing FastAPI's Depends for dependency injection, the QueryEndPointRequest schema for request validation, and QueryUseCase which contains the business logic implementation that the controller will delegate to.",
        "size": 408,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "39e1ebfac7ec362d52d0cf26a5d9f3f127b9f2dfef40e050d880713c3853f882",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "def __init__(self, usecase: QueryUseCase = Depends()):\n        self.query_usecase = usecase\n\nConstructor for QueryController class that injects a QueryUseCase dependency using FastAPI's dependency injection system, initializing the controller with the usecase that will handle query operations.",
        "size": 294,
        "parent-class": "QueryController",
        "function_name": "__init__"
    },
    {
        "id": "d6352d94e0eff0a90ab8e919d71ae2fe5b607cbdc23e5de59ee842d030a72d9c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/query_controller.py",
        "file_name": "query_controller.py",
        "start_line": 12,
        "end_line": 13,
        "content": "async def make_query(self, request: QueryEndPointRequest):\n        return await self.query_usecase.execute(request)\n\nController method that handles query requests by receiving a QueryEndPointRequest and asynchronously delegating execution to the query_usecase service. Part of the FastAPI controller layer that connects API endpoints to business logic in the QueryUseCase.",
        "size": 372,
        "parent-class": "QueryController",
        "function_name": "make_query"
    },
    {
        "id": "f0e95975e311c498cc65f82101247771ddc8184dcc14eb2da0607d3b549f9740",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.config_usecase import ConfigUsecase\n\nImport statements for the ConfigurationController class, bringing in the Depends function from FastAPI for dependency injection and the ConfigUsecase class from the application's usecase layer for configuration management functionality.",
        "size": 319,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "a545b946337c18bdcab9b8105e07a93a4ec62c8d1ba7ce4ca8a294150b60eebc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, usecase: ConfigUsecase = Depends()):\n        self.query_usecase = usecase\n\nConstructor for ConfigurationController class that initializes with a ConfigUsecase dependency injection. The controller stores the provided usecase instance as query_usecase, which is later used in the get_config method to retrieve configuration data.",
        "size": 346,
        "parent-class": "ConfigurationController",
        "function_name": "__init__"
    },
    {
        "id": "b4ac9052a97193bf11238498d0a5f31526a71ac2d83629387932e9e79ef106bc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/config_controller.py",
        "file_name": "config_controller.py",
        "start_line": 9,
        "end_line": 10,
        "content": "async def get_config(self):\n        return await self.query_usecase.get_config()\n\nAPI endpoint method in ConfigurationController that retrieves configuration data by delegating to the query_usecase service. Part of the controller layer that interfaces between HTTP requests and the usecase business logic.",
        "size": 305,
        "parent-class": "ConfigurationController",
        "function_name": "get_config"
    },
    {
        "id": "bf8827858be98c448481534e0fed1a41837732ec5ff246d068b38f9490232647",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends\nfrom app.usecases.random_query_usecase import RandomQueryUseCase\nfrom app.models.schemas.random_query_schema import RandomQueryRequest\n\nImport statements for the RandomQueryController class, importing the FastAPI Depends function for dependency injection, the RandomQueryUseCase for business logic implementation, and RandomQueryRequest schema for request data validation.",
        "size": 400,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "0a5a116b73fbe96e6aff2738d18073df2bea6c650043623c54eaef402fd94feb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 8,
        "end_line": 9,
        "content": "def __init__(self, random_query_usecase: RandomQueryUseCase = Depends()):\n        self.random_query_usecase = random_query_usecase\n\nConstructor for RandomQueryController class that initializes the controller with a RandomQueryUseCase dependency using FastAPI's dependency injection system. This initializer establishes the relationship between the controller and its core usecase component.",
        "size": 390,
        "parent-class": "RandomQueryController",
        "function_name": "__init__"
    },
    {
        "id": "adf22647ac809481b11d44f2f499d5e694e7a9784fd7209b917800ddeb40cb72",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_query_controller.py",
        "file_name": "random_query_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "async def random_query(self, request: RandomQueryRequest):\n        return await self.random_query_usecase.random_query(request)\n\nController method that handles random query requests by delegating to the random_query_usecase component. Takes a RandomQueryRequest parameter and returns the asynchronous result from the usecase layer, following a clean architecture pattern in a FastAPI application.",
        "size": 396,
        "parent-class": "RandomQueryController",
        "function_name": "random_query"
    },
    {
        "id": "40236ee4e75984f45d596efb98b8de6c33c357c18c10cded642424858b4ff4ed",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.usecases.random_question_usecase import RandomQuestionUseCase\n\nImport statements for RandomQuestionController class, importing Depends from FastAPI framework and RandomQuestionUseCase from the application's usecases module, which will be used as a dependency in the controller.",
        "size": 314,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "bb0bbcc1350c2e6935ad2c1cd7cfefde6bd2ba8581a4cc571995633784aee169",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 8,
        "end_line": 9,
        "content": "def __init__(self, random_question_usecase: RandomQuestionUseCase = Depends()):\n        self.random_question_usecase = random_question_usecase\n\nConstructor method for the RandomQuestionController class that injects the RandomQuestionUseCase dependency using FastAPI's dependency injection system. The controller initializes with this usecase component to handle random question retrieval operations.",
        "size": 399,
        "parent-class": "RandomQuestionController",
        "function_name": "__init__"
    },
    {
        "id": "a6ceb398a8459d7e504bc57df2a81cf341bb4cbe81d8f6d1d7c0f3968067c880",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/controllers/random_question_controller.py",
        "file_name": "random_question_controller.py",
        "start_line": 11,
        "end_line": 12,
        "content": "async def random_question(self, file_name: str):\n        return await self.random_question_usecase.random_question(file_name)\n\nAsynchronous controller method that delegates the random question retrieval operation to its dependency-injected usecase. Routes a file name parameter to the corresponding usecase method and awaits its response in a FastAPI controller implementation.",
        "size": 377,
        "parent-class": "RandomQuestionController",
        "function_name": "random_question"
    },
    {
        "id": "35a401805d661f7b8282d5c3f1e3c0f2987359bd36f8e700621d074c63dda2f7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 1,
        "end_line": 2,
        "content": "from fastapi import Depends\nfrom app.repositories.index_repository import IndexRepository\n\nImport statements for the ConfigUsecase class, importing the Depends function from FastAPI for dependency injection and IndexRepository from the application's repository layer.",
        "size": 267,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "2f992884820aed9b71897772a74802d5760055232a0ecff8a9ea644783e40faf",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 6,
        "end_line": 7,
        "content": "def __init__(self, index_repository: IndexRepository = Depends()):\n        self.index_repository = index_repository\n\nConfigUsecase class constructor that initializes the index_repository dependency using FastAPI's dependency injection system. This repository is used to fetch user configurations within the ConfigUsecase service.",
        "size": 329,
        "parent-class": "ConfigUsecase",
        "function_name": "__init__"
    },
    {
        "id": "67ec08c5b392fb66f9eec61612de3b3bacaff650968bc6153f1a27e862af08e3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/config_usecase.py",
        "file_name": "config_usecase.py",
        "start_line": 9,
        "end_line": 13,
        "content": "async def get_config(self):\n        response = await self.index_repository.fetch_user_previous_configurations()\n        if response is None:\n            return {\"message\": \"No configurations found\"}\n        return response\n\nAsynchronous method in the ConfigUsecase class that retrieves user configurations by calling the index repository's fetch_user_previous_configurations method. Returns either the fetched configurations or a message indicating no configurations were found. Part of a FastAPI application's usecases layer, connecting repository functionality to API endpoints.",
        "size": 580,
        "parent-class": "ConfigUsecase",
        "function_name": "get_config"
    },
    {
        "id": "c84f16d05d999aab0e99f98e85a6d50444823bf2cc49a731dec9354344bc2bcb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import os\nimport json\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom fastapi import Depends, HTTPException\nfrom app.models.schemas.reranking_schema import (\n    RerankingRequest,\n    RerankingResponse,\n)\nfrom app.repositories.index_repository import IndexRepository\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.reranking_service import RerankerService\nfrom app.utils.logging_util import loggers\n\nImport statements and class dependency definitions for a document retrieval reranking system. Includes imports for OS operations, JSON handling, async functionality, threading, FastAPI components, custom schemas, repository access, evaluation metrics, reranking service, and logging utilities that support the RerankingUseCase implementation.",
        "size": 796,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "dd93029d663f9fba98c2ced29eec2c7a093023f158b44553109e35bb802959ee",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 18,
        "end_line": 24,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        reranker_service: RerankerService = Depends(),\n    ):\n        self.reranker_service = reranker_service\n        self.index_repository = index_repository\n\nConstructor method for the RerankingUseCase class that initializes repository and service dependencies. Injects IndexRepository and RerankerService instances which are used for document reranking operations in information retrieval pipelines. These dependencies are initialized through FastAPI's dependency injection system.",
        "size": 568,
        "parent-class": "RerankingUseCase",
        "function_name": "__init__"
    },
    {
        "id": "f5a146ff99211a37ffdded124c78641e59d769609ec0bfba59127afd9d7db78c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 26,
        "end_line": 90,
        "content": "async def execute(self, request: RerankingRequest) -> RerankingResponse:\n        \"\"\"\n        Execute the reranking use case by processing queries and documents \n        from the saved first_stage_retrieval.json file.\n\n        Args:\n            request: RerankingRequest containing model_name and top_n\n\n        Returns:\n            RerankingResponse with evaluation metrics\n        \"\"\"\n        try:\n            model_name = request.model_name\n            top_n = request.top_n\n            top_k=request.top_k\n\n            if top_n > top_k:\n                raise HTTPException(\n                    status_code=400, \n                    detail=f\"Invalid request: top_n ({top_n}) cannot be greater than top_k ({top_k}).\"\n                )\n\n            # Load first stage retrieval results\n            first_stage_file_path = \"results/first_stage_retrieval.json\"\n            if not os.path.exists(first_stage_file_path):\n                raise HTTPException(\n                    status_code=404, \n                    detail=\"First stage retrieval results not found. Run query_usecase first.\"\n                )\n                \n            with open(first_stage_file_path, \"r\") as f:\n                questions_data = json.load(f)\n                \n            # Process each question in parallel\n            tasks = [\n                self._process_question(question, model_name, top_n)\n                for question in questions_data\n            ]\n            \n            processed_questions = await asyncio.gather(*tasks)\n            \n            # Extract questions and evaluation metrics\n            questions, evaluation_metrics_list = zip(*processed_questions)\n            \n            # Calculate average metrics\n            with ThreadPoolExecutor() as executor:\n                average_evaluation_metrics = executor.submit(\n                    self.average_metrics,\n                    evaluation_metrics_list,\n                    top_n\n                ).result()\n                \n            # Save results\n            os.makedirs(\"results\", exist_ok=True)\n            with open(\"results/second_stage_retrieval.json\", \"w\") as f:\n                json.dump(list(questions), f, indent=4)\n                \n            with open(\"results/second_stage_evaluation.json\", \"w\") as f:\n                json.dump(average_evaluation_metrics, f, indent=4)\n                \n            return RerankingResponse(evaluation_metrics=average_evaluation_metrics)\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking execution: {str(e)}\", exc_info=True)\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nMain execution method in the RerankingUseCase class that orchestrates document reranking operations. Processes a reranking request containing model_name, top_n, and top_k parameters. Validates input parameters, loads first-stage retrieval results, processes questions in parallel, aggregates results, calculates evaluation metrics, and saves output files. Handles error conditions with appropriate HTTP exceptions. Implements a multi-step reranking workflow that reads from first_stage_retrieval.json and produces second_stage_retrieval.json and second_stage_evaluation.json output files with comprehensive evaluation metrics.\n",
        "size": 3262,
        "parent-class": "RerankingUseCase",
        "function_name": "execute"
    },
    {
        "id": "4837a05ad714f1b7d909cbbf565d9f8454a66fc596d82fe2d8d55d217a558ab5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 92,
        "end_line": 113,
        "content": "async def _process_question(self, question, model_name, top_n):\n        \"\"\"Process a single question with reranking.\"\"\"\n        try:\n            query = question[\"question\"]\n            documents = question[\"relevant_docs\"]\n            ground_truth_chunk_ids = question[\"ground_truth_chunk_ids\"]\n            \n            reranked_docs = await self._rerank_documents(model_name, query, documents, top_n)\n            \n            # Update the question with reranked documents\n            question[\"reranked_docs\"] = reranked_docs\n            \n            evaluation_metrics = self._calculate_evaluation_metrics(\n                reranked_docs, ground_truth_chunk_ids, top_n\n            )\n            \n            return question, evaluation_metrics\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error processing question '{query}': {str(e)}\", exc_info=True)\n            question[\"error\"] = str(e)\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate helper method in the RerankingUseCase class that processes individual questions during document reranking. Extracts query and document information from the question data structure, calls the reranking function, updates the question with reranked documents, calculates evaluation metrics against ground truth, and returns both the updated question and metrics. Handles exceptions by logging errors and raising appropriate HTTP exceptions. Used within the parallel processing workflow of the execute method to apply reranking to each question independently.",
        "size": 1556,
        "parent-class": "RerankingUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "f548bfac791db7c4cec48a8a383fab9982ea75cacc72f7cde9cd84e9df9da757",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 115,
        "end_line": 217,
        "content": "async def _rerank_documents(self, model_name, query, documents, top_n):\n        \"\"\"Rerank documents using the specified reranker.\"\"\"\n\n        try:\n            pinecone_models = [\n                \"cohere-rerank-3.5\",\n                \"bge-reranker-v2-m3\",\n                \"pinecone-rerank-v0\",\n            ]\n            cohere_models = [\n                \"rerank-v3.5\",\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n            ]\n            jina_models = [\"jina-reranker-v2-base-multilingual\"]\n            voyage_models=[\"rerank-lite-1\",\"rerank-1\",\"rerank-2\"]\n            \n            # Extract text from documents for non-Pinecone rerankers\n            docs_text = [doc[\"text\"] for doc in documents]\n            # Format documents for Pinecone reranker\n            pinecone_docs = [{\"text\": doc[\"text\"]} for doc in documents]\n            \n            results = []\n            \n            # Determine which reranker to use based on the model name\n            if model_name.lower() in pinecone_models:\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model_name, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    # Find the original document to preserve the id\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            elif model_name.lower() in cohere_models:\n                reranking_result = await self.reranker_service.cohere_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n                        \n            elif model_name.lower() in jina_models:\n                reranking_result = await self.reranker_service.jina_rerank(\n                    model_name, query, docs_text, top_n\n                )\n                \n                for result in reranking_result.get(\"results\", []):\n                    idx = result.get(\"index\", 0)\n                    if 0 <= idx < len(documents):\n                        results.append({\n                            \"id\": documents[idx][\"id\"],\n                            \"text\": documents[idx][\"text\"],\n                            \"score\": result.get(\"relevance_score\", 0.0)\n                        })\n\n            elif model_name.lower() in voyage_models:\n                reranking_result = await self.reranker_service.voyage_rerank(\n                    model_name,query,docs_text,top_n\n                )\n                for result in reranking_result.get(\"data\",[]):\n                    idx=result.get(\"index\",0)\n                    if 0<=idx <len(documents):\n                        results.append({\n                            \"id\":documents[idx][\"id\"],\n                            \"text\":documents[idx][\"text\"],\n                            \"score\":result.get(\"relevance_score\",0.0)\n                        })\n                        \n            else:\n                # Default to Pinecone\n                model = \"bge-reranker-v2-m3\"\n                reranking_result = await self.reranker_service.pinecone_reranker(\n                    model, query, pinecone_docs, top_n\n                )\n                \n                for i, result in enumerate(reranking_result.get(\"data\", [])):\n                    doc_text = result.get(\"document\", {}).get(\"text\", \"\")\n                    doc_id = next((doc[\"id\"] for doc in documents if doc[\"text\"] == doc_text), f\"unknown-{i}\")\n                    \n                    results.append({\n                        \"id\": doc_id,\n                        \"text\": doc_text,\n                        \"score\": result.get(\"score\", 0.0)\n                    })\n                    \n            return results\n        \n        except Exception as e:\n            raise HTTPException(status_code=500, detail=str(e))\n\nA private method in the RerankingUseCase class that handles document reranking using different reranking services based on the specified model. Supports multiple reranker models from Pinecone, Cohere, Jina, and Voyage. Dynamically routes to the appropriate service implementation, processes the retrieved results to maintain consistency, and formats the response with document identifiers, text, and relevance scores. Falls back to a default Pinecone model when an unrecognized model is specified. Core component of the document reranking pipeline used within the question processing workflow.",
        "size": 5234,
        "parent-class": "RerankingUseCase",
        "function_name": "_rerank_documents"
    },
    {
        "id": "b0072f329fff4959b43fdc24ece07007581766e6e54d61f825d35ed2ab78f999",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 219,
        "end_line": 260,
        "content": "def _calculate_evaluation_metrics(self, retrieved_docs, ground_truth_ids, top_n):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n        return {\n            \"precision_at_k\": EvaluationService.precision_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"recall_at_k\": EvaluationService.recall_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n,\n            ),\n            \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids, \n                k=top_n\n            ),\n            \"bpref\": EvaluationService.bpref(\n                retrieved_docs=retrieved_docs, \n                ground_truth=ground_truth_ids\n            ),\n            \"mrr\": EvaluationService.reciprocal_rank(\n            retrieved_docs=retrieved_docs,\n            ground_truth=ground_truth_ids\n            ),\n            \"map\": EvaluationService.mean_average_precision(\n                retrieved_docs=retrieved_docs,\n                ground_truth=ground_truth_ids,\n                max_k=top_n\n            ),\n        }\n\nMethod within RerankingUseCase class that calculates comprehensive retrieval evaluation metrics including precision, recall, F1-score, hit rate, NDCG, BPREF, MRR, and MAP at specified k values. Takes reranked document results, ground truth document IDs, and a top_n parameter to evaluate search quality. Used during document reranking to quantify retrieval effectiveness against known relevant documents, supporting the reranking pipeline's evaluation workflow.",
        "size": 2173,
        "parent-class": "RerankingUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "c3224d81b173627e3fdd1fa336e41feb8ed68bcdce1878e883ff982487cbd24d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/reranking_usecase.py",
        "file_name": "reranking_usecase.py",
        "start_line": 262,
        "end_line": 314,
        "content": "def average_metrics(self, metrics_list, top_n):\n        \"\"\"Calculate average metrics across all questions.\"\"\"\n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_n + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n    \n        avg_dict = sum_dict.copy()\n        \n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    for sub_key, sub_value in value.items():\n                        if sub_key in sum_dict.get(key, {}):\n                            sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] if count_dict[key] > 0 else 0.0\n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key] if count_dict[key] > 0 else 0.0\n        \n        return avg_dict\n\nMethod in RerankingUseCase class that aggregates evaluation metrics from multiple queries. Initializes dictionaries to track evaluation metrics (precision, recall, F1-score, hit rate, NDCG, BPREF, MRR, MAP) at different K values. Sums all metrics across queries and calculates averages. Used in the execute method to generate the final performance metrics from individual question evaluations for document reranking operations. Handles both scalar metrics and dictionary-based metrics with proper averaging.",
        "size": 2427,
        "parent-class": "RerankingUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "3bbd9b70bbde9fbfea632d057c91825baf7d0bcd512f71e245ecec148808b96b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 1,
        "end_line": 16,
        "content": "import os\nimport time\nimport json\nimport asyncio\nfrom typing import List\nfrom typing import List\nfrom fastapi import Depends, HTTPException\nfrom concurrent.futures import ThreadPoolExecutor\nfrom app.models.schemas.query_schema import QueryEndPointRequest\nfrom app.repositories.index_repository import IndexRepository\nfrom app.repositories.query_repository import QueryRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.evaluation_service import EvaluationService\nfrom app.services.pinecone_service import PineconeService\nfrom app.models.domain.queryembed import QueryEmbeddings\nfrom app.utils.logging_util import loggers\n\nModule imports and class dependencies for the QueryUseCase class in a vector search evaluation system. Includes standard Python libraries (os, time, json, asyncio), typing utilities, FastAPI components, threading tools, and application-specific imports for repositories (index, query), services (embedding, evaluation, pinecone), data models, and logging utilities. These dependencies support a system that evaluates different embedding models and retrieval approaches using various metrics.",
        "size": 1151,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "561fa37b4150dbdf9c937f5207a3a54c260931df2aa0d9b18ec65d3fe5d2b18e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 23,
        "end_line": 70,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        query_repository: QueryRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(),\n    ):\n        self.index_repository = index_repository\n        self.query_repository = query_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n        self.semaphore = asyncio.Semaphore(50)\n        self.embedding_batch = 90\n        self.embedding_batch = 90\n\nConstructor for the QueryUseCase class that initializes dependencies, maps embedding models to their providers, and stores model dimension configurations. Sets up repositories for index and query operations, services for embeddings and Pinecone integration, and defines mappings between embedding models and their providers (Pinecone, Cohere, Jina, Voyage). Maintains valid dimension configurations for each model and establishes batch processing parameters with a semaphore for concurrency control in the query evaluation system.",
        "size": 2620,
        "parent-class": "QueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "01f1a6ff1dad030a07e05ee05ae931689ef835d4b9bb6c65d0900b21edf60fc3",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 72,
        "end_line": 145,
        "content": "async def execute(self, request_data: QueryEndPointRequest):\n        \"\"\"\n        Main execution function for processing query endpoint requests.\n        Breaks down the request handling into smaller, focused functions.\n        \"\"\"\n        \n        total_chunks = await self.index_repository.fetch_total_chunks(request_data.file_name)\n        if total_chunks < request_data.top_k:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Top K value cannot be greater than the total number of chunks: {total_chunks}\",\n            )\n        \n        try:\n            model = self.embeddings_provider_mapping[request_data.embedding_model]\n        except KeyError:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Invalid embedding model. Please provide a valid model.\",\n            )\n            \n        if request_data.dimension not in self.model_to_dimensions[request_data.embedding_model]:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Invalid dimension. Please provide a valid dimension for embedding model: {request_data.embedding_model}\",\n            )\n            \n        namespace_name, host = await self._get_namespace_and_host(request_data)\n        questions_with_ground_turth_chunks = await self.index_repository.fetch_questions(request_data.file_name)\n        \n        batches = [questions_with_ground_turth_chunks[i:min(i + self.embedding_batch, len(questions_with_ground_turth_chunks))]\n            for i in range(0, len(questions_with_ground_turth_chunks), self.embedding_batch)\n        ]\n        \n        embedding_tasks = [self._generate_batch_embeddings(batch, request_data) for batch in batches]\n        embeddings = await asyncio.gather(*embedding_tasks, return_exceptions=True)\n        \n        dense_embeddings = []\n        for x in embeddings:\n            dense_embeddings.extend(x)\n\n        loggers['evaluation'].info(f\"Total number of questions: {len(questions_with_ground_turth_chunks)}\")\n        loggers['evaluation'].info(f\"Total number of dense embeddings: {len(dense_embeddings)}\")\n\n        \n        s = time.time()\n        tasks = [self._process_question(embedding, question, namespace_name, host, request_data) for question, embedding in zip(questions_with_ground_turth_chunks, dense_embeddings)]\n        processed_questions = await asyncio.gather(*tasks)\n        \n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices: {e-s}\")\n        if processed_questions:\n            loggers['evaluation'].info(f\"processed_questions: {len(processed_questions)}\")\n        \n        questions, evaluation_metrics_list = zip(*processed_questions)\n\n        s = time.time()\n        with ThreadPoolExecutor() as executor:\n            average_evaluation_metrics = executor.submit(\n                self.average_metrics,\n                evaluation_metrics_list,\n                request_data.top_k,\n            ).result()\n        e = time.time()\n        loggers['evaluation'].info(f\"Total Time to execute evaluation metrices (Average): {e-s}\")\n\n        os.makedirs(\"results\", exist_ok=True)\n        with open(\"results/first_stage_retrieval.json\", \"w\") as f:\n            json.dump(list(questions), f, indent=4)\n        \n        with open(\"results/first_stage_evaluation.json\", \"w\") as f:\n            json.dump(average_evaluation_metrics, f, indent=4)\n            \n        return {\"questions\": questions, \"evaluation_result\" : average_evaluation_metrics}\n\nMain execution method in QueryUseCase class that orchestrates the evaluation of search relevance. It validates request parameters (top_k, embedding model, dimension), retrieves questions with ground truth chunks, generates embeddings in batches, processes search queries, calculates evaluation metrics (precision, recall, NDCG, etc.), and returns both search results and averaged evaluation metrics. The method implements parallel processing with asyncio and handles exceptions throughout the workflow.",
        "size": 4033,
        "parent-class": "QueryUseCase",
        "function_name": "execute"
    },
    {
        "id": "96bac761b0a2f839c388ae663c5b5b4363ce8455d3824d6bb5b76f4799b2f42c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 147,
        "end_line": 156,
        "content": "async def _generate_batch_embeddings(self, questions: List[dict], request_data: QueryEndPointRequest):\n        \n        questions = [question[\"question\"] for question in questions]\n        loggers['evaluation'].info(f'Generating embeddings for {len(questions)} questions.')\n        dense_embeddings = await self._generate_dense_embedding(request_data, questions)\n            \n        if not dense_embeddings:\n            raise HTTPException(status_code=500, detail=\"Error generating dense embedding.\")\n            \n        return dense_embeddings\n\nHelper method in QueryUseCase class that processes batches of questions to generate embeddings. Takes a list of question dictionaries and request data, extracts the question text, calls _generate_dense_embedding to create vector embeddings, validates the result, and returns dense embeddings used for vector search operations. Part of the evaluation pipeline that batches question processing for efficient embedding generation.",
        "size": 975,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_batch_embeddings"
    },
    {
        "id": "b486e2bc7990026638299672825577026b18902b8426bf5ad69ab447c08de0b1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 159,
        "end_line": 203,
        "content": "async def _process_question(self, dense_embedding: list, question: dict, namespace_name: str, host:str, request_data: QueryEndPointRequest):\n        \n        async with self.semaphore:\n            \n            results = None\n            if request_data.is_hybrid:\n                results = await self._perform_hybrid_search(\n                    request_data, namespace_name, host, dense_embedding, question['question']\n                )\n            else:\n                results = await self._perform_regular_search(\n                    request_data, namespace_name, host, dense_embedding\n                )\n                \n            if not results:\n                loggers['evaluation'].info(\"No results found.\")\n                \n            relevant_docs_ids = []\n            relevant_docs = []\n            for result in results[\"matches\"]:\n                relevant_docs_ids.append(result[\"id\"])\n                relevant_docs.append(\n                    {\"id\": result[\"id\"], \"text\": result[\"metadata\"][\"text\"]}\n                )\n            \n            question['relevant_docs'] = relevant_docs\n            \n            ground_truth_chunk_ids = question['ground_truth_chunk_ids']\n            \n            if not relevant_docs_ids:\n                return {\n                    \"relevant_docs\": {},\n                    \"error\": \"No relevant documents found.\",\n                }\n\n            else:\n                with ThreadPoolExecutor() as executor:\n                    evaluation_metrics = executor.submit(\n                        self._calculate_evaluation_metrics,\n                        relevant_docs,\n                        ground_truth_chunk_ids,\n                        request_data.top_k\n                    ).result()\n                    \n            return question, evaluation_metrics\n\n\nAsynchronous method in the QueryUseCase class that processes a single question for information retrieval evaluation. It performs either hybrid or regular vector search using the provided embedding, extracts relevant documents from search results, compares them against ground truth chunk IDs, calculates evaluation metrics via ThreadPoolExecutor, and returns both the question with retrieved documents and evaluation metrics. The method includes resource management with a semaphore to control concurrent execution across multiple questions.\n",
        "size": 2347,
        "parent-class": "QueryUseCase",
        "function_name": "_process_question"
    },
    {
        "id": "e2eb49243e7415b3311653be72371a676d9a242c4bc36ae41bf5072b4fa48aa7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 206,
        "end_line": 229,
        "content": "async def _get_namespace_and_host(self, request_data: QueryEndPointRequest):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{request_data.similarity_metric}-{request_data.dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    request_data.embedding_model,\n                    request_data.file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers['evaluation'].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nHelper method in the QueryUseCase class that retrieves the namespace and host for a vector index based on the provided query parameters. Constructs an index name from similarity metric and dimension, then fetches corresponding namespace and host from the index repository. Handles error cases with appropriate HTTP exceptions and logging. This method is used during the query execution process to identify where to search for embeddings.",
        "size": 1418,
        "parent-class": "QueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "211c385c0b67cf1fb829501bf17c6be6f83e8704e5aff2d4aa1b27c6d322d9c4",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 231,
        "end_line": 304,
        "content": "async def _generate_dense_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate dense embedding for the query using the appropriate provider.\"\"\"\n\n        try:\n            s = time.perf_counter()\n            existing_embeddings = []\n            for question in questions:\n                already_embeddings = await self.query_repository.retrieve_question_embeddings(\n                    request_data.file_name,\n                    request_data.embedding_model,\n                    request_data.dimension,\n                    question,\n                )\n                e = time.perf_counter()\n                if already_embeddings:\n                    loggers['evaluation'].info(f\"Time taken to retrieve question embeddings from MongoDB : {e-s}\")\n                    loggers['evaluation'].info(\"Embeddings already present in the database.\")  \n                    existing_embeddings.append(already_embeddings)\n            \n            loggers['evaluation'].info(f'Existing embeddings: {len(existing_embeddings)}')\n            if existing_embeddings and len(existing_embeddings) == len(questions):\n                return existing_embeddings\n\n            embedding_provider = None\n            for key, value in self.embeddings_provider_mapping.items():\n                if key == request_data.embedding_model:\n                    embedding_provider = value\n\n            embeddings = None\n            if embedding_provider == \"pinecone\":\n                embeddings =  await self._generate_pinecone_embedding(request_data, questions)\n                        \n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by pinecone.')\n                \n            elif embedding_provider == \"cohere\":\n                embeddings = await self._generate_cohere_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by cohere.')\n                \n            elif embedding_provider == \"jina\":\n                embeddings = await self._generate_jina_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by jina.')\n        \n            elif embedding_provider == \"voyage\":\n                embeddings = await self._generate_voyage_embedding(request_data, questions)\n\n                loggers['evaluation'].info(f'Generated embeddings for {len(embeddings)} questions by voyage.')\n                \n            for question, embedding in zip(questions, embeddings):\n                    query_embeddings = QueryEmbeddings(\n                        filename=request_data.file_name,\n                        embedding_model = request_data.embedding_model,\n                        dimension=request_data.dimension,\n                    )\n                    query_embeddings.add_question(question, embedding)\n                    result = await self.query_repository.insert_or_update_embeddings(query_embeddings)\n                    if result is None:\n                        loggers['evaluation'].error(\"Error inserting embeddings in motor\")\n                \n            if not len(embeddings) == len(questions):\n                loggers['main'].error(\"Error generating embeddings by pinecone\")\n                loggers[\"embedding\"].error(\"Error generating embeddings for questions: {questions}\")\n                \n            for question, embedding in zip(questions, embeddings):\n                self.validate_embedding(question, embedding, request_data.dimension)\n            \n            return embeddings\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error generating embedding: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nCore method in QueryUseCase that generates vector embeddings for search queries. First checks for cached embeddings in MongoDB, then routes to specialized embedding generators based on provider (Pinecone, Cohere, Jina, Voyage). Handles batched question processing, maintains dimension compatibility with embedding models, performs validation, and persists newly generated embeddings. Used in the search evaluation pipeline to convert natural language questions into vector representations for retrieval testing.\n",
        "size": 4333,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_dense_embedding"
    },
    {
        "id": "d19d8ff8ec58a706f493b75a2729b36fcc4565fae9989751488e7d02532d3151",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 306,
        "end_line": 319,
        "content": "async def _generate_pinecone_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Pinecone.\"\"\"\n    \n        pinecone_input = [{\"text\": question} for question in questions]\n        embeddings = await self.embedding_service.pinecone_dense_embeddings(\n            inputs=pinecone_input,\n            embedding_model=request_data.embedding_model,\n            dimension=request_data.dimension,\n            input_type=\"query\",\n        )\n        \n        return embeddings\n\nMethod in QueryUseCase class that generates vector embeddings for text queries using Pinecone's embedding service. It's one of several provider-specific embedding generation methods (alongside Cohere, Jina, and Voyage) used during the query processing workflow. This method transforms a list of question strings into the required format for Pinecone, calls the embedding service with appropriate parameters, and returns the resulting dense embeddings that will be used for vector similarity search against document chunks.",
        "size": 1061,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_pinecone_embedding"
    },
    {
        "id": "d26fe5324a0b8216c01dba12b3af3a2aa2cb023ed3050da6bb8408fae539988e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 321,
        "end_line": 331,
        "content": "async def _generate_cohere_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Cohere.\"\"\"\n        embeddings = await self.embedding_service.cohere_dense_embeddings(\n            texts=questions,\n            model_name=request_data.embedding_model,\n            input_type=\"search_query\",\n        )\n    \n        return embeddings\n\n\nA method within the QueryUseCase class that handles the generation of text embeddings specifically using Cohere's embedding models. It's one of several provider-specific embedding generation methods (alongside Pinecone, Jina, and Voyage). The method takes query requests and a list of questions, passes them to the embedding service with appropriate parameters, and returns dense vector embeddings formatted for retrieval operations. Called during the query execution flow when the selected embedding model is from Cohere's family of models.\n",
        "size": 945,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_cohere_embedding"
    },
    {
        "id": "88b4c1125faf84d9f64e250d4e859f66fd45acb7b04edec581c3e05e0bcd0705",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 333,
        "end_line": 345,
        "content": "async def _generate_jina_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        \"\"\"Generate embeddings using Jina.\"\"\"\n\n        embeddings = await self.embedding_service.jina_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"retrieval.query\",\n        )\n        \n        return embeddings\n\nMethod in QueryUseCase class that generates dense vector embeddings using Jina AI models. It takes query requests and question texts, calls the embedding service with appropriate parameters for Jina-specific embedding generation, and returns the vector representations. Part of a larger vector embedding system supporting multiple providers (Pinecone, Cohere, Jina, Voyage) for semantic search functionality.",
        "size": 859,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_jina_embedding"
    },
    {
        "id": "cc2100da61c64e42b0f38027d176b6fe3d01cd564fbc3ad8479b1c753fd64a91",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 347,
        "end_line": 357,
        "content": "async def _generate_voyage_embedding(\n        self, request_data: QueryEndPointRequest, questions: List[str]\n    ):\n        embeddings = await self.embedding_service.voyageai_dense_embeddings(\n            model_name=request_data.embedding_model,\n            dimension=request_data.dimension,\n            inputs=questions,\n            input_type=\"query\",\n        )\n\n        return embeddings\n\n\nFunction that generates text embeddings using the Voyage AI embedding model. Part of the QueryUseCase class that handles embedding generation for query processing. Accepts query data parameters and a list of questions, calls the embedding service with appropriate configuration, and returns vector embeddings. Used in the vector search retrieval pipeline alongside other embedding generation methods for different providers (Pinecone, Cohere, Jina).\n",
        "size": 843,
        "parent-class": "QueryUseCase",
        "function_name": "_generate_voyage_embedding"
    },
    {
        "id": "eaad667e5a1dddbe36a64cd7dbbf7e68aff6e5b8fd1976a53fa28b4ccfd6cee1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 359,
        "end_line": 381,
        "content": "async def _perform_hybrid_search(\n        self, request_data, namespace_name, host, dense_embedding, question\n    ):\n        \"\"\"Perform hybrid search using both dense and sparse embeddings.\"\"\"\n\n        try:\n            sparse_embedding = self.embedding_service.pinecone_sparse_embeddings(\n                inputs=[question]\n            )\n\n            return await self.pinecone_service.pinecone_hybrid_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                alpha=request_data.alpha,\n                query_vector_embeds=dense_embedding,\n                query_sparse_embeds=sparse_embedding[0],\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing hybrid search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in QueryUseCase class for executing hybrid vector search by combining dense and sparse embeddings. Creates sparse embeddings from the question text, then calls the pinecone service's hybrid query method with both embedding types. Used during query evaluation to retrieve relevant document chunks with configurable parameters like top_k results and alpha weighting between embedding types. Includes error handling with logging and appropriate HTTP exception raising.",
        "size": 1416,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_hybrid_search"
    },
    {
        "id": "24665720a221df57d60480d4d3042b19a38be912d847027a733f0332a23d2928",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 383,
        "end_line": 399,
        "content": "async def _perform_regular_search(\n        self, request_data, namespace_name, host, dense_embedding\n    ):\n        \"\"\"Perform regular dense vector search.\"\"\"\n\n        try:\n            return await self.pinecone_service.pinecone_query(\n                index_host=host,\n                namespace=namespace_name,\n                top_k=request_data.top_k,\n                vector=dense_embedding,\n                include_metadata=request_data.include_metadata,\n            )\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error performing regular search: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nVector search method in QueryUseCase class that performs dense embedding search through Pinecone. Part of the query evaluation system that handles standard vector similarity search as an alternative to hybrid search. Takes search parameters including namespace, host, and embeddings, then calls the pinecone_service to execute the query with appropriate error handling and logging.\n",
        "size": 1044,
        "parent-class": "QueryUseCase",
        "function_name": "_perform_regular_search"
    },
    {
        "id": "a647c06fa5d3c0f9ef5674c9fc450478c83dc0ce77095fac39327ab8a35b1457",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 401,
        "end_line": 404,
        "content": "async def _get_ground_truth(self, query):\n        \"\"\"Fetch ground truth data for the query.\"\"\"\n\n        return await self.index_repository.fetch_ground_truth(query=query)\n\n\nHelper method within the QueryUseCase class that asynchronously retrieves ground truth data for evaluation purposes by calling the fetch_ground_truth method from the index_repository. This method supports the retrieval evaluation workflow by providing reference data against which search results can be compared to calculate metrics like precision and recall.\n",
        "size": 533,
        "parent-class": "QueryUseCase",
        "function_name": "_get_ground_truth"
    },
    {
        "id": "89ce9828e8846b1b1cfe1f3504b309d26b8fab2ae0d2b10a44b2189e5c5890c9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 406,
        "end_line": 450,
        "content": "def _calculate_evaluation_metrics(self, relevant_docs, ground_truth_ids, top_k):\n        \"\"\"Calculate various evaluation metrics for the search results.\"\"\"\n\n        try:\n            return {\n                \"precision_at_k\": EvaluationService.precision_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"recall_at_k\": EvaluationService.recall_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"f1_score_at_k\": EvaluationService.f1_score_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"hit_rate_at_k\": EvaluationService.hit_rate_at_k(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k,\n                ),\n                \"ndcg_at_k\": EvaluationService.normalized_discounted_cumulative_gain_at_k(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids, k=top_k\n                ),\n                \"bpref\": EvaluationService.bpref(\n                    retrieved_docs=relevant_docs, ground_truth=ground_truth_ids\n                ),\n                \"mrr\": EvaluationService.reciprocal_rank(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids\n                ),\n                \"map\": EvaluationService.mean_average_precision(\n                    retrieved_docs=relevant_docs,\n                    ground_truth=ground_truth_ids,\n                    max_k=top_k\n                ),\n            }\n            \n        except Exception as e:\n            loggers['evaluation'].error(f\"Error calculating evaluation metrics: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nA method in the QueryUseCase class that calculates information retrieval evaluation metrics for search results. Takes retrieved documents, ground truth IDs, and top_k parameter to compute precision@k, recall@k, f1_score@k, hit_rate@k, NDCG@k, BPREF, MRR, and MAP using the EvaluationService. Used during search evaluation to assess retrieval performance against known relevant documents. Called during query processing to evaluate search effectiveness.",
        "size": 2468,
        "parent-class": "QueryUseCase",
        "function_name": "_calculate_evaluation_metrics"
    },
    {
        "id": "d7739fb3b8bb7c8ff758a8fcbdd02f141bcc363ee54b2e77b170e6d6865550dc",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 452,
        "end_line": 504,
        "content": "def average_metrics(self, metrics_list, top_k):\n    \n        sum_dict = {\n        \"precision_at_k\": {},\n        \"recall_at_k\": {},\n        \"f1_score_at_k\": {},\n        \"hit_rate_at_k\": {},\n        \"ndcg_at_k\": {},\n        \"bpref\": 0.0,\n        \"mrr\":0.0,\n        \"map\":0.0\n        }\n\n        for k in range(1, top_k + 1):\n            sum_dict[\"precision_at_k\"][f\"Precision@{k}\"] = 0.0\n            sum_dict[\"recall_at_k\"][f\"Recall@{k}\"] = 0.0\n            sum_dict[\"f1_score_at_k\"][f\"F1-Score@{k}\"] = 0.0\n            sum_dict[\"hit_rate_at_k\"][f\"Hit_Rate@{k}\"] = 0.0\n            sum_dict[\"ndcg_at_k\"][f\"NDCG@{k}\"] = 0.0\n        \n        avg_dict = sum_dict.copy()\n        \n        count_dict = {\n            \"precision_at_k\": 0.0,\n            \"recall_at_k\": 0.0,\n            \"f1_score_at_k\": 0.0,\n            \"hit_rate_at_k\": 0.0,\n            \"ndcg_at_k\": 0.0,\n            \"bpref\": 0.0,\n            \"mrr\":0.0,\n            \"map\":0.0\n        }\n        \n        for metric_dict in metrics_list:\n            for key, value in metric_dict.items():\n                if isinstance(value, dict):\n                    \n                    for sub_key, sub_value in value.items():\n                        sum_dict[key][sub_key] += sub_value\n                    count_dict[key] += 1\n                elif isinstance(value, (int, float)):\n                    \n                    sum_dict[key] += value\n                    count_dict[key] += 1\n        \n        for key, value in sum_dict.items():\n            if isinstance(value, dict): \n                avg_dict[key] = {sub_key: sub_value / count_dict[key] \n                                for sub_key, sub_value in value.items()}\n            else:\n                avg_dict[key] = value / count_dict[key]\n        \n        return avg_dict\n\nAggregation method within QueryUseCase class that calculates average evaluation metrics across multiple search results. Processes various information retrieval metrics including precision, recall, F1-score, hit rate, NDCG, BPREF, MRR, and MAP. The function handles both simple metrics and metrics that vary by k-value, accumulating values across all evaluation results before calculating final averages. Used in the search evaluation pipeline to provide summary performance statistics for vector search implementations.",
        "size": 2291,
        "parent-class": "QueryUseCase",
        "function_name": "average_metrics"
    },
    {
        "id": "51ce62912b132eddac0cf9308851032328a3b6e96fb72513f3fdbd86214954c8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/query_usecase.py",
        "file_name": "query_usecase.py",
        "start_line": 506,
        "end_line": 515,
        "content": "def validate_embedding(self, question: str, embedding: list, expected_dim: int):\n        \"\"\"Check if embedding is valid; otherwise, log failure.\"\"\"\n        if embedding is None or not isinstance(embedding, list):\n            loggers[\"embedding\"].error(f\"Invalid embedding for question: {question}\")\n\n        elif len(embedding) != expected_dim:\n            loggers[\"embedding\"].error(f\"Invalid embedding dimension for question: {question}\")\n    \n        elif any(np.isnan(embedding)) or any(np.isinf(embedding)):\n            loggers[\"embedding\"].error(f\"Invalid embedding values for question: {question}\")\n\n\nUtility method within the QueryUseCase class that validates vector embeddings by checking for null values, proper list type, correct dimensions, and containing valid numerical values (no NaN or infinity). Errors are logged to the embedding logger when validation fails. Used as part of the embedding generation pipeline to ensure quality before search operations are performed.\n",
        "size": 986,
        "parent-class": "QueryUseCase",
        "function_name": "validate_embedding"
    },
    {
        "id": "3ec178563cab47ffaa8e6f3e7c1b8ce0a31e540552380baca99a43063d978c78",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 1,
        "end_line": 11,
        "content": "import asyncio\nimport json\nimport os\nfrom uuid import uuid4\nfrom fastapi import UploadFile, HTTPException, status\nimport aiofiles\nfrom app.config.settings import settings\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\nfrom app.utils.llm_utils import LLMUtils\nfrom app.utils.logging_util import loggers\n\nImport declarations for a FastAPI file upload service that processes JSON data. Includes imports for async operations, file handling, repositories for ground truth and raw data, and utility classes for LLM interactions and logging.",
        "size": 595,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "46d8e813c799c697c6127915b56e1ef6acb9b69c6574c982bc2dc27055b51c9b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 14,
        "end_line": 17,
        "content": "def __init__(self):\n        self.raw_data_repo = RawDataRepo()\n        self.gt_data_repo = GTDataRepo()\n        self.llm_utils = LLMUtils()\n\nConstructor for the FileUploadUseCase class that initializes repositories for raw data storage, ground truth data storage, and LLM utility services required for file processing and analysis operations.",
        "size": 342,
        "parent-class": "FileUploadUseCase",
        "function_name": "__init__"
    },
    {
        "id": "34688fd23b36b6cb750d726af649ceb5ac190a19dead249372518eaabbbbfe98",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 19,
        "end_line": 25,
        "content": "async def store_file_locally(self, file: UploadFile):\n        os.makedirs(settings.UPLOAD_DIR, exist_ok=True)\n        file_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n        async with aiofiles.open(file_path, \"wb\") as f:\n            while chunk := await file.read(2 * 1024 * 1024):  # Read in 2MB chunks\n                await f.write(chunk)\n        return file_path\n\nMethod in FileUploadUseCase class that asynchronously saves uploaded files to local storage. Creates the upload directory if it doesn't exist, writes the file in 2MB chunks using aiofiles for asynchronous file operations, and returns the path where the file was stored. Part of the file processing pipeline for document ingestion.",
        "size": 725,
        "parent-class": "FileUploadUseCase",
        "function_name": "store_file_locally"
    },
    {
        "id": "fbce755440f3e912906275b6dab274824f4a2263faa5b655af8c13a225d92b14",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 27,
        "end_line": 39,
        "content": "async def process_and_enrich_json(self, file_path: str):\n        async with aiofiles.open(file_path, \"r\") as f:\n            content = await f.read()\n            data = json.loads(content)\n        if not isinstance(data, list):\n            raise ValueError(\"JSON data must be a list\")\n        enriched_data = []\n        for item in data:\n            item[\"_id\"] = str(uuid4())\n            enriched_data.append(item)\n        async with aiofiles.open(file_path, \"w\") as f:\n            await f.write(json.dumps(enriched_data))\n        return enriched_data\n\nMethod in FileUploadUseCase that reads, validates, and enhances JSON data by adding unique identifiers. Performs asynchronous file operations to read JSON content, ensures it's in list format, adds UUID to each item, then overwrites the original file with the enriched data before returning it for further processing. Part of the file upload and data preparation pipeline for document processing.",
        "size": 949,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_and_enrich_json"
    },
    {
        "id": "2a33ef1e97ad5d81536786fe878e3c7695354ebec85535b8a84e494ee8821c5f",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 41,
        "end_line": 73,
        "content": "async def process_multi_chunk(self, data: dict):\n\n        loggers['main'].info(f\"length of data before : {len(data)}\")\n        chunks = [item for item in data[\"chunks\"] if item.get(\"text\", \"\").strip()]\n        loggers['main'].info(f\"length of data after : {len(chunks)}\")\n\n        chunk_data_for_llm = [\n            {\"text\": chunk[\"text\"], \"_id\": chunk[\"_id\"]} for chunk in data[\"chunks\"]\n        ]\n\n        response_json = await self.llm_utils.generate_multi_chunk_question(\n            {\"chunks\": chunk_data_for_llm, \"file_type\": data[\"file_type\"]}\n        )\n        # loggers['main'].info(f\"response_json from generate multi : {response_json}\")\n\n        if isinstance(response_json, str):\n            try:\n                response = json.loads(response_json)\n            except Exception as e:\n                raise ValueError(str(e))\n        else:\n            response = response_json\n\n        final_results = []\n        for question_item in response:\n            relevant_ids = question_item[\"relevant_ids\"]\n            relevant_chunks = [chunk for chunk in data[\"chunks\"] if str(chunk[\"_id\"]) in relevant_ids]\n            \n            final_results.append({\n                \"question\": question_item[\"question\"],\n                \"chunks\": relevant_chunks\n            })\n        return final_results\n\n\nMethod in FileUploadUseCase class that processes text chunks to generate questions with relevant chunks. It filters empty chunks, prepares data for LLM processing, calls generate_multi_chunk_question, parses the response, and constructs result objects containing questions paired with their relevant text chunks. Used as part of a document processing pipeline that creates multi-chunk queries for document search and retrieval functionality.\n",
        "size": 1749,
        "parent-class": "FileUploadUseCase",
        "function_name": "process_multi_chunk"
    },
    {
        "id": "8fb9a720f10306bd19daedbe8d3cdae8baa48ecb87896300574af52b19ec7cdf",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 75,
        "end_line": 92,
        "content": "async def generate_multi_chunk_queries(self, data):\n        dataset = []\n        tasks = []\n        for i in range(\n            0,\n            min(len(data[\"chunks_with_metadata\"]), settings.NO_OF_CHUNKS_AT_A_TIME*settings.MULTI_CHUNK_QUERIES_COUNT),\n            settings.NO_OF_CHUNKS_AT_A_TIME\n        ):\n\n            selected_items = data[\"chunks_with_metadata\"][i:i+settings.NO_OF_CHUNKS_AT_A_TIME]\n            task = self.process_multi_chunk({\"chunks\": selected_items, \"file_type\": data[\"file_type\"]})\n            tasks.append(task)\n        \n        results = await asyncio.gather(*tasks)\n        for result in results:\n            dataset.extend(result)\n        loggers['main'].info(f\"length of results in generate multi : {len(results)}\")\n        return dataset\n\nMethod within FileUploadUseCase that processes document chunks in batches to generate multi-chunk queries. Divides data into smaller groups based on configured chunk size limits, processes each batch asynchronously by calling process_multi_chunk, and aggregates the results. Uses asyncio.gather for parallel execution. Key part of the document processing pipeline that prepares data for query generation with controlled batching and concurrency.",
        "size": 1214,
        "parent-class": "FileUploadUseCase",
        "function_name": "generate_multi_chunk_queries"
    },
    {
        "id": "6aab042ec674207b65176e293c0dfe3026933e6e593f62bf5212f2a35be60b76",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/file_upload_usecase.py",
        "file_name": "file_upload_usecase.py",
        "start_line": 94,
        "end_line": 171,
        "content": "async def execute(self, request_data):\n        try:\n\n            # File Store\n            file = request_data.get(\"input_data\")\n            file_name = request_data.get(\"file_name\")\n            file_type = request_data.get(\"file_type\")\n\n            if not isinstance(file_name, str):\n                raise ValueError(\"File name must be a string\")\n            _, file_extension = os.path.splitext(file_name)\n            if file_extension.lower() != \".json\":\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file is not in .json format\")\n\n            file_path = await self.store_file_locally(file)\n\n            existing_gt_data = await self.gt_data_repo.is_exist(file_name, file_type)\n            \n            if existing_gt_data:\n                doc = await self.raw_data_repo.is_exist(file_name, file_type)\n                doc = doc[\"data\"][0]\n                file_schema = {key: type(value).__name__ for key, value in doc.items() if key != \"_id\"}\n                if \"text\" not in file_schema.keys():\n                    raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n                \n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_gt_data.get(\"data\", []), default=str))\n                \n                existing_raw_data = await self.raw_data_repo.is_exist(file_name, file_type)\n                dataset_path = os.path.join(settings.UPLOAD_DIR, settings.RAW_DATA_FILE_NAME)\n                async with aiofiles.open(dataset_path, \"w\") as f:\n                    await f.write(json.dumps(existing_raw_data.get(\"data\", []), default=str))\n                return {\"data\": \"File already processed\", \"file_schema\": json.dumps(file_schema)}\n            \n            enriched_data = await self.process_and_enrich_json(file_path)\n\n            loggers['main'].info(f\"length of data before : {len(enriched_data)}\")\n            enriched_data = [item for item in enriched_data if item.get(\"text\", \"\").strip()]\n            loggers['main'].info(f\"length of data after : {len(enriched_data)}\")\n\n            file_schema = {key: type(value).__name__ for key, value in enriched_data[0].items() if key != \"_id\"}\n            if \"text\" not in list(file_schema.keys()):\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"The file should contain text field.\")\n            \n            # Generate Queries\n            multi_chunk_dataset = await self.generate_multi_chunk_queries(\n                {\"chunks_with_metadata\": enriched_data, \"file_type\": file_type}\n            )\n            loggers[\"main\"].info(f\"length of multi chunk dataset : {len(multi_chunk_dataset)}\")\n            raw_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": enriched_data\n            }\n            await self.raw_data_repo.insert_documents(raw_data_document)\n\n            gt_data_document = {\n                \"file_name\": file_name,\n                \"file_type\": file_type,\n                \"data\": [\n                    item.copy() for item in multi_chunk_dataset\n                ]\n            }\n            # loggers[\"main\"].info(f\"gt_data_document{gt_data_document}\")\n            try:\n                await self.gt_data_repo.insert_documents(gt_data_document)\n            except Exception as e:\n                loggers['main'].error(f\"documents were not inserted in mongodb , length of gt: {len(gt_data_document.get('data', []))}\")\n\n            dataset_path = os.path.join(settings.UPLOAD_DIR, settings.GT_DATA_FILE_NAME)\n            async with aiofiles.open(dataset_path, \"w\") as f:\n                await f.write(json.dumps(multi_chunk_dataset))\n\n            return {\"data\": \"File processed and dataset generated successfully\", \"file_schema\": json.dumps(file_schema)}\n        except Exception as e:\n            loggers['main'].error(f\"file upload usecase outermost code breaks : {str(e)}\")\n            raise Exception(str(e))\n\n\nMain execution method of FileUploadUseCase class handling JSON file processing workflow. Validates uploaded files, checks for existing data in repositories, processes new files by enriching with UUIDs, filters for text content, generates multi-chunk queries using LLM, stores processed data in both raw and ground truth repositories, and writes output files to disk. Includes error handling for file format validation, schema requirements, and database operations. Returns processing status and file schema information.\n",
        "size": 4674,
        "parent-class": "FileUploadUseCase",
        "function_name": "execute"
    },
    {
        "id": "b9e6ce4b970b3b110cd4d13b91eff3e77548a6bdd20e8445a59cad1b2f9ba7ea",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi import Depends, HTTPException, status\nfrom app.models.domain.indexupsert import IndexUpsert, Namespace\nfrom app.repositories.index_upsert_repository import IndexUpsertRepository\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.utils.logging_util import loggers\nimport time\n\nImport declarations for the IndexUpsertUseCase class, bringing in asynchronous functionality, JSON processing, FastAPI dependencies, domain models for index operations, repository interfaces, embedding services, Pinecone vector database integration, logging utilities, and time tracking. Sets up the foundation for an asynchronous vector database indexing and embedding system.",
        "size": 820,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "b18fa7de9b1a6fe8fbe852998ae0195e9b829306d66a3cd2151ff8e6b73c7d2b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 17,
        "end_line": 49,
        "content": "def __init__(\n        self,\n        index_upsert_repository=Depends(IndexUpsertRepository),\n        pinecone_service=Depends(PineconeService),\n        embedding_service=Depends(EmbeddingService),\n    ):\n        self.index_upsert_repository = index_upsert_repository\n        self.pinecone_service = pinecone_service\n        self.embedding_service = embedding_service\n        self.file_path = \"uploads/raw_dataset.json\"\n        self.chunk_size = 90\n        self.semaphore = asyncio.Semaphore(3)\n        self.upsert_batch_size = 50\n        self.model_provider = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"jina-clip-v2\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n\nConstructor for IndexUpsertUseCase class that initializes dependencies for vector database operations. Sets up repositories and services needed for embedding generation and vector storage. Configures operational parameters including file path, chunk size, concurrency controls via semaphore, batch processing size, and a mapping dictionary that associates embedding model names with their provider platforms (Pinecone, Cohere, Jina, Voyage). Used within a FastAPI dependency injection system for vector search implementation.",
        "size": 1895,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "__init__"
    },
    {
        "id": "2141fe16912317c1e99c5e4cc11421b690ebf0db2a4b64e918ddb36eea2b58e0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 51,
        "end_line": 76,
        "content": "async def process_chunk(self, chunk, provider, embed_model, dimension=None):\n        async with self.semaphore:\n            try:\n                if provider == \"pinecone\":\n                    return (\n                        await self.embedding_service.pinecone_dense_embeddings(\n                            chunk, embed_model, dimension=dimension\n                        )\n                    )\n                elif provider == \"cohere\":\n                    return await self.embedding_service.cohere_dense_embeddings(\n                        embed_model, chunk\n                    )\n                elif provider == \"jina\":\n                    return await self.embedding_service.jina_dense_embeddings(\n                        embed_model, dimension, chunk, \"retrieval.passage\"\n                    )\n                elif provider == \"voyage\":\n                    return await self.embedding_service.voyageai_dense_embeddings(\n                        embed_model, dimension, chunk\n                    )\n            except Exception as e:\n                loggers[\"main\"].error(\n                    f\"Error processing chunk with {provider} provider: {str(e)}\"\n                )\n                raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in IndexUpsertUseCase class that processes data chunks for embedding generation, routing to appropriate embedding service methods based on provider type (pinecone, cohere, jina, voyage). Uses semaphore for concurrency control and includes error handling with logging. Serves as a helper function for the embedding pipeline in vector database operations.",
        "size": 1620,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "process_chunk"
    },
    {
        "id": "f338a7345ce1ebe099ea8326ebf9df5f8f4812feeb954a47206a074fe987df9a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 78,
        "end_line": 112,
        "content": "async def _get_embeddings(self, data, embed_model, dimension):\n        try:\n            all_embeddings = []\n            embedding_provider = self.model_provider.get(embed_model)\n\n            if embedding_provider == \"pinecone\":\n                inputs = [{\"text\": item[\"text\"]} for item in data]\n            elif embedding_provider == \"cohere\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"jina\":\n                inputs = [item[\"text\"] for item in data]\n            elif embedding_provider == \"voyage\":\n                inputs = [item.get(\"text\", item.get(\"code\")) for item in data]\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            chunks = [\n                inputs[i : i + self.chunk_size]\n                for i in range(0, len(inputs), self.chunk_size)\n            ]\n            tasks = [\n                self.process_chunk(\n                    chunk, embedding_provider, embed_model, dimension\n                )\n                for chunk in chunks\n            ]\n            chunk_results = await asyncio.gather(*tasks)\n\n            for embeddings in chunk_results:\n                all_embeddings.extend(embeddings)\n\n            return all_embeddings\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nPrivate method in IndexUpsertUseCase class that handles vector embedding generation. Formats input data according to the specified embedding provider (pinecone, cohere, jina, or voyage), chunks inputs into batches, processes chunks concurrently using semaphore-controlled tasks, and collects all embeddings. Supports different embedding models with corresponding dimensions and handles errors by logging and returning appropriate HTTP exceptions. Called by the _prepare_and_upsert method as part of the vector database indexing pipeline.\n",
        "size": 2005,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_get_embeddings"
    },
    {
        "id": "1b357d0df7872f84e79baa269438d0e94ebcc279904b4973c91b2bf0f995620a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 114,
        "end_line": 122,
        "content": "async def _upsert_batch(self, index_host, batch, namespace_name):\n        \"\"\"Helper function to upsert a single batch of vectors\"\"\"\n        try:\n            return await self.pinecone_service.upsert_vectors(\n                index_host, batch, namespace_name\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error upserting batch: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nHelper method within IndexUpsertUseCase that manages the upserting of a single batch of vectors to Pinecone. Takes index host, vector batch, and namespace parameters. Calls the pinecone_service to perform the actual vector upsert operation, handles errors with logging, and raises HTTP exceptions when failures occur. Used as part of the batch processing system for vector database operations.",
        "size": 831,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_upsert_batch"
    },
    {
        "id": "2a57576fc119729404d6bf98a2b3c6e022c0ca5247bb182ed2ecfbd84fee0249",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 124,
        "end_line": 167,
        "content": "async def _prepare_and_upsert(\n        self, data, embed_model, dimension, index_host, namespace_name\n    ):\n        try:\n            all_embeddings = await self._get_embeddings(\n                data, embed_model, dimension\n            )\n\n            text_list = [item[\"text\"] for item in data]\n            sparse_embeds = self.embedding_service.pinecone_sparse_embeddings(\n                text_list\n            )\n            final_upsert_format = await self.pinecone_service.upsert_format(\n                data, all_embeddings, sparse_embeds\n            )\n\n            batches = [\n                final_upsert_format[i : i + self.upsert_batch_size]\n                for i in range(0, len(final_upsert_format), self.upsert_batch_size)\n            ]\n\n            loggers[\"main\"].info(f\"Upserting {len(final_upsert_format)} vectors in {len(batches)} batches\")\n\n            upsert_tasks = [\n                self._upsert_batch(index_host, batch, namespace_name)\n                for batch in batches\n            ]\n            \n            # Gather results from all batches\n            batch_results = await asyncio.gather(*upsert_tasks)\n            \n            # Combine results\n            total_upserted = sum(result.get(\"upserted_count\", 0) for result in batch_results)\n            time.sleep(15)\n            return {\n                \"upserted_count\": total_upserted,\n                \"batches_processed\": len(batches),\n                \"batch_results\": batch_results\n            }\n\n    \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in preparing and upserting vectors : {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate method in IndexUpsertUseCase that prepares and uploads vector embeddings to Pinecone. The function generates both dense embeddings (via _get_embeddings) and sparse embeddings, formats them for Pinecone, splits them into batches based on upsert_batch_size, and executes parallel batch upserts. It processes text data through embedding generation, vector formatting, batch splitting, concurrent uploading, and returns statistics about the operation including counts of successfully upserted vectors. Includes error handling with appropriate logging and HTTP exception raising.",
        "size": 2252,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_prepare_and_upsert"
    },
    {
        "id": "f91cfb86aecd1f5245daa021f3ef724a8629923aa134c0e65d19b6915707a0f9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 169,
        "end_line": 196,
        "content": "async def _save_in_db(\n        self,\n        file_name,\n        embed_model,\n        index_name,\n        index_host,\n        dimension,\n        similarity_metric,\n    ):\n        namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n        namespace = Namespace(\n            name=namespace_name, filename=file_name, embedding_model=embed_model\n        )\n\n        index_upsert = IndexUpsert(\n            index_name=index_name,\n            index_host=index_host,\n            dimension=dimension,\n            similarity_metric=similarity_metric,\n        )\n\n        index_upsert.add_namespace(namespace)\n        return (\n            await self.index_upsert_repository.add_index_upsert_details(\n                index_upsert\n            ),\n        )\n\nHelper method within IndexUpsertUseCase class that persists vector database index and namespace information to database storage. Creates a unique namespace using filename and embedding model, constructs IndexUpsert and Namespace domain objects, links them together, and saves the configuration via repository. Used during vector database operations to track which embeddings have been stored where, supporting the overall document indexing workflow.",
        "size": 1197,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "_save_in_db"
    },
    {
        "id": "a0fd47fda7c6a063782259f296cb54ee7c01043ad593bb3f5de3454a8daa8ae8",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/index_upsert_usecase.py",
        "file_name": "index_upsert_usecase.py",
        "start_line": 198,
        "end_line": 300,
        "content": "async def index_upsert(self, request):\n        try:\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            embed_model = request.embed_model\n\n            already_upserted = (\n                await self.index_upsert_repository.find_matching_index_upsert(\n                    dimension, similarity_metric, file_name, embed_model\n                )\n            )\n\n            if already_upserted:\n                return {\n                    \"message\": \"such dimension, similarity metric, filename and embed_model configuration already exists, move on to query\"\n                }\n\n            with open(self.file_path, \"r\") as file:\n                data = json.load(file)\n\n            loggers[\"main\"].info(f\"length of data before : {len(data)}\")\n            data = [item for item in data if item.get(\"text\", \"\").strip()]\n            loggers[\"main\"].info(f\"length of data after : {len(data)}\")\n\n\n\n            already_index = (\n                await self.index_upsert_repository.find_matching_index(\n                    dimension, similarity_metric\n                )\n            )\n\n            if not already_index:\n                index_json = await self.pinecone_service.list_pinecone_indexes()\n                index_list = index_json.get(\"indexes\")\n                index_names = [index[\"name\"] for index in index_json[\"indexes\"]]\n                if(len(index_list) >= 5):\n                    loggers[\"main\"].error(f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n                    raise HTTPException(status_code= status.HTTP_403_FORBIDDEN, detail = f\"Already 5 indexes are created in pinecone couldn't make one more, already existing indexes {index_names}\")\n\n                loggers[\"main\"].info(f\"already index {already_index}\")\n                loggers[\"main\"].info(f\"index list {index_json}\")\n\n\n                index_name = f\"{similarity_metric}-{dimension}\"\n                response = await self.pinecone_service.create_index(\n                    index_name, dimension, similarity_metric\n                )\n                index_host = response.get(\"host\")\n\n                namespace_name = f\"{file_name}-{embed_model}-namespace\"\n\n                upsert_result = await self._prepare_and_upsert(\n                    data, embed_model, dimension, index_host, namespace_name\n                )\n\n                db_result = await self._save_in_db(\n                    file_name,\n                    embed_model,\n                    index_name,\n                    index_host,\n                    dimension,\n                    similarity_metric,\n                )\n\n                return {\n                    \"upsert_result\": upsert_result,\n                    \"database_result\": db_result,\n                }\n\n            index_name = already_index.get(\"index_name\")\n            index_host = already_index.get(\"index_host\")\n\n            index_json = await self.pinecone_service.list_pinecone_indexes()\n            index_list = index_json.get(\"indexes\")\n            loggers[\"main\"].info(f\"length of index list : {len(index_list)}\")\n\n            loggers[\"main\"].info(f\"already index outside if{already_index}\")\n            loggers[\"main\"].info(f\"index list outside if {index_list}\")\n\n            namespace_name = f\"{file_name}-{embed_model}-namespace\"\n            upsert_result = await self._prepare_and_upsert(\n                data, embed_model, dimension, index_host, namespace_name\n            )\n\n            db_result = await self._save_in_db(\n                file_name,\n                embed_model,\n                index_name,\n                index_host,\n                dimension,\n                similarity_metric,\n            )\n\n            return {\n                \"upsert_result\": upsert_result,\n                \"database_result\": db_result,\n            }\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in index upsert {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n\nMain implementation of the IndexUpsertUseCase's index_upsert method that processes vector embedding requests. Handles creation and management of Pinecone indexes based on dimension and similarity metric parameters. Checks for existing index configurations, enforces a limit of 5 Pinecone indexes, creates new indexes when needed, and upserts document vectors with appropriate namespaces. The method loads data from a JSON file, filters empty entries, generates embeddings through the _prepare_and_upsert helper method, and records index metadata in the repository. Implements error handling with detailed logging throughout the vector database indexing workflow.\n",
        "size": 4751,
        "parent-class": "IndexUpsertUseCase",
        "function_name": "index_upsert"
    },
    {
        "id": "7cf646a1b37633dd4a511aae6958d7567f033094a7788cbfb6286ffa13c22f27",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 1,
        "end_line": 5,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.services.embedding_service import EmbeddingService\nfrom app.services.pinecone_service import PineconeService\nfrom app.repositories.index_repository import IndexRepository\nfrom app.utils.logging_util import loggers\n\nImport statements for the RandomQueryUseCase class in a FastAPI application, importing HTTP-related functions from FastAPI, embedding generation services, Pinecone vector database service, data access layer components, and logging utilities.",
        "size": 516,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "9e4b7f8e897bdfdc63ba58672ee9b9bec46755c7312bc1a976c9f833435b2973",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 10,
        "end_line": 52,
        "content": "def __init__(\n        self,\n        index_repository: IndexRepository = Depends(),\n        embedding_service: EmbeddingService = Depends(),\n        pinecone_service: PineconeService = Depends(), \n    ):\n        self.index_repository = index_repository\n        self.embedding_service = embedding_service\n        self.pinecone_service = pinecone_service\n        self.embeddings_provider_mapping = {\n            \"llama-text-embed-v2\": \"pinecone\",\n            \"multilingual-e5-large\": \"pinecone\",\n            \"embed-english-v3.0\": \"cohere\",\n            \"embed-multilingual-v3.0\": \"cohere\",\n            \"embed-english-light-v3.0\": \"cohere\",\n            \"embed-multilingual-light-v3.0\": \"cohere\",\n            \"embed-english-v2.0\": \"cohere\",\n            \"embed-english-light-v2.0\": \"cohere\",\n            \"embed-multilingual-v2.0\": \"cohere\",\n            \"jina-embeddings-v3\": \"jina\",\n            \"jina-clip-v2\" : \"jina\",\n            \"jina-embeddings-v2-base-code\": \"jina\",\n            \"voyage-3-large\": \"voyage\",\n            \"voyage-code-3\": \"voyage\",\n            \"voyage-finance-2\": \"voyage\",\n            \"voyage-3\": \"voyage\",\n            \"voyage-3-lite\": \"voyage\",\n            \"voyage-law-2\": \"voyage\"\n        }\n        self.model_to_dimensions = {\n            \"llama-text-embed-v2\": [1024, 2048, 768, 512, 384],\n            \"multilingual-e5-large\": [1024],\n            \"embed-english-v3.0\": [1024],\n            \"embed-multilingual-v3.0\": [1024],\n            \"embed-english-light-v3.0\": [384],\n            \"embed-multilingual-light-v3.0\": [384],\n            \"embed-english-v2.0\": [4096],\n            \"embed-multilingual-v2.0\": [768],\n            \"jina-embeddings-v3\": [32, 64, 128, 256, 512, 768, 1024],\n            \"jina-clip-v2\": [64, 128, 256, 512, 768, 1024],\n            \"jina-embeddings-v2-base-code\": [768],\n            \"voyage-code-3\": [256, 512, 1024, 2048]\n        }\n\nInitializes the RandomQueryUseCase with dependency injection for repository and services. Maps embedding models to their providers (pinecone, cohere, jina, voyage) and defines supported dimension configurations for each model. This setup enables the class to route embedding generation requests to appropriate services and validate dimension parameters during vector search operations.",
        "size": 2257,
        "parent-class": "RandomQueryUseCase",
        "function_name": "__init__"
    },
    {
        "id": "a779846bbc15f5a1c3ed6fddb8bd2dcd4a46886e9513d1f9f516234e0cd50593",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 55,
        "end_line": 78,
        "content": "async def _get_namespace_and_host(self, similarity_metric, dimension, embedding_model, file_name):\n        \"\"\"Get the namespace and host for the index.\"\"\"\n\n        try:\n            index_name = (\n                f\"{similarity_metric}-{dimension}\"\n            )\n            namespace_name, host = (\n                await self.index_repository.get_namespace_and_host(\n                    index_name,\n                    embedding_model,\n                    file_name,\n                )\n            )\n\n            if not namespace_name or not host:\n                loggers[\"main\"].info(f\"Namespace or host not found for {index_name}\")\n                raise HTTPException(status_code=404, detail=\"Namespace not found.\")\n\n            return namespace_name, host\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error fetching namespace and host: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nHelper method in RandomQueryUseCase class that constructs an index name from similarity metric and dimension parameters, then retrieves the corresponding namespace and host from the index repository. Used in vector search operations to locate the correct Pinecone index. Handles error cases by logging failures and raising appropriate HTTP exceptions when namespace or host information cannot be found.",
        "size": 1341,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_namespace_and_host"
    },
    {
        "id": "a27799ec95c4723926863b28abf343df7f519fa35804bc7e9866edac41f97dce",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 81,
        "end_line": 119,
        "content": "async def _get_query_embeddings(self, query, embed_model, dimension):\n        try:\n            embedding_provider = self.embeddings_provider_mapping.get(embed_model)\n            if embedding_provider == \"pinecone\":\n\n                pinecone_input = [{\"text\": query}]\n                embeddings =  await self.embedding_service.pinecone_dense_embeddings(\n                    pinecone_input, embed_model, dimension=dimension,input_type=\"query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"cohere\":\n                cohere_input = [query]\n                embeddings = await self.embedding_service.cohere_dense_embeddings(\n                    cohere_input, embed_model, input_type=\"search_query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"jina\":\n                jina_input = [query]\n                embeddings = await self.embedding_service.jina_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = jina_input, input_type = \"retrieval.query\"\n                )\n                return embeddings[0]\n            \n            elif embedding_provider == \"voyage\":\n                voyage_input = [query]\n                embeddings = await self.embedding_service.voyageai_dense_embeddings(\n                    embed_model, dimension = dimension, inputs = voyage_input, input_type = \"query\"\n                )\n                return embeddings[0]\n\n            else:\n                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid Embedding Model\")\n\n            \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error generating embedding {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nPrivate method in RandomQueryUseCase that generates vector embeddings for query text using various models. Maps embedding provider names to appropriate services (Pinecone, Cohere, Jina, Voyage), handling provider-specific input formats and parameters. Determines which embedding service to use based on the model name, passes dimension parameters where needed, and returns the first embedding vector from the result. Called by the random_query method as part of vector search functionality.",
        "size": 2294,
        "parent-class": "RandomQueryUseCase",
        "function_name": "_get_query_embeddings"
    },
    {
        "id": "8f84c53d9c8557a2092466f9c818c05db80a7dbea3981c071f4683522329541d",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_query_usecase.py",
        "file_name": "random_query_usecase.py",
        "start_line": 122,
        "end_line": 166,
        "content": "async def random_query(self, request):\n        try:\n            query = request.query\n            embed_model = request.embedding_model\n            dimension = request.dimension\n            similarity_metric = request.similarity_metric\n            file_name = request.file_name\n            top_k = request.top_k\n            include_metadata = request.include_metadata\n            namespace, host = await self._get_namespace_and_host(similarity_metric, dimension, embed_model,file_name)\n        \n           \n            query_dense_vector = await self._get_query_embeddings(query, embed_model, dimension)\n            \n            if request.is_hybrid:\n                query_sparse_vector = self.embedding_service.pinecone_sparse_embeddings([query])\n                query_sparse_vector = query_sparse_vector[0]\n                alpha = request.alpha\n                loggers[\"main\"].info(\"sparse embeddings generated in random query use case\")\n                pinecone_response = await self.pinecone_service.pinecone_hybrid_query(\n                    host, namespace, top_k, alpha, query_dense_vector, query_sparse_vector, include_metadata\n                )\n            else:\n                pinecone_response = await self.pinecone_service.pinecone_query(\n                    host, namespace, top_k, query_dense_vector, include_metadata\n                )\n            \n            matches = pinecone_response.get(\"matches\", [])\n            final_responses = []\n            for match in matches:\n                score = match.get(\"score\", None)\n                id = match.get(\"id\", None)\n                text = match.get(\"metadata\", None).get(\"text\", None)\n                metadata = {key: value for key, value in match.get(\"metadata\").items() if key != \"text\"}\n                final_responses.append({\n                    \"id\": id,\n                    \"score\": score,\n                    \"text\": text,\n                    \"metadata\": metadata\n                })\n            return final_responses\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in random_query_usecase: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\n\nMain implementation method of RandomQueryUseCase that processes vectorized semantic search queries against Pinecone vector database. Extracts request parameters, generates dense embeddings for the query, performs either standard or hybrid vector search (combining dense and sparse vectors), formats results with scores and metadata, and handles exceptions with appropriate error logging. Supports various embedding models through dimension-specific namespacing and customizable search parameters including top_k results and metadata inclusion.\n",
        "size": 2754,
        "parent-class": "RandomQueryUseCase",
        "function_name": "random_query"
    },
    {
        "id": "4a290fe9faa48c8f0282700f64d4c10dfce10a0d170e4ae32f062d2f99a042b7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 1,
        "end_line": 3,
        "content": "from fastapi import Depends, HTTPException, status\nfrom app.repositories.gt_data_repo import GTDataRepo\nfrom app.repositories.raw_data_repo import RawDataRepo\n\nImport statements for a FastAPI application use case that retrieves random questions. Imports dependency injection utilities, HTTP exception handling, repository interfaces for ground truth data and raw data access.",
        "size": 375,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "5c74e17f267c0d5d08fa649c5a036dc5c6802bc42beb8cc26f3be25d734c0da5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 9,
        "end_line": 15,
        "content": "def __init__(\n        self, \n        gt_data_repo: GTDataRepo = Depends(),\n        raw_data_repo: RawDataRepo = Depends(),\n    ):\n        self.gt_data_repo = gt_data_repo\n        self.raw_data_repo = raw_data_repo\n\nInitialization method for RandomQuestionUseCase class that injects repository dependencies using FastAPI's dependency injection system. Sets up GTDataRepo for ground truth data access and RawDataRepo for raw text data retrieval, both required for random question generation functionality.",
        "size": 503,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "__init__"
    },
    {
        "id": "a566c74cd6be34b6865cd71874a3142d657efc506ff064b20d5daba59b357a95",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/usecases/random_question_usecase.py",
        "file_name": "random_question_usecase.py",
        "start_line": 17,
        "end_line": 28,
        "content": "async def random_question(self, file_name):\n        try:\n            question_with_groundtruth, ids = await self.gt_data_repo.get_random_question(file_name)\n           \n            text_content = await self.raw_data_repo.fetch_texts_by_ids(file_name,ids)\n            \n            for i in range(len(ids)):\n                question_with_groundtruth[\"chunks\"][i][\"text\"] = text_content[i]\n               \n            return question_with_groundtruth\n        except Exception as e:\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))\n\nMethod in RandomQuestionUseCase class that retrieves a random question with its ground truth data. Fetches question details from gt_data_repo, retrieves corresponding text content from raw_data_repo using document IDs, populates the question chunks with actual text content, and handles exceptions by raising HTTP 500 errors. Core functionality for random question retrieval in a FastAPI application.",
        "size": 978,
        "parent-class": "RandomQuestionUseCase",
        "function_name": "random_question"
    },
    {
        "id": "560b96cee9700ee5aad337552339d0f117c8ce3ceafae3d7e0cb3403c8a5294e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 1,
        "end_line": 10,
        "content": "import asyncio\nimport json\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict\nimport httpx\nfrom fastapi import HTTPException\nfrom pinecone import Pinecone\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\n\nImport statements for the PineconeService class, which handles vector database operations. Includes essential dependencies for asynchronous HTTP requests (asyncio, httpx), data handling (json, datetime), error management (HTTPException), and the Pinecone vector database integration. These imports support the service's capabilities for vector embedding storage, retrieval, and hybrid search functionality.",
        "size": 666,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "4e8e4f1f67baa55f2fc9c18b041aa8b86465bdc77b24f5cf447e9d4654f58f66",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 16,
        "end_line": 31,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.api_version = settings.PINECONE_API_VERSION\n        self.index_url = settings.PINECONE_CREATE_INDEX_URL\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.upsert_url = settings.PINECONE_UPSERT_URL\n        self.query_url = settings.PINECONE_QUERY_URL\n        self.list_index_url = settings.PINECONE_LIST_INDEXES_URL\n        self.semaphore = asyncio.Semaphore(10)\n        self.pc = Pinecone(api_key=settings.PINECONE_API_KEY)\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nInitialization method for the PineconeService class that configures connections to Pinecone vector database. Sets up API keys, endpoints, connection parameters, creates a Pinecone client instance, and configures timeouts for HTTP requests. Prepares the service for vector database operations including index creation, vector upserts, and hybrid search queries.",
        "size": 1240,
        "parent-class": "PineconeService",
        "function_name": "__init__"
    },
    {
        "id": "a058a6237ad7918cc22ce8ff62cc33e4fd90495c5783a545c0f8a8bd9e567426",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 33,
        "end_line": 53,
        "content": "async def list_pinecone_indexes(self):\n        url = self.list_index_url\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url, headers=headers)\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n\n            loggers[\"main\"].error(f\"Error creating index: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the PineconeService class that retrieves all available indexes from Pinecone using the API. Makes an authenticated GET request with the Pinecone API key and version headers, handles HTTP errors with appropriate status codes and logging, and returns the JSON response containing the list of indexes. Part of the vector database interface that supports querying, indexing, and managing vector embeddings in the application.",
        "size": 1228,
        "parent-class": "PineconeService",
        "function_name": "list_pinecone_indexes"
    },
    {
        "id": "34a1094bd292436688f344a589bac63bc55758f3fc31841761a050979bdb6832",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 55,
        "end_line": 118,
        "content": "async def create_index(\n        self, index_name: str, dimension: int, metric: str\n    ) -> Dict[str, Any]:\n        if self.pc.has_index(index_name) == False:\n            index_data = {\n                \"name\": index_name,\n                \"dimension\": dimension,\n                \"metric\": metric,\n                \"spec\": {\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}},\n            }\n\n            headers = {\n                \"Accept\": \"application/json\",\n                \"Content-Type\": \"application/json\",\n                \"Api-Key\": self.pinecone_api_key,\n                \"X-Pinecone-API-Version\": self.api_version,\n            }\n\n            try:\n                async with httpx.AsyncClient() as client:\n                    response = await client.post(\n                        self.index_url, headers=headers, json=index_data\n                    )\n                    response.raise_for_status()\n\n                    retry_count = 0\n                    max_retries = 30\n                    while retry_count < max_retries:\n                        status = (\n                            self.pc.describe_index(index_name)\n                            .get(\"status\")\n                            .get(\"state\")\n                        )\n                        loggers[\"main\"].info(f\"Index status: {status}\")\n\n                        if status == \"Ready\":\n                            loggers[\"main\"].info(f\"Index {index_name} is ready\")\n                            break\n\n                        retry_count += 1\n                        time.sleep(2)\n\n                    if retry_count > max_retries:\n                        raise HTTPException(\n                            status_code=500, detail=\"Index creation timed out\"\n                        )\n\n                    loggers[\"main\"].info(\"Index Created\")\n                    return response.json()\n\n            except httpx.HTTPStatusError as e:\n                parsed_response = json.loads(response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\n                    \"message\", \"Unknown error occurred\"\n                )\n                loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            except Exception as e:\n                loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        else:\n            loggers[\"main\"].info(\"index already created\")\n            return {\"host\": self.pc.describe_index(index_name).get(\"host\")}\n\nAsynchronous method in PineconeService class that creates a new serverless Pinecone vector index with specified name, dimension and metric parameters. Checks if index exists first, then makes API request to create index and polls for ready status with retry mechanism. Returns index information upon successful creation or host details if index already exists. Includes comprehensive error handling for HTTP and general exceptions with appropriate logging and status code responses.",
        "size": 3094,
        "parent-class": "PineconeService",
        "function_name": "create_index"
    },
    {
        "id": "09142a1f42a9a8a58120d47997ea208c95e47f2c359cafcb3835e47744b75bc1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 120,
        "end_line": 138,
        "content": "async def upsert_format(\n        self, chunks: list, vector_embeddings: list, sparse_embeddings: list\n    ):\n        results = []\n        for i in range(len(chunks)):\n            metadata = {key: value for key, value in chunks[i].items() if key != \"_id\"}\n\n            metadata[\"created_at\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            result = {\n                \"id\": chunks[i][\"_id\"],\n                \"values\": vector_embeddings[i],\n                \"metadata\": metadata,\n                \"sparse_values\": {\n                    \"indices\": sparse_embeddings[i][\"indices\"],\n                    \"values\": sparse_embeddings[i][\"values\"],\n                },\n            }\n            results.append(result)\n        return results\n\nMethod in PineconeService class that prepares documents for vector database insertion by formatting chunks with their dense and sparse embeddings. Converts input chunks and embeddings into Pinecone-compatible vector records with metadata, preserving document identifiers and adding timestamps. This transformation step occurs between embedding generation and actual vector database upsert operations.",
        "size": 1140,
        "parent-class": "PineconeService",
        "function_name": "upsert_format"
    },
    {
        "id": "ef65e44833fef513f60feeac5f9e0ff4b1d1f187e0ba088dbde4ced6f4b76459",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 140,
        "end_line": 169,
        "content": "async def upsert_vectors(self, index_host, input, namespace):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        url = self.upsert_url.format(index_host)\n\n        payload = {\"vectors\": input, \"namespace\": namespace}\n        try:\n            async with httpx.AsyncClient(timeout= self.timeout) as client:\n                response = await client.post(\n                    url=url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors http status error : {str(e)} - {e.response.text}\")\n            raise HTTPException(status_code=400, detail=e.response.text)    \n        \n        except httpx.HTTPError as e:    \n            loggers[\"main\"].error(f\"Error in upsert vectors http error : {str(e)}\")\n            raise HTTPException(status_code=400, detail=str(e))\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in upsert vectors : {str(e)} \")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in PineconeService class that uploads vector embeddings to a Pinecone index. Takes index host URL, vector data, and namespace parameters, then formats HTTP request with proper authentication headers. Makes POST request to Pinecone's upsert endpoint with configurable timeout settings. Implements comprehensive error handling with specific logging for different HTTP error types, converting errors to appropriate FastAPI HTTP exceptions with status codes 400 for client errors and 500 for server errors.",
        "size": 1772,
        "parent-class": "PineconeService",
        "function_name": "upsert_vectors"
    },
    {
        "id": "60b08bf8ab6ec2334c618c10dc255a753dd9756d714cf60eac7de83feb9fca0e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 171,
        "end_line": 181,
        "content": "def hybrid_scale(self, dense, sparse, alpha: float):\n\n        if alpha < 0 or alpha > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        # scale sparse and dense vectors to create hybrid search vecs\n        hsparse = {\n            \"indices\": sparse[\"indices\"],\n            \"values\": [v * (1 - alpha) for v in sparse[\"values\"]],\n        }\n        hdense = [v * alpha for v in dense]\n        return hdense, hsparse\n\nVector scaling function in the PineconeService class that balances dense and sparse embeddings for hybrid search. Takes dense vector, sparse vector, and alpha parameter (0-1) to adjust the weight between them. Returns scaled vectors with dense values multiplied by alpha and sparse values multiplied by (1-alpha). Used by the pinecone_hybrid_query method for vector similarity search.",
        "size": 820,
        "parent-class": "PineconeService",
        "function_name": "hybrid_scale"
    },
    {
        "id": "db195a6771645139553a65c7c8aca9e61336e6fc36da6fd7b9f7f7fcdb00fbed",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 183,
        "end_line": 247,
        "content": "async def pinecone_hybrid_query(\n        self,\n        index_host,\n        namespace,\n        top_k,\n        alpha: int,\n        query_vector_embeds: list,\n        query_sparse_embeds: dict,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        if query_vector_embeds is None or query_sparse_embeds is None:\n            time.sleep(2)\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        hdense, hsparse = self.hybrid_scale(\n            query_vector_embeds, query_sparse_embeds, alpha\n        )\n\n        payload = {\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n            \"vector\": hdense, \n            \"sparseVector\": {\n                \"indices\": hsparse.get(\n                    \"indices\"\n                ),  \n                \"values\": hsparse.get(\n                    \"values\"\n                ),  \n            },\n            \"topK\": top_k,\n            \"namespace\": namespace,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone hybrid query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error performing hybrid query: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in PineconeService class that performs hybrid vector search queries combining dense and sparse embeddings with configurable weighting. Accepts parameters for index host, namespace, results count, alpha weighting factor, embeddings, and filtering options. Scales vectors using hybrid_scale method, constructs API payload with both vector types, handles errors with detailed logging, and returns vectorized search results from Pinecone with usage metrics tracked.",
        "size": 2830,
        "parent-class": "PineconeService",
        "function_name": "pinecone_hybrid_query"
    },
    {
        "id": "4699a14d582737a0499d0065452410a43ad306735cfb72b6ac3d969bfef6e893",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/pinecone_service.py",
        "file_name": "pinecone_service.py",
        "start_line": 249,
        "end_line": 297,
        "content": "async def pinecone_query(\n        self,\n        index_host: str,\n        namespace: str,\n        top_k: int,\n        vector: list,\n        include_metadata: bool,\n        filter_dict: dict = None,\n    ):\n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.api_version,\n        }\n\n        payload = {\n            \"namespace\": namespace,\n            \"vector\": vector,\n            # \"filter\": filter_dict,\n            \"topK\": top_k,\n            \"includeValues\": False,\n            \"includeMetadata\": include_metadata,\n        }\n\n        if filter_dict:\n            payload[\"filter\"] = filter_dict\n\n        url = self.query_url.format(index_host)\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.post(url, headers=headers, json=payload)\n                loggers[\"pinecone\"].info(f\"pinecone Normal query read units: {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPError as e:\n            if e.response is not None:\n                parsed_response = json.loads(e.response.content.decode(\"utf-8\"))\n                error_message = parsed_response.get(\"error\", {}).get(\"message\", \"Unknown error occurred\")\n                loggers[\"main\"].error(f\"Error from Pinecone: {error_message}\")\n                raise HTTPException(status_code=400, detail=error_message)\n            else:\n                loggers[\"main\"].error(f\"HTTP error without response: {str(e)}\")\n                raise HTTPException(status_code=400, detail=\"Unknown HTTP error occurred\")\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in PineconeService class that performs standard vector search against Pinecone vector database. Accepts index host, namespace, top_k results limit, dense vector for querying, metadata inclusion flag, and optional filter criteria. Sets up request headers with authentication, constructs query payload, sends asynchronous HTTP request to Pinecone, logs read units consumed, handles HTTP and general exceptions with appropriate error messages, and returns query results as JSON. Distinct from the hybrid_query method which combines dense and sparse vectors for improved retrieval.",
        "size": 2400,
        "parent-class": "PineconeService",
        "function_name": "pinecone_query"
    },
    {
        "id": "0de534008b15270ec58af5ddbf4c6d28d589879f45731b0ef571bbbf8799688e",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 1,
        "end_line": 8,
        "content": "import json\nimport logging\nimport pickle\nimport httpx\nfrom fastapi import HTTPException, status\nfrom pinecone_text.sparse import BM25Encoder\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\n\nImport statements for the EmbeddingService module that handles vector embeddings for text. Includes utilities for HTTP requests, logging, serialization, FastAPI error handling, and the BM25 sparse vector encoder from Pinecone. Sets up logger and imports application settings and logging utilities.",
        "size": 523,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "367f8989ceeb2a7e7b6c4be1092ff1df86858c3baec976a743f53bf9a759242a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 18,
        "end_line": 38,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.dense_embed_url = settings.PINECONE_EMBED_URL\n        self.pinecone_embedding_url = settings.PINECONE_EMBED_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.togetherai_api_key = settings.TOGETHERAI_API_KEY\n        self.voyageai_api_key = settings.VOYAGEAI_API_KEY\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.togetherai_base_url = settings.TOGETHERAI_BASE_URL\n        self.voyageai_base_url = settings.VOYAGEAI_BASE_URL\n        self.EMBED_SUFFIX = \"embed\"\n        self.JINA_EMBED_SUFFIX = \"embeddings\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=300.0,    # Time to read the response\n                        write=300.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nInitialization method for the EmbeddingService class that configures API credentials, endpoints, and connection parameters for multiple embedding providers including Pinecone, Cohere, Jina, TogetherAI, and VoyageAI. Sets up API keys, base URLs, endpoint suffixes, and HTTP timeout settings necessary for making embedding API requests across different services.",
        "size": 1511,
        "parent-class": "EmbeddingService",
        "function_name": "__init__"
    },
    {
        "id": "6e7322206e4c091ae4c733450c2fcd83bfb4c8355f770f85687f5f5547f7e7cd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 40,
        "end_line": 84,
        "content": "async def pinecone_dense_embeddings(\n        self,\n        inputs: list,\n        embedding_model: str = \"llama-text-embed-v2\",\n        input_type: str = \"passage\",\n        truncate: str = \"END\",\n        dimension: int = 1024,\n    ):\n        payload = {\n            \"model\": embedding_model,\n            \"parameters\": {\n                \"input_type\": input_type,\n                \"truncate\": truncate,\n                # \"dimension\": dimension,\n            },\n            \"inputs\": inputs,\n        }\n\n        if embedding_model != \"multilingual-e5-large\":\n            payload[\"parameters\"][\"dimension\"] = dimension \n\n        headers = {\n            \"Api-Key\": self.pinecone_api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n        }\n\n        url = self.dense_embed_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"embeddings generated\")\n                response = response.json()\n                loggers[\"pinecone\"].info(f\"pinecone hosted embedding model tokens usage: {response['usage']}\")\n                list_result = [item[\"values\"] for item in response[\"data\"]]\n                return list_result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {e.response.text}\")\n            raise HTTPException(status_code=400, detail=f\"{str(e)}-{e.response.text}\")\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error dense embeddings in pinecone dense embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the EmbeddingService class that generates dense vector embeddings using Pinecone's hosted models. Constructs API requests with configurable parameters for embedding text inputs, handles model-specific configuration requirements, processes HTTP responses, logs token usage metrics, and transforms the response into a list of embedding vectors. Includes error handling for HTTP and general exceptions with appropriate status codes and logging.",
        "size": 2279,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_dense_embeddings"
    },
    {
        "id": "f12590ba98a5a4e443eaa9a79f9306685dbff3c39c2b8e41f4b89f6740b41ec1",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 86,
        "end_line": 93,
        "content": "def pinecone_sparse_embeddings(self, inputs):\n        try:\n            sparse_vector = bm25.encode_documents(inputs)\n            return sparse_vector\n\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating sparse embeddings: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in the EmbeddingService class that generates sparse embeddings using a pre-loaded BM25Encoder. Takes a list of documents as input and returns their sparse vector representations for information retrieval. Handles exceptions by logging errors and raising HTTP 500 responses. Part of a vector embedding pipeline supporting both dense and sparse embedding generation for document retrieval systems.",
        "size": 730,
        "parent-class": "EmbeddingService",
        "function_name": "pinecone_sparse_embeddings"
    },
    {
        "id": "60a53525a6c536fa77b6e8e60a23ea4fe385d2d87727c065e04fc72acdd87e37",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 95,
        "end_line": 137,
        "content": "async def cohere_dense_embeddings(\n        self,\n        model_name: str,\n        texts: list[str],\n        input_type: str = \"search_document\",\n    ):\n\n        url = f\"{self.cohere_base_url}/{self.EMBED_SUFFIX}\"\n\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.cohere_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"texts\": texts,\n            \"input_type\": input_type,\n            \"embedding_types\": [\"float\"],\n        }\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout,verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                # return response.json()\n                response = response.json()\n                loggers[\"cohere\"].info(f\"cohere hosted embedding model tokens usage: { response.get('meta', {}).get('billed_units', {})}\")\n                result = response[\"embeddings\"][\"float\"]\n                return result\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}-{e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense cohere embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method within the EmbeddingService class that generates vector embeddings using Cohere's API. Takes a model name, text inputs, and input type parameter, then constructs a properly formatted request with authentication headers. Makes an HTTP POST request to Cohere's embedding endpoint, logs token usage metrics, extracts the float embeddings from the response, and handles various error conditions with appropriate HTTP exceptions. Part of a larger embedding service that supports multiple embedding providers including Pinecone, Jina, TogetherAI, and VoyageAI.",
        "size": 2335,
        "parent-class": "EmbeddingService",
        "function_name": "cohere_dense_embeddings"
    },
    {
        "id": "e0e5a5cb79f36e736be5f9132ec3961359318fcaa28d5f4131f80832079a5d88",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 139,
        "end_line": 187,
        "content": "async def jina_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n\n        url = f\"{self.jina_base_url}/{self.JINA_EMBED_SUFFIX}\"\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",\n        }\n        data = {\n            \"model\": model_name,\n            \"embedding_type\": \"float\",\n            \"input\": inputs,\n        }\n\n        if model_name == \"jina-embeddings-v3\":\n            data[\"task\"] = input_type\n            data[\"late_chunking\"] = False\n            data['dimensions'] = dimension\n        elif model_name == \"jina-embeddings-v2-base-code\":\n            data[\"normalized\"] = True\n        else:\n            data[\"normalized\"] = True\n            data['dimensions'] = dimension\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout, verify=False) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"jina\"].info(f\"jina hosted embedding model tokens usage: {response.get('usage', {})}\")\n                result = [item[\"embedding\"] for item in response[\"data\"]]\n                return result\n\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.content} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=f\"{str(e)}, {e.response.text}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502,  # Bad Gateway (Failed to connect)\n                detail= f\"Failed to connect to API httpx Request error : {str(e)}\",\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating dense jina embeddings {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in the EmbeddingService class that generates dense vector embeddings using the Jina AI API. The method constructs requests with model-specific parameters (handling special configurations for jina-embeddings-v3 and jina-embeddings-v2-base-code), sends them to the Jina embeddings endpoint, processes responses, logs token usage, and handles various HTTP and request exceptions. Returns extracted embeddings as a list of vectors.",
        "size": 2517,
        "parent-class": "EmbeddingService",
        "function_name": "jina_dense_embeddings"
    },
    {
        "id": "bdc9d63f8d6b4a43f5c07f1afb31cd6f47a2bd690321d0a24f2cc2b2d81a4b72",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 189,
        "end_line": 219,
        "content": "async def togetherai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list[str], input_type :str\n    ):\n        url = f\"{self.togetherai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        headers = {\n            \"accept\": \"application/json\",\n            \"authorization\": f\"Bearer {self.togetherai_api_key}\",\n            \"content-type\": \"application/json\"\n        }\n        payload = {\n            \"model\": model_name,\n            \"input\": inputs\n        }\n\n        try:\n            async with httpx.AsyncClient(verify = False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                return response.json()\n        \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error:{str(e)} {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx : {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in togetherai_dense_embedding: {str(e)}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured : {str(e)}\")\n\nAsynchronous method in the EmbeddingService class that generates dense vector embeddings using the TogetherAI API. Takes model name, dimension, input texts, and input type parameters, constructs the API request with proper authentication headers, handles HTTP responses, and implements comprehensive error handling with appropriate logging. Part of a larger embedding service that supports multiple embedding providers including Pinecone, Cohere, Jina, and VoyageAI.",
        "size": 1997,
        "parent-class": "EmbeddingService",
        "function_name": "togetherai_dense_embeddings"
    },
    {
        "id": "47cbf17e7a019f83fb0482520ee2fea1846c890b7bdb48dafc1b936ff0832a2c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/embedding_service.py",
        "file_name": "embedding_service.py",
        "start_line": 223,
        "end_line": 263,
        "content": "async def voyageai_dense_embeddings(\n        self, model_name: str, dimension: int, inputs: list, input_type: str = \"document\"\n    ):\n        url = f\"{self.voyageai_base_url}/{self.JINA_EMBED_SUFFIX}\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.voyageai_api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        data = {\n            \"input\": inputs,\n            \"model\": model_name,\n            \"input_type\": input_type,\n            \"output_dimension\": dimension\n        }\n\n        try:\n\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                response = response.json()\n                loggers[\"voyage\"].info(f\"Embedding model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                embedding_list = [item[\"embedding\"] for item in response[\"data\"]]\n                return embedding_list\n            \n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error occurred in httpx status error  : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {e.response.text}\")\n            raise HTTPException(status_code=e.response.status_code, detail=f\"HTTP error occurred in httpx status error  : {str(e)} - {e.response.text}\")\n        \n        except httpx.HTTPError as e:\n            loggers[\"main\"].error(f\"HTTP request failed in httpx http error : {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"HTTP error in httpx voyage dense embed: {str(e)}\")\n        \n        except Exception as e:\n            loggers[\"main\"].error(f\"Unexpected error in voyageai_dense_embedding: {str(e)}\")\n            loggers[\"main\"].error(f\"detail message of voyage embed failure: {response.json().get('detail', '')}\")\n            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Unknown Exception occured in voyageai_dense_embedding: {str(e)}, \")\n\nMethod in EmbeddingService class that generates dense vector embeddings using VoyageAI's API service. Accepts model name, dimension size, input texts, and input type parameters. Makes an asynchronous HTTP request to the VoyageAI embeddings endpoint, processes the response to extract embedding vectors, logs token usage, and handles various HTTP and request errors with appropriate error logging and exception handling. Part of a larger embedding service that supports multiple embedding providers including Pinecone, Cohere, Jina, and TogetherAI.",
        "size": 2781,
        "parent-class": "EmbeddingService",
        "function_name": "voyageai_dense_embeddings"
    },
    {
        "id": "91714e2366f1d257e2f3382f4546ba0b39a3e416881df09c2e76eac676d2394c",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 1,
        "end_line": 4,
        "content": "import math\nimport logging\nfrom typing import Dict, List\nfrom app.utils.logging_util import loggers\n\nModule imports for the EvaluationService class that calculates information retrieval metrics. Imports math for logarithmic calculations in ranking metrics, typing for type annotations on collection parameters, and custom logging utilities for error handling and evaluation result reporting.",
        "size": 391,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "8f6e1967c38ac1f15141efc0576926099a19572ccf203ff325b74cb5bebacbea",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 10,
        "end_line": 45,
        "content": "def _discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Discounted Cumulative Gain (DCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            retrieved_texts = [doc[\"id\"] for doc in retrieved_docs[:k]]\n            relevance_scores = [\n                1 if doc in ground_truth else 0 for doc in retrieved_texts\n            ]\n\n            if not relevance_scores:\n                return 0.0\n\n            dcg_at_k = relevance_scores[0] if relevance_scores else 0\n            for i in range(1, len(relevance_scores)):\n                dcg_at_k += relevance_scores[i] / math.log2(i + 1)\n\n            return dcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic helper method within the EvaluationService class that calculates Discounted Cumulative Gain (DCG) at position k. This is a private method used internally as a building block for normalized DCG (NDCG) calculations. The method assigns binary relevance scores to retrieved documents based on ground truth, computes DCG with logarithmic position discounting, and includes input validation and error handling. Part of a comprehensive information retrieval evaluation framework that includes various metrics like precision, recall, F1, and NDCG.",
        "size": 1838,
        "parent-class": "EvaluationService",
        "function_name": "_discounted_cumulative_gain_at_k"
    },
    {
        "id": "c067ce727dfaf902a17e99a24af1d6ebac799142b93263136a6b00e587403cbd",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 48,
        "end_line": 78,
        "content": "def _ideal_discounted_cumulative_gain_at_k(\n        ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Ideal Discounted Cumulative Gain (IDCG) @ K.\n        \"\"\"\n        try:\n            if not isinstance(ground_truth, list) or not isinstance(k, int):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ideal_relevance_scores = [1] * min(len(ground_truth), k)\n\n            if not ideal_relevance_scores:\n                return 0.0\n\n            idcg_at_k = (\n                ideal_relevance_scores[0] if ideal_relevance_scores else 0\n            )\n            for i in range(1, len(ideal_relevance_scores)):\n                idcg_at_k += ideal_relevance_scores[i] / math.log2(i + 1)\n\n            return idcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in ideal_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nPrivate utility method within the EvaluationService class that calculates the Ideal Discounted Cumulative Gain (IDCG) at position K for search evaluation metrics. This method computes the theoretical maximum DCG score possible by assuming all relevant documents are perfectly ranked. It validates input parameters, creates ideal relevance scores (all 1's) for the top K items, and applies the DCG formula with logarithmic position discounting. Used internally by the normalized_discounted_cumulative_gain_at_k method to normalize DCG scores. Part of a comprehensive information retrieval evaluation framework.",
        "size": 1716,
        "parent-class": "EvaluationService",
        "function_name": "_ideal_discounted_cumulative_gain_at_k"
    },
    {
        "id": "be1c760533bb00d549a4b4fdd37c4be2c1b2efc397bddc586cf4cf993027bf7b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 81,
        "end_line": 119,
        "content": "def normalized_discounted_cumulative_gain_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], k: int\n    ) -> float:\n        \"\"\"\n        Computes the Normalized Discounted Cumulative Gain (NDCG) @ K.\n        \"\"\"\n        try:\n            if (\n                not isinstance(retrieved_docs, list)\n                or not isinstance(ground_truth, list)\n                or not isinstance(k, int)\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str], int).\"\n                )\n\n            if k <= 0:\n                raise ValueError(\"Parameter 'k' should be a positive integer.\")\n\n            ndcg_at_k = {}\n            for i in range(k):\n                dcg_at_i = EvaluationService._discounted_cumulative_gain_at_k(\n                    retrieved_docs, ground_truth, i + 1\n                )\n                idcg_at_i = (\n                    EvaluationService._ideal_discounted_cumulative_gain_at_k(\n                        ground_truth, i + 1\n                    )\n                )\n                ndcg_at_i = dcg_at_i / idcg_at_i if idcg_at_i > 0 else 0.0\n\n                ndcg_at_k[f\"NDCG@{i+1}\"] = ndcg_at_i\n\n            loggers['evaluation'].info(f\"NDCG Result: {ndcg_at_k}\")\n            return ndcg_at_k\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in normalized_discounted_cumulative_gain_at_k: {str(e)}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in EvaluationService that calculates Normalized Discounted Cumulative Gain (NDCG) at different K values for information retrieval evaluation. Iterates through values 1 to k, computing DCG and IDCG for each position using helper methods. Returns a dictionary mapping each position (NDCG@1, NDCG@2, etc.) to its corresponding NDCG value. Includes input validation for types and positive k values. Logs results and handles exceptions gracefully. Part of a comprehensive search evaluation framework alongside precision, recall, F1-score, and other metrics.",
        "size": 2041,
        "parent-class": "EvaluationService",
        "function_name": "normalized_discounted_cumulative_gain_at_k"
    },
    {
        "id": "689b202f59428a3f3286123fa822b01cc4949e1f7377ccb1f603e3d03bd06f3b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 122,
        "end_line": 153,
        "content": "def bpref(retrieved_docs: List[Dict], ground_truth: List[str]) -> float:\n        \"\"\"\n        Computes BPREF (Binary Preference).\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            relevant_docs = set(ground_truth)\n            irrelevant_count = 0\n            total_relevant = len(relevant_docs)\n            bpref_score = 0.0\n\n            if total_relevant == 0:\n                return 0.0\n\n            for doc in retrieved_docs:\n                if doc[\"id\"] in relevant_docs:\n                    bpref_score += 1 - (min(irrelevant_count, total_relevant) / total_relevant)\n                else:\n                    irrelevant_count += 1\n\n            loggers['evaluation'].info(f\"BPREF Result: {bpref_score / total_relevant}\")\n            return bpref_score / total_relevant\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in bpref: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in the EvaluationService class that calculates the Binary Preference (BPREF) retrieval evaluation metric. BPREF measures how often relevant documents are retrieved before irrelevant ones, handling cases where relevance judgments are incomplete. The method validates input types, processes retrieved documents against ground truth, computes the BPREF score based on document ranking, logs results, and handles exceptions with appropriate error reporting. Part of a comprehensive search evaluation framework that includes other metrics like precision, recall, and NDCG.",
        "size": 1734,
        "parent-class": "EvaluationService",
        "function_name": "bpref"
    },
    {
        "id": "65746dacd85d5f49531697e99e0ed5ad44c0d46fd1ded951481d5dd8eb10daa7",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 156,
        "end_line": 201,
        "content": "def precision_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Precision@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Precision@k' to precision scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            precision_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision_results[f\"Precision@{k}\"] = (\n                    round(matches / float(k), 2) if k > 0 else 0.0\n                )\n            loggers['evaluation'].info(f\"Precision Result: {precision_results}\")\n            return precision_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in precision_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in EvaluationService class that calculates precision@k metrics for search/retrieval evaluation. Computes the proportion of relevant documents in the top-k results for each k from 1 to max_k. Handles input validation, calculates precision scores for multiple k values by comparing retrieved document IDs against ground truth, and returns a dictionary of precision scores. Part of a comprehensive retrieval evaluation framework alongside other metrics like recall, F1-score, NDCG, and reciprocal rank.",
        "size": 2318,
        "parent-class": "EvaluationService",
        "function_name": "precision_at_k"
    },
    {
        "id": "20e5c707239a9a545b9c93a4f1c1fe799bc83f9b2e4018155fb9eb5e4f1b819b",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 204,
        "end_line": 251,
        "content": "def recall_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Recall@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Recall@k' to recall scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            recall_results = {}\n\n            if len(ground_truth) == 0:\n                return {f\"Recall@{k}\": 0.0 for k in range(1, max_k + 1)}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                matches = len(ground_truth_ids.intersection(retrieved_at_k))\n                recall_results[f\"Recall@{k}\"] = round(\n                    matches / float(len(ground_truth)), 2\n                )\n            loggers['evaluation'].info(f\"Recall Results: {recall_results}\")\n            return recall_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in recall_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method in the EvaluationService class that calculates recall metrics for information retrieval evaluation. Computes the ratio of relevant documents found among top-k results compared to all relevant documents, for each k from 1 to max_k. Implements input validation, handles edge cases, and returns a dictionary mapping \"Recall@k\" keys to their corresponding scores. Part of a comprehensive evaluation framework that includes precision, F1-score, NDCG, and other information retrieval metrics.",
        "size": 2387,
        "parent-class": "EvaluationService",
        "function_name": "recall_at_k"
    },
    {
        "id": "2b274eaddaabe473319c1379032eac56afe059e1ebe30dfebc7c4d09542b3543",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 254,
        "end_line": 314,
        "content": "def f1_score_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes F1-Score@K for all k values from 1 to max_k.\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'F1-Score@k' to F1 scores for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            f1_score_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_ids[:k]\n\n                # Calculate precision\n                matches = sum(\n                    1 for doc_id in retrieved_at_k if doc_id in ground_truth\n                )\n                precision = matches / float(k) if k > 0 else 0.0\n\n                # Calculate recall\n                recall = (\n                    matches / float(len(ground_truth))\n                    if ground_truth\n                    else 0.0\n                )\n\n                # Calculate F1 score\n                f1 = 0.0\n                if precision + recall > 0:\n                    f1 = 2 * (precision * recall) / (precision + recall)\n\n                f1_score_results[f\"F1-Score@{k}\"] = round(f1, 2)\n\n            loggers['evaluation'].info(f\"F1-Score Results: {f1_score_results}\")\n            return f1_score_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in f1_score_at_k: {e}\")\n            return {\"error\": \"couldnt calculate rr\"}\n\nStatic method within the EvaluationService class that calculates F1 scores at multiple k values for information retrieval evaluation. Combines precision and recall metrics to provide balanced retrieval assessment. Processes retrieved documents against ground truth, computes the harmonic mean of precision and recall at each k threshold, handles input validation, logs results through the evaluation logger, and returns a dictionary of F1 scores at different k values. Used alongside other evaluation metrics like precision_at_k, recall_at_k, and NDCG in retrieval system evaluation.",
        "size": 2784,
        "parent-class": "EvaluationService",
        "function_name": "f1_score_at_k"
    },
    {
        "id": "3de0a604ebb126cce2c7c27074d1b5e75b6de4baddbf7de6fa0d323986c76ee9",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 317,
        "end_line": 365,
        "content": "def hit_rate_at_k(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Computes Hit Rate@K for all k values from 1 to max_k.\n        (Binary outcome: 1 if at least one relevant document is in top-K, 0 otherwise)\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            Dictionary mapping 'Hit_Rate@k' to binary hit values for k from 1 to max_k\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[Dict]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_ids = set(ground_truth)\n            retrieved_ids = [doc[\"id\"] for doc in retrieved_docs]\n            hit_rate_results = {}\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = set(retrieved_ids[:k])\n                hit = (\n                    1.0\n                    if len(ground_truth_ids.intersection(retrieved_at_k)) > 0\n                    else 0.0\n                )\n                hit_rate_results[f\"Hit_Rate@{k}\"] = hit\n\n            loggers[\"evaluation\"].info(f\"Hit Rate Results: {hit_rate_results}\")\n            return hit_rate_results\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in hit_rate_at_k: {e}\")\n            return {}\n\nStatic method in EvaluationService class calculating Hit Rate@K metrics for information retrieval evaluation. Determines if any relevant document appears in top-K results for different K values. Returns a dictionary mapping Hit_Rate@k to binary values (1.0 if at least one ground truth document appears in top-K results, 0.0 otherwise). Handles input validation, edge cases, and logs results to evaluation logger. Part of a comprehensive evaluation framework alongside precision, recall, F1, NDCG, and other retrieval metrics.",
        "size": 2398,
        "parent-class": "EvaluationService",
        "function_name": "hit_rate_at_k"
    },
    {
        "id": "9826446cf3af509400f1a4c9134435e032644bd99cb227d9f2b62dcb2c5b553a",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 368,
        "end_line": 401,
        "content": "def reciprocal_rank(\n        retrieved_docs: List[Dict], ground_truth: List[str]\n    ) -> float:\n        \"\"\"\n        Computes Mean Reciprocal Rank (MRR).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n\n        Returns:\n            MRR score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            reciprocal_rank = 0.0\n            ground_truth_set = set(ground_truth)\n\n            for rank, doc in enumerate(retrieved_docs, start=1):\n                if doc[\"id\"] in ground_truth_set:\n                    reciprocal_rank = 1.0 / rank\n                    break\n\n            return reciprocal_rank\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_reciprocal_rank: {e}\")\n            return 0.0\n\nStatic method in EvaluationService class that calculates Reciprocal Rank (RR) for information retrieval evaluation. Finds the rank of the first relevant document in retrieved results and returns the reciprocal of that position. Includes input validation, error handling, and logging. Part of a comprehensive evaluation metrics framework alongside NDCG, precision@k, recall@k, F1-score, and other retrieval quality metrics.",
        "size": 1516,
        "parent-class": "EvaluationService",
        "function_name": "reciprocal_rank"
    },
    {
        "id": "d04963a67f8f514dcb529d1584b98a7f8ebca51d0d917b31e159102d2caf0588",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/evaluation_service.py",
        "file_name": "evaluation_service.py",
        "start_line": 404,
        "end_line": 452,
        "content": "def mean_average_precision(\n        retrieved_docs: List[Dict], ground_truth: List[str], max_k: int = None\n    ) -> float:\n        \"\"\"\n        Computes Mean Average Precision (MAP).\n\n        Args:\n            retrieved_docs: List of retrieved documents, each with an \"id\" field\n            ground_truth: List of ground truth documents, each with an \"id\" field\n            max_k: Maximum k value to compute. If None, uses length of retrieved_docs\n\n        Returns:\n            MAP score (float)\n        \"\"\"\n        try:\n            if not isinstance(retrieved_docs, list) or not isinstance(\n                ground_truth, list\n            ):\n                raise TypeError(\n                    \"Invalid input types. Expected (List[Dict], List[str]).\"\n                )\n\n            if max_k is None:\n                max_k = len(retrieved_docs)\n            elif max_k <= 0:\n                raise ValueError(\n                    \"Parameter 'max_k' should be a positive integer.\"\n                )\n\n            ground_truth_set = set(ground_truth)\n            average_precision = 0.0\n            relevant_count = 0\n\n            for k in range(1, max_k + 1):\n                retrieved_at_k = retrieved_docs[:k]\n                matches = sum(\n                    1 for doc in retrieved_at_k if doc[\"id\"] in ground_truth_set\n                )\n                precision_at_k = matches / float(k) if k > 0 else 0.0\n\n                if retrieved_at_k[-1][\"id\"] in ground_truth_set:\n                    average_precision += precision_at_k\n                    relevant_count += 1\n\n            return average_precision / relevant_count if relevant_count > 0 else 0.0\n\n        except Exception as e:\n            loggers['main'].error(f\"Error in mean_average_precision: {e}\")\n            return 0.0\n\nStatic method within EvaluationService class calculating Mean Average Precision (MAP), a standard information retrieval evaluation metric. Examines document retrieval effectiveness by measuring precision at positions where relevant documents appear. Takes retrieved documents, ground truth references, and optional cutoff parameter. Handles input validation, computes precision incrementally at each position containing relevant documents, and returns the average. Part of a comprehensive evaluation framework including other metrics like NDCG, precision/recall, F1-score, and hit rate calculations.",
        "size": 2384,
        "parent-class": "EvaluationService",
        "function_name": "mean_average_precision"
    },
    {
        "id": "691076586db2583ff6c6ee5eb80f49da8912501924240cc8bfc9e75457c94beb",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 1,
        "end_line": 5,
        "content": "import json\nimport httpx\nfrom fastapi import HTTPException\nfrom app.config.settings import settings\nfrom app.utils.logging_util import loggers\n\nPython import statements for a RerankerService class that handles document reranking. Imports JSON handling, HTTP client (httpx), FastAPI error handling, application settings, and logging utilities needed for API integration with reranking services like Pinecone, Cohere, Jina, and VoyageAI.",
        "size": 435,
        "parent-class": null,
        "function_name": null
    },
    {
        "id": "03b42c82b71e2df6b46621e1a14df6f4a2c3ca3397186d1a1bb84edc3b1144f0",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 11,
        "end_line": 27,
        "content": "def __init__(self):\n        self.pinecone_api_key = settings.PINECONE_API_KEY\n        self.cohere_api_key = settings.COHERE_API_KEY\n        self.jina_api_key = settings.JINA_API_KEY\n        self.voyage_api_key=settings.VOYAGEAI_API_KEY\n        self.pinecone_rerank_url = settings.PINECONE_RERANK_URL\n        self.pinecone_api_version = settings.PINECONE_API_VERSION\n        self.cohere_base_url = settings.COHERE_BASE_URL\n        self.jina_base_url = settings.JINA_BASE_URL\n        self.voyage_base_url=settings.VOYAGEAI_BASE_URL\n        self.RERANK_SUFFIX = \"rerank\"\n        self.timeout = httpx.Timeout(\n                        connect=60.0,  # Time to establish a connection\n                        read=120.0,    # Time to read the response\n                        write=120.0,   # Time to send data\n                        pool=60.0      # Time to wait for a connection from the pool\n                    )\n\nInitializer for RerankerService class, configuring API keys, endpoints, and timeouts for multiple reranking services including Pinecone, Cohere, Jina, and VoyageAI. Sets up connection parameters and default timeout values for asynchronous HTTP requests used in document reranking operations.",
        "size": 1203,
        "parent-class": "RerankerService",
        "function_name": "__init__"
    },
    {
        "id": "4eaeb117de9f86d0226916433b8844d3121b0cea8e72431de9e09a4a6bc401ac",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 29,
        "end_line": 70,
        "content": "async def pinecone_reranker(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"X-Pinecone-API-Version\": self.pinecone_api_version,\n            \"Api-Key\": self.pinecone_api_key,\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"return_documents\": True,\n            \"top_n\": top_n,\n            \"documents\": documents,\n            \"parameters\": {\n                \"truncate\": \"END\",\n            },\n        }\n\n        url = self.pinecone_rerank_url\n\n        try:\n            async with httpx.AsyncClient(timeout = self.timeout) as client:\n                response = await client.post(url, headers=headers, json=payload)\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done\")\n                loggers[\"pinecone\"].info(f\"Reranking model hosted by Pinecone tokens usage : {response.json()['usage']}\")\n                return response.json()\n\n        except httpx.HTTPStatusError as e:\n            parsed_response = json.loads(response.content.decode(\"utf-8\"))\n            error_message = parsed_response.get(\"error\", {}).get(\n                \"message\", \"Unknown error occurred\"\n            )\n            loggers[\"main\"].error(f\"Error creating index: {error_message}\")\n            raise HTTPException(status_code=400, detail=error_message)\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error creating index: {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method within RerankerService class that sends requests to Pinecone's reranking API. Accepts a model name, query, document list, and top_n parameter to reorder documents by relevance. Configures request headers with API credentials, constructs payload with search parameters, handles timeout settings, logs token usage, and implements comprehensive error handling for HTTP and general exceptions.",
        "size": 2054,
        "parent-class": "RerankerService",
        "function_name": "pinecone_reranker"
    },
    {
        "id": "5172c965ec33a86e9cf35a2fc98ed3467448c55e69bb331df065218f1caf0ae2",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 72,
        "end_line": 114,
        "content": "async def cohere_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        rerank_url = f\"{self.cohere_base_url}/{self.RERANK_SUFFIX}\"\n\n        headers = {\n            \"content-type\": \"application/json\",\n            \"accept\": \"application/json\",\n            \"Authorization\": f\"bearer {self.cohere_api_key}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url,\n                    headers=headers,\n                    json=payload,\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by cohere\")\n                loggers[\"cohere\"].info(f\"Reranking model hosted by Cohere tokens usage : {response.json().get('meta',{}).get('billed_units', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in cohere {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsynchronous method in RerankerService class for reranking documents using Cohere's API. Sends HTTP requests with query and documents to Cohere's rerank endpoint, configures authentication and payload formatting, handles various error conditions, and logs token usage metrics. Part of a modular design pattern with similar implementations for other reranking providers including Pinecone, Jina, and Voyage.",
        "size": 2183,
        "parent-class": "RerankerService",
        "function_name": "cohere_rerank"
    },
    {
        "id": "6057a6b072a505fab876260d9d874ebd39534569c15896be93fa1395469a8c60",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 116,
        "end_line": 155,
        "content": "async def jina_rerank(\n        self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        # query will be string and documents will be list of strings\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.jina_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_n\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.jina_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by jina\")\n                loggers[\"jina\"].info(f\"Reranking model hosted by Jina tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail=str(e)\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in jina {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nAsync method in RerankerService class that sends reranking requests to Jina AI's API. Prepares request headers with authentication, builds a payload with the model, query, documents, and top_n parameters, then posts to the rerank endpoint. Handles HTTP responses, logs token usage metrics, and includes error handling for various failure scenarios. Part of a larger service that supports multiple reranking providers (Pinecone, Cohere, Jina, Voyage).",
        "size": 2150,
        "parent-class": "RerankerService",
        "function_name": "jina_rerank"
    },
    {
        "id": "417f137659c70b6a794a2c1a2b33bbd3eabd8c09768c871b4f2b550484d14dc5",
        "file_path": "/Users/tapankheni/Developer/POC-SWE-RAG/code_repo/app/services/reranking_service.py",
        "file_name": "reranking_service.py",
        "start_line": 158,
        "end_line": 196,
        "content": "async def voyage_rerank(\n            self, model_name: str, query: str, documents: list, top_n: int\n    ):\n        headers = {\n            \"content-type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.voyage_api_key}\",  # f\"Bearer {os.getenv('JINA_API_KEY')}\",\n        }\n\n        payload = {\n            \"model\": model_name,\n            \"query\": query,\n            \"top_k\": top_n,\n            \"documents\": documents,\n        }\n\n        rerank_url = f\"{self.voyage_base_url}/{self.RERANK_SUFFIX}\"\n\n        try:\n            async with httpx.AsyncClient(verify=False, timeout = self.timeout) as client:\n                response = await client.post(\n                    rerank_url, headers=headers, json=payload\n                )\n                response.raise_for_status()\n                loggers[\"main\"].info(\"reranking done by voyage\")\n                loggers[\"voyage\"].info(f\"Reranking model hosted by Voyage tokens usage : {response.json().get('usage', {})}\")\n                return response.json()\n        except httpx.HTTPStatusError as e:\n            loggers[\"main\"].error(f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\")\n            raise HTTPException(\n                status_code=e.response.status_code, detail = f\"HTTP error: {e.response.status_code} - {e.response.text} - {str(e)}\"\n            )\n        except httpx.RequestError as e:\n            loggers[\"main\"].error(f\"Request error:  {str(e)}\")\n            raise HTTPException(\n                status_code=502, detail=\"Failed to connect to API\"\n            )\n        except Exception as e:\n            loggers[\"main\"].error(f\"Error in reranking in Voyage {str(e)}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\nMethod in RerankerService class that handles reranking using VoyageAI's API. Takes model name, query, documents list, and top_n parameters. Constructs API request with proper authentication headers, sends documents to be reranked based on relevance to query, logs token usage, and handles various HTTP and request errors. Part of a service that implements multiple reranking providers including Pinecone, Cohere, Jina, and VoyageAI.",
        "size": 2167,
        "parent-class": "RerankerService",
        "function_name": "voyage_rerank"
    }
]